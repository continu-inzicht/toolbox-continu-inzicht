[
  {
    "objectID": "voorbeelden.html",
    "href": "voorbeelden.html",
    "title": "Voorbeelden",
    "section": "",
    "text": "Hier zijn een aantal notebooks met voorbeelden hoe de toolbox gebruikt kan worden.\nDeze notebook met bijbehorende data en configuratie zijn beschikbaar op GitHub.\nTijdens het ontwikkelen zijn ook een heel aantal development notebooks gemaakt, in de loop van de tijd zullen de meeste ook naar deze wiki pagina worden gemigreerd. De notebooks gemaakt voor de demo hebben vaak interactie met de database om zo de viewer te laten zien. Deze zullen hier niet beschikbaar worden, wel zijn ze te vinden onder tests op GitHub.\nDe voorbeelden zijn:\n\nArchitectuur voorbeeld\nInladen van belastingen\nFragility curve overtopping\nAanpassen van geïntegreerde faalkans\nInspectieresultaten\n\nDaarnaast zijn er ook notebook met meer technische uitleg over aspecten van de toolbox:\n\nGebruik van logging\nWMS laag instellen in de viewer",
    "crumbs": [
      "Voorbeelden"
    ]
  },
  {
    "objectID": "reference/SectionsTechnicalFailureprobability.html",
    "href": "reference/SectionsTechnicalFailureprobability.html",
    "title": "SectionsTechnicalFailureprobability",
    "section": "",
    "text": "sections.SectionsTechnicalFailureprobability()\nBepaal de technische faalkans van een dijkvak\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object voor het verwerken van gegevens.\n\n\ndf_in_section_loads\nOptional[pd.DataFrame] | None\nInvoer DataFrame met belasting per dijkvak. Standaardwaarde is None.\n\n\ndf_in_fragility_curves\nOptional[pd.DataFrame] | None\nInvoer DataFrame met fragiliteitscurves per dijkvak. Standaardwaarde is None.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nUitvoer DataFrame met faalkansen per dijkvak. Standaardwaarde is None.\n\n\ninput_schema_fragility_curves\nClassVar[dict[str, str]]\nSchema voor de invoer van fragiliteitscurves per dijkvak.\n\n\ninput_schema_loads\nClassVar[dict[str, str]]\nSchema voor de invoer van belasting per dijkvak.\n\n\n\n\n\n\nInput schema’s\ninput_schema_sections: schema voor de lijst met dijkvakken\n\nid: int64 : id van het dijkvak\nname: str : naam van de dijkvak\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\ninput_schema_section_fractions: schema voor koppeling van de maatgevende meetlocaties per dijkvak\n\nid: int64 : id van de dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedenstrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\nOutput schema\ndf_out (DataFrame): uitvoer\n\nid: int64 : id van het dijkvak\nname; str : naam van de dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nunit: str : eenheid van de belastingparameter\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\niterate_combinations\n\n\n\nrun\nBepalen faalkans van een dijkvak.\n\n\n\n\n\nsections.SectionsTechnicalFailureprobability.iterate_combinations(\n    unique_combinations\n    df_in_belasting\n    df_in_fragility_curves\n    df_out\n)\n\n\n\nsections.SectionsTechnicalFailureprobability.run(input, output)\nBepalen faalkans van een dijkvak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst met namen van data adapters (2) voor tijdreeks met belasting op de dijkvak en fragility curves voor de dijkvak\nrequired\n\n\noutput\nstr\nUitvoer data adapter naam.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de lengte van de input variabele niet gelijk is aan 2."
  },
  {
    "objectID": "reference/SectionsTechnicalFailureprobability.html#attributes",
    "href": "reference/SectionsTechnicalFailureprobability.html#attributes",
    "title": "SectionsTechnicalFailureprobability",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object voor het verwerken van gegevens.\n\n\ndf_in_section_loads\nOptional[pd.DataFrame] | None\nInvoer DataFrame met belasting per dijkvak. Standaardwaarde is None.\n\n\ndf_in_fragility_curves\nOptional[pd.DataFrame] | None\nInvoer DataFrame met fragiliteitscurves per dijkvak. Standaardwaarde is None.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nUitvoer DataFrame met faalkansen per dijkvak. Standaardwaarde is None.\n\n\ninput_schema_fragility_curves\nClassVar[dict[str, str]]\nSchema voor de invoer van fragiliteitscurves per dijkvak.\n\n\ninput_schema_loads\nClassVar[dict[str, str]]\nSchema voor de invoer van belasting per dijkvak."
  },
  {
    "objectID": "reference/SectionsTechnicalFailureprobability.html#notes",
    "href": "reference/SectionsTechnicalFailureprobability.html#notes",
    "title": "SectionsTechnicalFailureprobability",
    "section": "",
    "text": "Input schema’s\ninput_schema_sections: schema voor de lijst met dijkvakken\n\nid: int64 : id van het dijkvak\nname: str : naam van de dijkvak\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\ninput_schema_section_fractions: schema voor koppeling van de maatgevende meetlocaties per dijkvak\n\nid: int64 : id van de dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedenstrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\nOutput schema\ndf_out (DataFrame): uitvoer\n\nid: int64 : id van het dijkvak\nname; str : naam van de dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nunit: str : eenheid van de belastingparameter\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)"
  },
  {
    "objectID": "reference/SectionsTechnicalFailureprobability.html#methods",
    "href": "reference/SectionsTechnicalFailureprobability.html#methods",
    "title": "SectionsTechnicalFailureprobability",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\niterate_combinations\n\n\n\nrun\nBepalen faalkans van een dijkvak.\n\n\n\n\n\nsections.SectionsTechnicalFailureprobability.iterate_combinations(\n    unique_combinations\n    df_in_belasting\n    df_in_fragility_curves\n    df_out\n)\n\n\n\nsections.SectionsTechnicalFailureprobability.run(input, output)\nBepalen faalkans van een dijkvak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst met namen van data adapters (2) voor tijdreeks met belasting op de dijkvak en fragility curves voor de dijkvak\nrequired\n\n\noutput\nstr\nUitvoer data adapter naam.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de lengte van de input variabele niet gelijk is aan 2."
  },
  {
    "objectID": "reference/SectionsLoads.html",
    "href": "reference/SectionsLoads.html",
    "title": "SectionsLoads",
    "section": "",
    "text": "sections.SectionsLoads()\nBepaal de belasting op een dijkvak gegeven een belasting\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter: De data adapter.\n\n\ndf_in_sections\nOptional[pd.DataFrame] | None\nDataFrame: lijst met dijkvakken.\n\n\ndf_in_loads\nOptional[pd.DataFrame] | None\nDataFrame: belasting per moment per meetlocaties.\n\n\ndf_in_section_fractions\nOptional[pd.DataFrame] | None\nDataFrame: koppeling van de maatgevende meetlocaties per dijkvak .\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame: uitvoer.\n\n\ninput_schema_sections\nClassVar[dict[str, str]]\nSchema voor de lijst met dijkvakken.\n\n\ninput_schema_loads\nClassVar[dict[str, str]]\nSchema voor belasting per moment per meetlocaties.\n\n\ninput_schema_section_fractions\nClassVar[dict[str, str]]\nSchema voor koppeling van de maatgevende meetlocaties per dijkvak door middel van verhoudingen.\n\n\n\n\n\n\nInput schema’s\ninput_schema_sections: schema voor de lijst met dijkvakken\n\nid: int64 : id van het dijkvak\nname: str : naam van de dijkvak\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\ninput_schema_section_fractions: schema voor koppeling van de maatgevende meetlocaties per dijkvak\n\nid: int64 : id van de dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedenstrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\nOutput schema\ndf_out (DataFrame): uitvoer\n\nid: int64 : id van het dijkvak\nname; str : naam van de dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nunit: str : eenheid van de belastingparameter\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nBepalen de belasting op een dijkvak.\n\n\n\n\n\nsections.SectionsLoads.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nsections.SectionsLoads.run(input, output)\nBepalen de belasting op een dijkvak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nlijst van data adapters met: dijkvakken, belasting per moment per meetlocaties en koppeling van de maatgevende meetlocaties per dijkvak\nrequired\n\n\noutput\nstr\nData adapter voor koppeling van de maatgevende meetlocaties per dijkvak\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de input variabele niet 3 string waarden bevat."
  },
  {
    "objectID": "reference/SectionsLoads.html#attributes",
    "href": "reference/SectionsLoads.html#attributes",
    "title": "SectionsLoads",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter: De data adapter.\n\n\ndf_in_sections\nOptional[pd.DataFrame] | None\nDataFrame: lijst met dijkvakken.\n\n\ndf_in_loads\nOptional[pd.DataFrame] | None\nDataFrame: belasting per moment per meetlocaties.\n\n\ndf_in_section_fractions\nOptional[pd.DataFrame] | None\nDataFrame: koppeling van de maatgevende meetlocaties per dijkvak .\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame: uitvoer.\n\n\ninput_schema_sections\nClassVar[dict[str, str]]\nSchema voor de lijst met dijkvakken.\n\n\ninput_schema_loads\nClassVar[dict[str, str]]\nSchema voor belasting per moment per meetlocaties.\n\n\ninput_schema_section_fractions\nClassVar[dict[str, str]]\nSchema voor koppeling van de maatgevende meetlocaties per dijkvak door middel van verhoudingen."
  },
  {
    "objectID": "reference/SectionsLoads.html#notes",
    "href": "reference/SectionsLoads.html#notes",
    "title": "SectionsLoads",
    "section": "",
    "text": "Input schema’s\ninput_schema_sections: schema voor de lijst met dijkvakken\n\nid: int64 : id van het dijkvak\nname: str : naam van de dijkvak\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\ninput_schema_section_fractions: schema voor koppeling van de maatgevende meetlocaties per dijkvak\n\nid: int64 : id van de dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedenstrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\nOutput schema\ndf_out (DataFrame): uitvoer\n\nid: int64 : id van het dijkvak\nname; str : naam van de dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nunit: str : eenheid van de belastingparameter\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)"
  },
  {
    "objectID": "reference/SectionsLoads.html#methods",
    "href": "reference/SectionsLoads.html#methods",
    "title": "SectionsLoads",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nBepalen de belasting op een dijkvak.\n\n\n\n\n\nsections.SectionsLoads.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nsections.SectionsLoads.run(input, output)\nBepalen de belasting op een dijkvak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nlijst van data adapters met: dijkvakken, belasting per moment per meetlocaties en koppeling van de maatgevende meetlocaties per dijkvak\nrequired\n\n\noutput\nstr\nData adapter voor koppeling van de maatgevende meetlocaties per dijkvak\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de input variabele niet 3 string waarden bevat."
  },
  {
    "objectID": "reference/SectionsClassify.html",
    "href": "reference/SectionsClassify.html",
    "title": "SectionsClassify",
    "section": "",
    "text": "sections.SectionsClassify()\nBepaal de status van een dijkvak gegeven de faalkans en grenswaardes.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die wordt gebruikt om de data in te laden en op te slaan.\n\n\ndf_in_thresholds\nOptional[pd.DataFrame] | None\nDataframe met klassegrenzen per dijkvak.\n\n\ndf_in_failureprobability\nOptional[pd.DataFrame] | None\nDataframe met faalkans per moment per dijkvak.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataframe met geclassificeerde faalkansen per dijkvak.\n\n\ninput_schema_thresholds\nClassVar[dict[str, str]]\nSchema voor klassegrenzen per dijkvak.\n\n\ninput_schema_failureprobability\nClassVar[dict[str, str]]\nSchema voor faalkans per moment per dijkvak.\n\n\n\n\n\n\nInput schema’s\ninput_schema_thresholds: schema voor grenswaardes per dijkvak\n\nlower_boundary: float64 : ondergrens van de klasses\nupper_boundary: float64 : bovengrens van de klassegrens\nstate_id: int64 : id van de klassegrens\n\n*input_schema_failureprobability**: schema voor faalkans per moment per dijkvak\n\nsection_id: int64 : id van het dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : faalkans van de tijdreeksitem\n\nOutput schema\nOutput format: uitvoer\n\nfailureprobability_id: in64 : id van de dijkvak/faalmechanisme/maatregel combinatie\nsection_id: int64 : id van het dijkvak\nvalue_parameter_id : id van de belasting parameter (1,2,3,4)\nfailuremechanism_id: int64 : id van het faalmechanisme\nfailuremechanism: str : code van het faalmechanisme\nmeasures_id: int : id van de maatregel\nmeasure str : naam van de maatregel\nparameter_id: int64 : id van de faalkans parameter (5,100,101,102)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : faalkans van de tijdreeksitem\nstate_id: int64 : id van de klassegrens\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nBepaal de status van een dijkvak\n\n\n\n\n\nsections.SectionsClassify.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nsections.SectionsClassify.run(input, output)\nBepaal de status van een dijkvak\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van data adapters met klassegrenzen en faalkans per dijkvak\nrequired\n\n\noutput\nstr\nkoppeling van de maatgevende meetlocaties per dijkvak\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de input variabele niet 2 string waarden bevat. (klassegrenzen/faalkans per dijkvak)\n\n\n\nValueError\nAls df_in_failureprobability is None"
  },
  {
    "objectID": "reference/SectionsClassify.html#attributes",
    "href": "reference/SectionsClassify.html#attributes",
    "title": "SectionsClassify",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die wordt gebruikt om de data in te laden en op te slaan.\n\n\ndf_in_thresholds\nOptional[pd.DataFrame] | None\nDataframe met klassegrenzen per dijkvak.\n\n\ndf_in_failureprobability\nOptional[pd.DataFrame] | None\nDataframe met faalkans per moment per dijkvak.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataframe met geclassificeerde faalkansen per dijkvak.\n\n\ninput_schema_thresholds\nClassVar[dict[str, str]]\nSchema voor klassegrenzen per dijkvak.\n\n\ninput_schema_failureprobability\nClassVar[dict[str, str]]\nSchema voor faalkans per moment per dijkvak."
  },
  {
    "objectID": "reference/SectionsClassify.html#notes",
    "href": "reference/SectionsClassify.html#notes",
    "title": "SectionsClassify",
    "section": "",
    "text": "Input schema’s\ninput_schema_thresholds: schema voor grenswaardes per dijkvak\n\nlower_boundary: float64 : ondergrens van de klasses\nupper_boundary: float64 : bovengrens van de klassegrens\nstate_id: int64 : id van de klassegrens\n\n*input_schema_failureprobability**: schema voor faalkans per moment per dijkvak\n\nsection_id: int64 : id van het dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : faalkans van de tijdreeksitem\n\nOutput schema\nOutput format: uitvoer\n\nfailureprobability_id: in64 : id van de dijkvak/faalmechanisme/maatregel combinatie\nsection_id: int64 : id van het dijkvak\nvalue_parameter_id : id van de belasting parameter (1,2,3,4)\nfailuremechanism_id: int64 : id van het faalmechanisme\nfailuremechanism: str : code van het faalmechanisme\nmeasures_id: int : id van de maatregel\nmeasure str : naam van de maatregel\nparameter_id: int64 : id van de faalkans parameter (5,100,101,102)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : faalkans van de tijdreeksitem\nstate_id: int64 : id van de klassegrens"
  },
  {
    "objectID": "reference/SectionsClassify.html#methods",
    "href": "reference/SectionsClassify.html#methods",
    "title": "SectionsClassify",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nBepaal de status van een dijkvak\n\n\n\n\n\nsections.SectionsClassify.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nsections.SectionsClassify.run(input, output)\nBepaal de status van een dijkvak\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van data adapters met klassegrenzen en faalkans per dijkvak\nrequired\n\n\noutput\nstr\nkoppeling van de maatgevende meetlocaties per dijkvak\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de input variabele niet 2 string waarden bevat. (klassegrenzen/faalkans per dijkvak)\n\n\n\nValueError\nAls df_in_failureprobability is None"
  },
  {
    "objectID": "reference/output_section.html",
    "href": "reference/output_section.html",
    "title": "output_section",
    "section": "",
    "text": "base.adapters.output.continu_inzicht_postgresql.output_section\nData adapters voor het schrijven naar de Continu Inzicht database\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_failuremechanisms\nOphalen lijst met faalmechanismes uit de Continu Inzicht database\n\n\nget_parameters\nOphalen lijst met parameters uit de Continu Inzicht database\n\n\noutput_ci_postgresql_section\nSchrijft secties naar de Continu Inzicht database (tabel: sections).\n\n\noutput_ci_postgresql_section_load_to_data\nSchrijft data voor dijkvakken de belasting naar Continu Inzicht database (tabel: data)\n\n\noutput_ci_postgresql_section_to_data\nSchrijft data naar Continu Inzicht database\n\n\noutput_ci_postgresql_section_to_states\nSchrijft state naar Continu Inzicht database\n\n\noutput_ci_postgresql_sectionfractions\nSchrijft (interpolatie)fracties van meetlocatie per sectie naar de Continu Inzicht database (tabel: sectionfractions).\n\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.get_failuremechanisms(\n    engine\n    schema\n)\nOphalen lijst met faalmechanismes uit de Continu Inzicht database\nFaalmechanismes:\n\ncode: naam\nCOMB: Combinatie faalmechanismen\nGEKB: Overloop en overslag dijken\nSTPH: Opbarsten en piping dijken\nSTBI: Stabiliteit binnenwaarts dijken\nHTKW: Overloop en overslag langsconstructies\nSTKWl: Stabiliteit langsconstructies\nPKW: Piping langsconstructies\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.get_parameters(\n    engine\n    schema\n)\nOphalen lijst met parameters uit de Continu Inzicht database\nFaalmechanismes:\n\ncode: naam\nH10: Gemeten waterstand\nH10V: Voorspelde waterstand\nH10EH: Voorspelde waterstand ensemble hoog\nH10EL: Voorspelde waterstand ensemble laag\nPF: Faalkans\nBO: Beheerdersoordeel\nMR: Maatregel\nRSCH: Risico verwachte schade\nRSL: Risico verwachte slachtoffers\nRGETR: Risico getroffenen\nRPLPF: Risico plaatsgebonden overstromingskans\nPFT: Faalkans technical\nPFM: Faalkans measure\nPFEJ: Faalkans expert judgement\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section(\n    output_config\n    df\n)\nSchrijft secties naar de Continu Inzicht database (tabel: sections).\nYaml example:\ntype: ci_postgresql_section\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties df (DataFrame):\n\nid: int64: id van de sectie\nsegmentid: int64: id van het segment waartoe de sectie behoort\nname: str: naam van de sectie\ngeometry: geom: geometrie (ligging) van de sectie (let op projectie altijd EPSG4326!)\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section_load_to_data(\n    output_config\n    df\n)\nSchrijft data voor dijkvakken de belasting naar Continu Inzicht database (tabel: data)\nYaml example:\ntype: ci_postgresql_section_load_to_data\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nunit_conversion_factor: 0.01\nArgs:\noutput_config (dict): configuratie opties\ndf (DataFrame):\n\nmeasurement_location_id: int64\ndate_time: datetime64[ns, UTC]\nvalue: float64\nvalue_type: str\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section_to_data(\n    output_config\n    df\n)\nSchrijft data naar Continu Inzicht database\n\n\noutput_config (dict):\n\n\n\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str):\npostgresql_password (str):\npostgresql_host (str):\npostgresql_port (str):\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str):\nschema (str):\n\n\n\n\npd.Dataframe\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section_to_states(\n    output_config\n    df\n)\nSchrijft state naar Continu Inzicht database\n\n\noutput_config (dict):\n\n\n\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str):\npostgresql_password (str):\npostgresql_host (str):\npostgresql_port (str):\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str):\nschema (str):\n\n\n\n\npd.Dataframe\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_sectionfractions(\n    output_config\n    df\n)\nSchrijft (interpolatie)fracties van meetlocatie per sectie naar de Continu Inzicht database (tabel: sectionfractions).\nYaml example:\ntype: ci_postgresql_sectionfractions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties\ndf (DataFrame): - sectionid: int64 : id van de sectie - idup: int64 : id van het meetlocatie (measuringlocation), stroomopwaarst gelegen (indien van toepassing) - iddown: int64 : id van het meetlocatie (measuringlocation), stroomafwaarst gelegen (indien van toepassing) - fractionup: float64 : fractie van de belasting gebruikt voor interpolatie belasting bij sectie stroomopwaarst gelegen (indien van toepassing) - fractiondown: float64 : fractie van de belasting gebruikt voor interpolatie belasting bij sectie stroomafwaarst gelegen (indien van toepassing) - parameters: XXXXXX : OPTIONEEL lijst van (belasting)parameters (ROLF VRAGEN)\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht"
  },
  {
    "objectID": "reference/output_section.html#functions",
    "href": "reference/output_section.html#functions",
    "title": "output_section",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_failuremechanisms\nOphalen lijst met faalmechanismes uit de Continu Inzicht database\n\n\nget_parameters\nOphalen lijst met parameters uit de Continu Inzicht database\n\n\noutput_ci_postgresql_section\nSchrijft secties naar de Continu Inzicht database (tabel: sections).\n\n\noutput_ci_postgresql_section_load_to_data\nSchrijft data voor dijkvakken de belasting naar Continu Inzicht database (tabel: data)\n\n\noutput_ci_postgresql_section_to_data\nSchrijft data naar Continu Inzicht database\n\n\noutput_ci_postgresql_section_to_states\nSchrijft state naar Continu Inzicht database\n\n\noutput_ci_postgresql_sectionfractions\nSchrijft (interpolatie)fracties van meetlocatie per sectie naar de Continu Inzicht database (tabel: sectionfractions).\n\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.get_failuremechanisms(\n    engine\n    schema\n)\nOphalen lijst met faalmechanismes uit de Continu Inzicht database\nFaalmechanismes:\n\ncode: naam\nCOMB: Combinatie faalmechanismen\nGEKB: Overloop en overslag dijken\nSTPH: Opbarsten en piping dijken\nSTBI: Stabiliteit binnenwaarts dijken\nHTKW: Overloop en overslag langsconstructies\nSTKWl: Stabiliteit langsconstructies\nPKW: Piping langsconstructies\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.get_parameters(\n    engine\n    schema\n)\nOphalen lijst met parameters uit de Continu Inzicht database\nFaalmechanismes:\n\ncode: naam\nH10: Gemeten waterstand\nH10V: Voorspelde waterstand\nH10EH: Voorspelde waterstand ensemble hoog\nH10EL: Voorspelde waterstand ensemble laag\nPF: Faalkans\nBO: Beheerdersoordeel\nMR: Maatregel\nRSCH: Risico verwachte schade\nRSL: Risico verwachte slachtoffers\nRGETR: Risico getroffenen\nRPLPF: Risico plaatsgebonden overstromingskans\nPFT: Faalkans technical\nPFM: Faalkans measure\nPFEJ: Faalkans expert judgement\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section(\n    output_config\n    df\n)\nSchrijft secties naar de Continu Inzicht database (tabel: sections).\nYaml example:\ntype: ci_postgresql_section\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties df (DataFrame):\n\nid: int64: id van de sectie\nsegmentid: int64: id van het segment waartoe de sectie behoort\nname: str: naam van de sectie\ngeometry: geom: geometrie (ligging) van de sectie (let op projectie altijd EPSG4326!)\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section_load_to_data(\n    output_config\n    df\n)\nSchrijft data voor dijkvakken de belasting naar Continu Inzicht database (tabel: data)\nYaml example:\ntype: ci_postgresql_section_load_to_data\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nunit_conversion_factor: 0.01\nArgs:\noutput_config (dict): configuratie opties\ndf (DataFrame):\n\nmeasurement_location_id: int64\ndate_time: datetime64[ns, UTC]\nvalue: float64\nvalue_type: str\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section_to_data(\n    output_config\n    df\n)\nSchrijft data naar Continu Inzicht database\n\n\noutput_config (dict):\n\n\n\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str):\npostgresql_password (str):\npostgresql_host (str):\npostgresql_port (str):\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str):\nschema (str):\n\n\n\n\npd.Dataframe\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_section_to_states(\n    output_config\n    df\n)\nSchrijft state naar Continu Inzicht database\n\n\noutput_config (dict):\n\n\n\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str):\npostgresql_password (str):\npostgresql_host (str):\npostgresql_port (str):\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str):\nschema (str):\n\n\n\n\npd.Dataframe\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_section.output_ci_postgresql_sectionfractions(\n    output_config\n    df\n)\nSchrijft (interpolatie)fracties van meetlocatie per sectie naar de Continu Inzicht database (tabel: sectionfractions).\nYaml example:\ntype: ci_postgresql_sectionfractions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties\ndf (DataFrame): - sectionid: int64 : id van de sectie - idup: int64 : id van het meetlocatie (measuringlocation), stroomopwaarst gelegen (indien van toepassing) - iddown: int64 : id van het meetlocatie (measuringlocation), stroomafwaarst gelegen (indien van toepassing) - fractionup: float64 : fractie van de belasting gebruikt voor interpolatie belasting bij sectie stroomopwaarst gelegen (indien van toepassing) - fractiondown: float64 : fractie van de belasting gebruikt voor interpolatie belasting bij sectie stroomafwaarst gelegen (indien van toepassing) - parameters: XXXXXX : OPTIONEEL lijst van (belasting)parameters (ROLF VRAGEN)\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht"
  },
  {
    "objectID": "reference/output_calculation.html",
    "href": "reference/output_calculation.html",
    "title": "output_calculation",
    "section": "",
    "text": "base.adapters.output.continu_inzicht_postgresql.output_calculation\nData adapters voor het schrijven naar de Continu Inzicht database\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput_ci_postgresql_to_calculation_end\n- Update de datetime in de Continu Inzicht database tabel moments\n\n\noutput_ci_postgresql_to_calculation_start\nUpdate de calculatietijd in de Continu Inzicht database tabel moments\n\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_calculation.output_ci_postgresql_to_calculation_end(\n    output_config\n    df\n)\n\nUpdate de datetime in de Continu Inzicht database tabel moments\nVerwijderd alle data waar calculating op False staat\nZet alle data waar calculating op True staat naar False\n\nYaml example:\n type: ci_postgresql_to_calculation_end\n database: \"continuinzicht\"\n schema: \"continuinzicht_demo_realtime\"\nArgs:\n * output_config (dict): configuratie opties\n * df (DataFrame): geen data nodig\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_calculation.output_ci_postgresql_to_calculation_start(\n    output_config\n    df\n)\nUpdate de calculatietijd in de Continu Inzicht database tabel moments\nYaml example:\ntype: ci_postgresql_to_calculation_start\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- moment_id: int64\n- calc_time: datetime64[ns, UTC]\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht"
  },
  {
    "objectID": "reference/output_calculation.html#functions",
    "href": "reference/output_calculation.html#functions",
    "title": "output_calculation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noutput_ci_postgresql_to_calculation_end\n- Update de datetime in de Continu Inzicht database tabel moments\n\n\noutput_ci_postgresql_to_calculation_start\nUpdate de calculatietijd in de Continu Inzicht database tabel moments\n\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_calculation.output_ci_postgresql_to_calculation_end(\n    output_config\n    df\n)\n\nUpdate de datetime in de Continu Inzicht database tabel moments\nVerwijderd alle data waar calculating op False staat\nZet alle data waar calculating op True staat naar False\n\nYaml example:\n type: ci_postgresql_to_calculation_end\n database: \"continuinzicht\"\n schema: \"continuinzicht_demo_realtime\"\nArgs:\n * output_config (dict): configuratie opties\n * df (DataFrame): geen data nodig\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_calculation.output_ci_postgresql_to_calculation_start(\n    output_config\n    df\n)\nUpdate de calculatietijd in de Continu Inzicht database tabel moments\nYaml example:\ntype: ci_postgresql_to_calculation_start\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- moment_id: int64\n- calc_time: datetime64[ns, UTC]\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht"
  },
  {
    "objectID": "reference/LoadsWaterinfo.html",
    "href": "reference/LoadsWaterinfo.html",
    "title": "LoadsWaterinfo",
    "section": "",
    "text": "loads.LoadsWaterinfo()\nBelastinggegevens ophalen van Rijkswaterstaat Waterinfo\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter voor het ophalen en opslaan van gegevens.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nDataframe met meetlocaties.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataframe met belastinggegevens.\n\n\nurl\nstr\nDe url van de Waterinfo API.\n\n\ninput_waterinfo_schema\nClassVar[dict[str, str]]\nHet schema van de invoer data meetlocaties.\n\n\n\n\n\n\nHiervoor wordt de url gebruikt: [https://waterinfo.rws.nl/#/publiek/waterhoogte](https://waterinfo.rws.nl/#/publiek/waterhoogte\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_dataframe\nMaak een pandas dataframe van de opgehaalde data uit Waterinfo\n\n\nget_maptype\nBepaalt welk schema moet worden gebruikt voor het ophalen van de belasting.\n\n\nget_value_by_observedhours\nbepaal welke range gebruikt moet worden voor het ophalen van de belasting\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Belasting Waterinfo functie.\n\n\n\n\n\nloads.LoadsWaterinfo.create_dataframe(\n    options\n    maptype_schema\n    measuringstation\n    json_data\n)\nMaak een pandas dataframe van de opgehaalde data uit Waterinfo\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOpties opgegeven in de yaml.\nrequired\n\n\nmaptype_schema\ndict\nGegevens van de maptype.\nrequired\n\n\nmeasuringstation\ndict\nGegevens van het meetstation.\nrequired\n\n\njson_data\ndict[str, Any]\nJSON data met opgehaalde belasting data.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nPandas dataframe geschikt voor uitvoer.\n\n\n\n\n\n\nHet dataframe bevat de volgende kolommen:\n\nMeetlocatie id (measurement_location_id)\nMeetlocatie code (measurement_location_code)\nMeetlocatie omschrijving/naam (measurement_location_description)\nParameter id overeenkomstig Aquo-standaard: ‘4724’ (parameter_id)\nParameter code overeenkomstig Aquo-standaard: ‘WATHTE’ (parameter_code)\nParameter omschrijving overeenkomstig Aquo-standaard: ‘Waterhoogte’ (parameter_description)\nEenheid (unit)\nDatum en tijd (date_time)\nWaarde (value)\nType waarde: meting of verwachting (value_type)\n\n\n\n\n\nloads.LoadsWaterinfo.get_maptype(maptype, global_variables)\nBepaalt welk schema moet worden gebruikt voor het ophalen van de belasting.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmaptype\nstr\nHet type kaart: - waterhoogte, - wind, - golfhoogte, - watertemperatuur, - luchttemperatuur, - astronomische-getij, - waterafvoer, - zouten\nrequired\n\n\nglobal_variables\ndict\nDe globale variabelen van de configuratie.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nstr\nDe query van het bereik als een string. Bijvoorbeeld: -48,0\n\n\n\n\n\n\n\nloads.LoadsWaterinfo.get_value_by_observedhours(\n    maptype_schema\n    observedhours_moments\n)\nbepaal welke range gebruikt moet worden voor het ophalen van de belasting\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmaptype_schema\ndict\nschema met mogelijke ranges. Voorbeeld: json     {\"observedhours\": 48, \"predictionhours\": 48, \"query\": \"-48,0\"},     {\"observedhours\": 6, \"predictionhours\": 3, \"query\": \"-6,0\"},     {\"observedhours\": 216, \"predictionhours\": 48, \"query\": \"-216,0\"},     {\"observedhours\": 672, \"predictionhours\": 0, \"query\": \"-672,0\"}\nrequired\n\n\nobservedhours_moments\nint\nhet laagste moment.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nde query van de range als string: str\nvoorbeeld: -48,0\n\n\nNone\nNone\nals er geen range gevonden kan worden\n\n\n\n\n\n\n\nloads.LoadsWaterinfo.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsWaterinfo.run(input, output)\nDe runner van de Belasting Waterinfo functie.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de dataadapter met invoergegevens.\nrequired\n\n\noutput\nstr\nNaam van de dataadapter om uitvoergegevens op te slaan.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nWanneer de belasting niet kan worden opgehaald. Wanneer moments niet aanwezig in global_variables (config) Wanneer de opgegeven parameter(s) komen niet voor in Waterinfo. Wanneer de opgegeven locatie niet voorkomt in Waterinfo"
  },
  {
    "objectID": "reference/LoadsWaterinfo.html#attributes",
    "href": "reference/LoadsWaterinfo.html#attributes",
    "title": "LoadsWaterinfo",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter voor het ophalen en opslaan van gegevens.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nDataframe met meetlocaties.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataframe met belastinggegevens.\n\n\nurl\nstr\nDe url van de Waterinfo API.\n\n\ninput_waterinfo_schema\nClassVar[dict[str, str]]\nHet schema van de invoer data meetlocaties."
  },
  {
    "objectID": "reference/LoadsWaterinfo.html#notes",
    "href": "reference/LoadsWaterinfo.html#notes",
    "title": "LoadsWaterinfo",
    "section": "",
    "text": "Hiervoor wordt de url gebruikt: [https://waterinfo.rws.nl/#/publiek/waterhoogte](https://waterinfo.rws.nl/#/publiek/waterhoogte"
  },
  {
    "objectID": "reference/LoadsWaterinfo.html#methods",
    "href": "reference/LoadsWaterinfo.html#methods",
    "title": "LoadsWaterinfo",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_dataframe\nMaak een pandas dataframe van de opgehaalde data uit Waterinfo\n\n\nget_maptype\nBepaalt welk schema moet worden gebruikt voor het ophalen van de belasting.\n\n\nget_value_by_observedhours\nbepaal welke range gebruikt moet worden voor het ophalen van de belasting\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Belasting Waterinfo functie.\n\n\n\n\n\nloads.LoadsWaterinfo.create_dataframe(\n    options\n    maptype_schema\n    measuringstation\n    json_data\n)\nMaak een pandas dataframe van de opgehaalde data uit Waterinfo\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOpties opgegeven in de yaml.\nrequired\n\n\nmaptype_schema\ndict\nGegevens van de maptype.\nrequired\n\n\nmeasuringstation\ndict\nGegevens van het meetstation.\nrequired\n\n\njson_data\ndict[str, Any]\nJSON data met opgehaalde belasting data.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nPandas dataframe geschikt voor uitvoer.\n\n\n\n\n\n\nHet dataframe bevat de volgende kolommen:\n\nMeetlocatie id (measurement_location_id)\nMeetlocatie code (measurement_location_code)\nMeetlocatie omschrijving/naam (measurement_location_description)\nParameter id overeenkomstig Aquo-standaard: ‘4724’ (parameter_id)\nParameter code overeenkomstig Aquo-standaard: ‘WATHTE’ (parameter_code)\nParameter omschrijving overeenkomstig Aquo-standaard: ‘Waterhoogte’ (parameter_description)\nEenheid (unit)\nDatum en tijd (date_time)\nWaarde (value)\nType waarde: meting of verwachting (value_type)\n\n\n\n\n\nloads.LoadsWaterinfo.get_maptype(maptype, global_variables)\nBepaalt welk schema moet worden gebruikt voor het ophalen van de belasting.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmaptype\nstr\nHet type kaart: - waterhoogte, - wind, - golfhoogte, - watertemperatuur, - luchttemperatuur, - astronomische-getij, - waterafvoer, - zouten\nrequired\n\n\nglobal_variables\ndict\nDe globale variabelen van de configuratie.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nstr\nDe query van het bereik als een string. Bijvoorbeeld: -48,0\n\n\n\n\n\n\n\nloads.LoadsWaterinfo.get_value_by_observedhours(\n    maptype_schema\n    observedhours_moments\n)\nbepaal welke range gebruikt moet worden voor het ophalen van de belasting\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmaptype_schema\ndict\nschema met mogelijke ranges. Voorbeeld: json     {\"observedhours\": 48, \"predictionhours\": 48, \"query\": \"-48,0\"},     {\"observedhours\": 6, \"predictionhours\": 3, \"query\": \"-6,0\"},     {\"observedhours\": 216, \"predictionhours\": 48, \"query\": \"-216,0\"},     {\"observedhours\": 672, \"predictionhours\": 0, \"query\": \"-672,0\"}\nrequired\n\n\nobservedhours_moments\nint\nhet laagste moment.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nde query van de range als string: str\nvoorbeeld: -48,0\n\n\nNone\nNone\nals er geen range gevonden kan worden\n\n\n\n\n\n\n\nloads.LoadsWaterinfo.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsWaterinfo.run(input, output)\nDe runner van de Belasting Waterinfo functie.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de dataadapter met invoergegevens.\nrequired\n\n\noutput\nstr\nNaam van de dataadapter om uitvoergegevens op te slaan.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nWanneer de belasting niet kan worden opgehaald. Wanneer moments niet aanwezig in global_variables (config) Wanneer de opgegeven parameter(s) komen niet voor in Waterinfo. Wanneer de opgegeven locatie niet voorkomt in Waterinfo"
  },
  {
    "objectID": "reference/LoadsMatroos.html",
    "href": "reference/LoadsMatroos.html",
    "title": "LoadsMatroos",
    "section": "",
    "text": "loads.LoadsMatroos()\nHaalt matroos tijdserie informatie op uit de Noos, Matroos of Vitaal server.\nDe Matroos informatie is beschikbaar op de volgende websites: https://noos.matroos.rws.nl/maps1d/\nMet de functie get_matroos_sources() kan je de beschikbare bronnen ophalen. Met de functie get_matroos_locations(source='...') kan je de bijbehorende beschikbare locaties ophalen.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nData adapter object for input and output data.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nInput dataframe containing measurement location codes.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput dataframe containing processed data.\n\n\nurl_retrieve_series_noos\nstr\nURL for retrieving series from Noos server.\n\n\nurl_retrieve_series_matroos\nstr\nURL for retrieving series from Matroos server.\n\n\nurl_retrieve_series_vitaal\nstr\nURL for retrieving series from Vitaal server.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_dataframe\nMaakt een dataframe met waardes van de rws water webservices\n\n\nformat_location_names\nNeemt een lijst met locatienamen en verwijdert spaties en maakt ze allemaal in kleine letters\n\n\ngenerate_url\nGeeft de benodigde URL terug om het verzoek naar de Noos-server te maken\n\n\nget_matroos_available_locations\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nVoert de functie uit om gegevens op te halen en te verwerken voor matroos gegevens.\n\n\n\n\n\nloads.LoadsMatroos.create_dataframe(\n    options\n    df_in\n    calc_time\n    json_data\n    global_variables\n)\nMaakt een dataframe met waardes van de rws water webservices\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nEen dictionary met opties uit de config\nrequired\n\n\ndf_in\npd.DataFrame\nHet invoerdataframe\nrequired\n\n\ncalc_time\ndatetime\nDe huidige tijd\nrequired\n\n\njson_data\nlist\nEen lijst met ogehaalde JSON data\nrequired\n\n\nglobal_variables\ndict\nEen dictionary met globale variabelen\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndataframe\npd.Dataframe\nPandas dataframe met de voor uitvoer\n\n\n\n\n\n\n\nloads.LoadsMatroos.format_location_names(location_names)\nNeemt een lijst met locatienamen en verwijdert spaties en maakt ze allemaal in kleine letters\n\n\n\nloads.LoadsMatroos.generate_url(options, global_variables)\nGeeft de benodigde URL terug om het verzoek naar de Noos-server te maken\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOpties die door de gebruiker zijn opgegeven, in dit geval is ‘source’ het belangrijkst\nrequired\n\n\nglobal_variables\ndict\nGlobale variabelen die nodig zijn om de URL te genereren\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nurl\nstr\nDe gegenereerde URL voor het verzoek aan de Noos-server\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de ‘website’ niet is opgegeven in de opties Als de ‘website’ niet overeenkomt met de opties ‘noos’, ‘matroos’ of ‘vitaal’ Als de ‘website’ ‘matroos’ of ‘vitaal’ is en de gebruiker geen gebruikersnaam en wachtwoord heeft opgegeven\n\n\n\n\n\n\n\nloads.LoadsMatroos.get_matroos_available_locations(\n    df_in\n    options\n    endpoint_model\n)\n\n\n\nloads.LoadsMatroos.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsMatroos.run(input, output)\nVoert de functie uit om gegevens op te halen en te verwerken voor matroos gegevens.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de dataadapter met invoergegevens.\nrequired\n\n\noutput\nstr\nNaam van de dataadapter om uitvoergegevens op te slaan.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de ‘LoadsMatroos’ sectie niet aanwezig is in de global_variables (config). Als de ‘measurement_location_code’ ontbreekt in de inputdata. Als het gegeven model niet wordt herkend. Als de locaties niet worden gevonden.\n\n\n\nConnectionError\nAls er geen resultaten in de data zitten. Als de verbinding mislukt."
  },
  {
    "objectID": "reference/LoadsMatroos.html#attributes",
    "href": "reference/LoadsMatroos.html#attributes",
    "title": "LoadsMatroos",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nData adapter object for input and output data.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nInput dataframe containing measurement location codes.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput dataframe containing processed data.\n\n\nurl_retrieve_series_noos\nstr\nURL for retrieving series from Noos server.\n\n\nurl_retrieve_series_matroos\nstr\nURL for retrieving series from Matroos server.\n\n\nurl_retrieve_series_vitaal\nstr\nURL for retrieving series from Vitaal server."
  },
  {
    "objectID": "reference/LoadsMatroos.html#methods",
    "href": "reference/LoadsMatroos.html#methods",
    "title": "LoadsMatroos",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_dataframe\nMaakt een dataframe met waardes van de rws water webservices\n\n\nformat_location_names\nNeemt een lijst met locatienamen en verwijdert spaties en maakt ze allemaal in kleine letters\n\n\ngenerate_url\nGeeft de benodigde URL terug om het verzoek naar de Noos-server te maken\n\n\nget_matroos_available_locations\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nVoert de functie uit om gegevens op te halen en te verwerken voor matroos gegevens.\n\n\n\n\n\nloads.LoadsMatroos.create_dataframe(\n    options\n    df_in\n    calc_time\n    json_data\n    global_variables\n)\nMaakt een dataframe met waardes van de rws water webservices\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nEen dictionary met opties uit de config\nrequired\n\n\ndf_in\npd.DataFrame\nHet invoerdataframe\nrequired\n\n\ncalc_time\ndatetime\nDe huidige tijd\nrequired\n\n\njson_data\nlist\nEen lijst met ogehaalde JSON data\nrequired\n\n\nglobal_variables\ndict\nEen dictionary met globale variabelen\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndataframe\npd.Dataframe\nPandas dataframe met de voor uitvoer\n\n\n\n\n\n\n\nloads.LoadsMatroos.format_location_names(location_names)\nNeemt een lijst met locatienamen en verwijdert spaties en maakt ze allemaal in kleine letters\n\n\n\nloads.LoadsMatroos.generate_url(options, global_variables)\nGeeft de benodigde URL terug om het verzoek naar de Noos-server te maken\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOpties die door de gebruiker zijn opgegeven, in dit geval is ‘source’ het belangrijkst\nrequired\n\n\nglobal_variables\ndict\nGlobale variabelen die nodig zijn om de URL te genereren\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nurl\nstr\nDe gegenereerde URL voor het verzoek aan de Noos-server\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de ‘website’ niet is opgegeven in de opties Als de ‘website’ niet overeenkomt met de opties ‘noos’, ‘matroos’ of ‘vitaal’ Als de ‘website’ ‘matroos’ of ‘vitaal’ is en de gebruiker geen gebruikersnaam en wachtwoord heeft opgegeven\n\n\n\n\n\n\n\nloads.LoadsMatroos.get_matroos_available_locations(\n    df_in\n    options\n    endpoint_model\n)\n\n\n\nloads.LoadsMatroos.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsMatroos.run(input, output)\nVoert de functie uit om gegevens op te halen en te verwerken voor matroos gegevens.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de dataadapter met invoergegevens.\nrequired\n\n\noutput\nstr\nNaam van de dataadapter om uitvoergegevens op te slaan.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de ‘LoadsMatroos’ sectie niet aanwezig is in de global_variables (config). Als de ‘measurement_location_code’ ontbreekt in de inputdata. Als het gegeven model niet wordt herkend. Als de locaties niet worden gevonden.\n\n\n\nConnectionError\nAls er geen resultaten in de data zitten. Als de verbinding mislukt."
  },
  {
    "objectID": "reference/LoadsClassify.html",
    "href": "reference/LoadsClassify.html",
    "title": "LoadsClassify",
    "section": "",
    "text": "loads.LoadsClassify()\nMet deze functie worden de waterstanden met opgegeven grenzen geclassificeerd.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die wordt gebruikt om de data in te laden en op te slaan.\n\n\ndf_in_thresholds\nOptional[pd.DataFrame] | None\nDataframe met drempelwaarden per meetlocatie.\n\n\ndf_in_loads\nOptional[pd.DataFrame] | None\nDataframe met belasting per moment per meetlocaties.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataframe met geclassificeerde waterstanden voor opgegeven momenten.\n\n\ninput_schema_thresholds\nClassVar[dict[str, str]]\nSchema voor drempelwaarden per meetlocatie.\n\n\ninput_schema_loads\nClassVar[dict[str, str | list[str]]]\nSchema voor belasting per moment per meetlocaties.\n\n\n\n\n\n\nInput schema’s\ninput_schema_thresholds: schema voor drempelwaarden per meetlocatie\n\nmeasurement_location_id: int64 : id van het meetstation\nlower_boundary: float64 : ondergrens van de drempelwaarde\nupper_boundary: float64 : bovengrens van de drempelwaarde\ncolor: str : kleurcode voor de drempelwaarde\nlabel: str : label voor de drempelwaarde\nunit: str : eenheid van de drempelwaarde\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Loads Classify.\n\n\n\n\n\nloads.LoadsClassify.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsClassify.run(input, output)\nDe runner van de Loads Classify.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst met namen van de data adapter voor de drempelwaarde en belasting per meetlocatie.\nrequired\n\n\noutput\nstr\nData adapter voor output van de koppeling van de maatgevende meetlocaties per dijkvak\nrequired"
  },
  {
    "objectID": "reference/LoadsClassify.html#attributes",
    "href": "reference/LoadsClassify.html#attributes",
    "title": "LoadsClassify",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die wordt gebruikt om de data in te laden en op te slaan.\n\n\ndf_in_thresholds\nOptional[pd.DataFrame] | None\nDataframe met drempelwaarden per meetlocatie.\n\n\ndf_in_loads\nOptional[pd.DataFrame] | None\nDataframe met belasting per moment per meetlocaties.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataframe met geclassificeerde waterstanden voor opgegeven momenten.\n\n\ninput_schema_thresholds\nClassVar[dict[str, str]]\nSchema voor drempelwaarden per meetlocatie.\n\n\ninput_schema_loads\nClassVar[dict[str, str | list[str]]]\nSchema voor belasting per moment per meetlocaties."
  },
  {
    "objectID": "reference/LoadsClassify.html#notes",
    "href": "reference/LoadsClassify.html#notes",
    "title": "LoadsClassify",
    "section": "",
    "text": "Input schema’s\ninput_schema_thresholds: schema voor drempelwaarden per meetlocatie\n\nmeasurement_location_id: int64 : id van het meetstation\nlower_boundary: float64 : ondergrens van de drempelwaarde\nupper_boundary: float64 : bovengrens van de drempelwaarde\ncolor: str : kleurcode voor de drempelwaarde\nlabel: str : label voor de drempelwaarde\nunit: str : eenheid van de drempelwaarde\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)"
  },
  {
    "objectID": "reference/LoadsClassify.html#methods",
    "href": "reference/LoadsClassify.html#methods",
    "title": "LoadsClassify",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Loads Classify.\n\n\n\n\n\nloads.LoadsClassify.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsClassify.run(input, output)\nDe runner van de Loads Classify.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst met namen van de data adapter voor de drempelwaarde en belasting per meetlocatie.\nrequired\n\n\noutput\nstr\nData adapter voor output van de koppeling van de maatgevende meetlocaties per dijkvak\nrequired"
  },
  {
    "objectID": "reference/IntegrateFragilityCurveMultiple.html",
    "href": "reference/IntegrateFragilityCurveMultiple.html",
    "title": "IntegrateFragilityCurveMultiple",
    "section": "",
    "text": "fragility_curves.IntegrateFragilityCurveMultiple()\nIntegreert een waterniveau overschrijdingsfrequentielijn met een fragility curve voor reeks aan secties\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_exceedance_frequency\nOptional[pd.DataFrame] | None\nDataFrame containing exceedance frequency data.\n\n\ndf_fragility_curve\nOptional[pd.DataFrame] | None\nDataFrame containing fragility curve data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the integrated fragility curve.\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt\n\n\n\n\n\n\nBij het combineren van de fragility curves met overschrijdingsfrequentielijn moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen worden ingesteld:\n\nrefine_step_size: De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncalculate_integration\n\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve voor verschillende vakken\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.calculate_integration(\n    exceedance_frequency_curve\n    fragility_curve\n    refine_step_size\n)\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.run(input, output)\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve voor verschillende vakken\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van data adapters met exceedance_frequency en fragility_curve\nrequired\n\n\noutput\nstr\nData adapter voor de output\nrequired\n\n\n\n\n\n\nexceedance_frequency bevat een hydraulische belasting met overschrijdingsfrequentie statistiek, beide floats:\n\nhydraulicload, hydralische belastingen\nprobability_exceedance, reek van overschrijdingsfrequenties\n\nfragility_curve bevat een hydraulische belasting met conditionele faalkansen, beide floats:\n\nhydraulicload, hydralische belastingen\nfailure_probabilities, conditionele faalkansen\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de input dataframes niet voldoen aan de verwachte schema’s."
  },
  {
    "objectID": "reference/IntegrateFragilityCurveMultiple.html#attributes",
    "href": "reference/IntegrateFragilityCurveMultiple.html#attributes",
    "title": "IntegrateFragilityCurveMultiple",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_exceedance_frequency\nOptional[pd.DataFrame] | None\nDataFrame containing exceedance frequency data.\n\n\ndf_fragility_curve\nOptional[pd.DataFrame] | None\nDataFrame containing fragility curve data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the integrated fragility curve.\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt"
  },
  {
    "objectID": "reference/IntegrateFragilityCurveMultiple.html#notes",
    "href": "reference/IntegrateFragilityCurveMultiple.html#notes",
    "title": "IntegrateFragilityCurveMultiple",
    "section": "",
    "text": "Bij het combineren van de fragility curves met overschrijdingsfrequentielijn moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen worden ingesteld:\n\nrefine_step_size: De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05."
  },
  {
    "objectID": "reference/IntegrateFragilityCurveMultiple.html#methods",
    "href": "reference/IntegrateFragilityCurveMultiple.html#methods",
    "title": "IntegrateFragilityCurveMultiple",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncalculate_integration\n\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve voor verschillende vakken\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.calculate_integration(\n    exceedance_frequency_curve\n    fragility_curve\n    refine_step_size\n)\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.IntegrateFragilityCurveMultiple.run(input, output)\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve voor verschillende vakken\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van data adapters met exceedance_frequency en fragility_curve\nrequired\n\n\noutput\nstr\nData adapter voor de output\nrequired\n\n\n\n\n\n\nexceedance_frequency bevat een hydraulische belasting met overschrijdingsfrequentie statistiek, beide floats:\n\nhydraulicload, hydralische belastingen\nprobability_exceedance, reek van overschrijdingsfrequenties\n\nfragility_curve bevat een hydraulische belasting met conditionele faalkansen, beide floats:\n\nhydraulicload, hydralische belastingen\nfailure_probabilities, conditionele faalkansen\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de input dataframes niet voldoen aan de verwachte schema’s."
  },
  {
    "objectID": "reference/InspectionsToDatabase.html",
    "href": "reference/InspectionsToDatabase.html",
    "title": "InspectionsToDatabase",
    "section": "",
    "text": "inspections.InspectionsToDatabase()\nCombineert de inspectieresultaten met de opmaak en slaat deze op in de database.\nMet deze functie wordt de gehele geojson onderdeel van 1 tabel in de database. Bij grote lagen is het aan te raden om deze als aparte tabel op te slaan, de aanpak voor het opslaan van grotere lagen in de database is te vinden onder modules inspectieresultaten in de documentatie.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_in_inspections\nOptional[pd.DataFrame | gpd.GeoDataFrame] | None\nInput DataFrame met inspectieresultaten.\n\n\ndf_in_legend\nOptional[pd.DataFrame] | None\nDataFrame met standaard opmaak informatie.\n\n\ndf_in_layers\nOptional[pd.DataFrame] | None\nDataFrame met de lagen informatie.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the filtered DataFrame.\n\n\nlegend_schema\nClassVar[dict[str, str]]\nSchema DataFrame met de opmaak informatie\n\n\nlayer_schema\nClassVar[dict[str, str]]\nSchema DataFrame met de layer informatie\n\n\n\n\n\n\nDefault waarden te overschrijven in de global variables:\n\nmax_rows = 10, Maximale toegestane rijen geodata in een database veld\nindex = 0, Index van df_in_layers waarin de geodata wordt opgeslagen\n\nDe layers tabel geeft de mogelijkheid om de meer configuratie door te geven aan de viewer. Als deze niet aanwezig is, worden standaard opties gebruikt. Hier moet minimaal de volgende kolommen in zitten:\n\ngroup_name: naam van de groep in de viewer waar de layer toegevoegd wordt.\nlayer_name: naam van de laag in de viewer.\nlayer_visible: of de laag direct zichtbaar is in de viewer (true), of dat hij moet worden aangezet door de gebruiker (false).\n\nOptionele kolommen voor de df_in_layers zijn:\n\nlayer_type: type van de laag, wordt standaard gevuld als geojson.\nlayer_tabel: naam van een overige tabel in de database die met geodaata is gevuld.\nlayer_wms_url: str URL van een WMS service die gebruikt kan worden voor de laag. Bij het inladen worden de volgende lagen opgehaald:\n\nlayer_wms_layer: str\nlayer_wms_style: str\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_default_styling\n\n\n\nget_possible_styling\nHaal de mogelijke kolommen op voor de opmaak.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRun het combineren van inspectieresultaten met opmaak voor het opslaan in de database.\n\n\nset_default_styling\n\n\n\n\n\n\ninspections.InspectionsToDatabase.get_default_styling()\n\n\n\ninspections.InspectionsToDatabase.get_possible_styling(\n    type=None\n    dict_output=False\n)\nHaal de mogelijke kolommen op voor de opmaak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntype\nstr | None\nType van de laag, indien None worden alle kolommen opgehaald. Mogelijke waardes zijn: Polyline, Polygon, Marker, CircleMarker\nNone\n\n\ndict_output\nbool\nAls True, wordt een dictionary met de kolommen en hun type terug gegeven. Anders wordt een lijst met de kolommen terug gegeven.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlist[str] | dict[str, dict]\nEen lijst met de mogelijke kolommen of een dictionary met de kolommen en hun type.\n\n\n\n\n\n\nDe standaard waardes & mogelijke opties zijn:\n\n\n\nPolyline\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van lijn\n\n\nweight\nnumber\n3\nbreedte lijn\n\n\nopacity\nnumber\n1\ntransparantie van lijn\n\n\ndashArray\nstring\nnull\narray voor dashed lijn\n\n\n\n\n\n\nPolygon\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\n\n\n\n\nMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nopacity\nnumber\n1\ntransparantie van marker\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nSVGname\nstring\nnull\nnaam van de marker\n\n\n\n\n\n\nCircleMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\nradius\nnumber\n10\ngroote van circle\n\n\n\nDefault waardes worden hier getoond, maar deze hebben geen invloed op de output. Om default aan te passen gebruik set_default_styling(df).\n\n\n\n\ninspections.InspectionsToDatabase.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\ninspections.InspectionsToDatabase.run(input, output)\nRun het combineren van inspectieresultaten met opmaak voor het opslaan in de database.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nNaam van de Data Adapters met inspectieresultaten, opmaak en lagen (in die volgorde). Resultaten en opmaak zijn verplicht, lagen zijn optioneel. Indien er geen informatie is meegegeven, worden standaard waardes gebruikt.\nrequired\n\n\noutput\nstr\nNaam van Data adapter voor de output\nrequired\n\n\n\n\n\n\n…\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls er meer dan max_rows rijen zijn in de inspectieresultaten.\n\n\n\n\n\n\n\ninspections.InspectionsToDatabase.set_default_styling()"
  },
  {
    "objectID": "reference/InspectionsToDatabase.html#attributes",
    "href": "reference/InspectionsToDatabase.html#attributes",
    "title": "InspectionsToDatabase",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_in_inspections\nOptional[pd.DataFrame | gpd.GeoDataFrame] | None\nInput DataFrame met inspectieresultaten.\n\n\ndf_in_legend\nOptional[pd.DataFrame] | None\nDataFrame met standaard opmaak informatie.\n\n\ndf_in_layers\nOptional[pd.DataFrame] | None\nDataFrame met de lagen informatie.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the filtered DataFrame.\n\n\nlegend_schema\nClassVar[dict[str, str]]\nSchema DataFrame met de opmaak informatie\n\n\nlayer_schema\nClassVar[dict[str, str]]\nSchema DataFrame met de layer informatie"
  },
  {
    "objectID": "reference/InspectionsToDatabase.html#notes",
    "href": "reference/InspectionsToDatabase.html#notes",
    "title": "InspectionsToDatabase",
    "section": "",
    "text": "Default waarden te overschrijven in de global variables:\n\nmax_rows = 10, Maximale toegestane rijen geodata in een database veld\nindex = 0, Index van df_in_layers waarin de geodata wordt opgeslagen\n\nDe layers tabel geeft de mogelijkheid om de meer configuratie door te geven aan de viewer. Als deze niet aanwezig is, worden standaard opties gebruikt. Hier moet minimaal de volgende kolommen in zitten:\n\ngroup_name: naam van de groep in de viewer waar de layer toegevoegd wordt.\nlayer_name: naam van de laag in de viewer.\nlayer_visible: of de laag direct zichtbaar is in de viewer (true), of dat hij moet worden aangezet door de gebruiker (false).\n\nOptionele kolommen voor de df_in_layers zijn:\n\nlayer_type: type van de laag, wordt standaard gevuld als geojson.\nlayer_tabel: naam van een overige tabel in de database die met geodaata is gevuld.\nlayer_wms_url: str URL van een WMS service die gebruikt kan worden voor de laag. Bij het inladen worden de volgende lagen opgehaald:\n\nlayer_wms_layer: str\nlayer_wms_style: str"
  },
  {
    "objectID": "reference/InspectionsToDatabase.html#methods",
    "href": "reference/InspectionsToDatabase.html#methods",
    "title": "InspectionsToDatabase",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_default_styling\n\n\n\nget_possible_styling\nHaal de mogelijke kolommen op voor de opmaak.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRun het combineren van inspectieresultaten met opmaak voor het opslaan in de database.\n\n\nset_default_styling\n\n\n\n\n\n\ninspections.InspectionsToDatabase.get_default_styling()\n\n\n\ninspections.InspectionsToDatabase.get_possible_styling(\n    type=None\n    dict_output=False\n)\nHaal de mogelijke kolommen op voor de opmaak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntype\nstr | None\nType van de laag, indien None worden alle kolommen opgehaald. Mogelijke waardes zijn: Polyline, Polygon, Marker, CircleMarker\nNone\n\n\ndict_output\nbool\nAls True, wordt een dictionary met de kolommen en hun type terug gegeven. Anders wordt een lijst met de kolommen terug gegeven.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlist[str] | dict[str, dict]\nEen lijst met de mogelijke kolommen of een dictionary met de kolommen en hun type.\n\n\n\n\n\n\nDe standaard waardes & mogelijke opties zijn:\n\n\n\nPolyline\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van lijn\n\n\nweight\nnumber\n3\nbreedte lijn\n\n\nopacity\nnumber\n1\ntransparantie van lijn\n\n\ndashArray\nstring\nnull\narray voor dashed lijn\n\n\n\n\n\n\nPolygon\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\n\n\n\n\nMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nopacity\nnumber\n1\ntransparantie van marker\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nSVGname\nstring\nnull\nnaam van de marker\n\n\n\n\n\n\nCircleMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\nradius\nnumber\n10\ngroote van circle\n\n\n\nDefault waardes worden hier getoond, maar deze hebben geen invloed op de output. Om default aan te passen gebruik set_default_styling(df).\n\n\n\n\ninspections.InspectionsToDatabase.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\ninspections.InspectionsToDatabase.run(input, output)\nRun het combineren van inspectieresultaten met opmaak voor het opslaan in de database.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nNaam van de Data Adapters met inspectieresultaten, opmaak en lagen (in die volgorde). Resultaten en opmaak zijn verplicht, lagen zijn optioneel. Indien er geen informatie is meegegeven, worden standaard waardes gebruikt.\nrequired\n\n\noutput\nstr\nNaam van Data adapter voor de output\nrequired\n\n\n\n\n\n\n…\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls er meer dan max_rows rijen zijn in de inspectieresultaten.\n\n\n\n\n\n\n\ninspections.InspectionsToDatabase.set_default_styling()"
  },
  {
    "objectID": "reference/input_measuringstation.html",
    "href": "reference/input_measuringstation.html",
    "title": "input_measuringstation",
    "section": "",
    "text": "base.adapters.input.continu_inzicht_postgresql.input_measuringstation\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\n\n\n\nName\nDescription\n\n\n\n\ninput_ci_postgresql_from_conditions\nHaalt klassegrenzen op uit een Continu Inzicht database.\n\n\ninput_ci_postgresql_from_measuringstations\nHaalt meetstations op uit een continu database.\n\n\ninput_ci_postgresql_from_waterlevels\nHaalt belasting op uit de Continu Inzicht database voor het WhatIf scenario (tabel: waterstanden).\n\n\ninput_ci_postgresql_measuringstation_data_table\nHaalt tijdreeks van belasting per meetstation op uit een Continu Inzicht database.\n\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_from_conditions(\n    input_config\n)\nHaalt klassegrenzen op uit een Continu Inzicht database.\nYAML voorbeeld:\ntype: ci_postgresql_from_conditions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nlower_boundary: float64 : ondergrens van de klassegrens\nupper_boundary: float64 : bovengrens van de klassegrens\ncolor: str : kleur van de klassegrens\nlabel: str : legendanaam van de klassegrens\nunit: str : unit van de klassegrens\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_from_measuringstations(\n    input_config\n)\nHaalt meetstations op uit een continu database.\nYaml example:\ntype: ci_postgresql_from_measuringstations\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nsource: \"waterinfo\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\nsource (str): source (veld) waar de meetstations aan gekoppeld zijn.\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nmeasurement_location_description: str : naam van het meetstation\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_from_waterlevels(\n    input_config\n)\nHaalt belasting op uit de Continu Inzicht database voor het WhatIf scenario (tabel: waterstanden).\nYAML voorbeeld:\ntype: ci_postgresql_from_waterlevels\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nmeasurement_location_description: str : naam van het meetstation\nparameter_id: int64 : id van de parameter\nparameter_code: str : code van de parameter\nparameter_description: str : omschrijving van de parameter\nunit: str : unit van de parameter\ndate_time: datetime64 : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_measuringstation_data_table(\n    input_config\n)\nHaalt tijdreeks van belasting per meetstation op uit een Continu Inzicht database.\nYAML voorbeeld:\ntype: ci_postgresql_measuringstation_data_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nmeasurement_location_description: str : naam van het meetstation\nparameter_id: int64 : id van de parameter\nparameter_code: str : code van de parameter\nparameter_description: str : omschrijving van de parameter\nunit: str : unit van de parameter\ndate_time: datetime64 : datum/ tijd van het tijdreeksitem\nvalue: float64 : waarde van het tijdreeksitem\nvalue_type: str : type waarde van het tijdreeksitem (meting of verwacht)"
  },
  {
    "objectID": "reference/input_measuringstation.html#functions",
    "href": "reference/input_measuringstation.html#functions",
    "title": "input_measuringstation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninput_ci_postgresql_from_conditions\nHaalt klassegrenzen op uit een Continu Inzicht database.\n\n\ninput_ci_postgresql_from_measuringstations\nHaalt meetstations op uit een continu database.\n\n\ninput_ci_postgresql_from_waterlevels\nHaalt belasting op uit de Continu Inzicht database voor het WhatIf scenario (tabel: waterstanden).\n\n\ninput_ci_postgresql_measuringstation_data_table\nHaalt tijdreeks van belasting per meetstation op uit een Continu Inzicht database.\n\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_from_conditions(\n    input_config\n)\nHaalt klassegrenzen op uit een Continu Inzicht database.\nYAML voorbeeld:\ntype: ci_postgresql_from_conditions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nlower_boundary: float64 : ondergrens van de klassegrens\nupper_boundary: float64 : bovengrens van de klassegrens\ncolor: str : kleur van de klassegrens\nlabel: str : legendanaam van de klassegrens\nunit: str : unit van de klassegrens\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_from_measuringstations(\n    input_config\n)\nHaalt meetstations op uit een continu database.\nYaml example:\ntype: ci_postgresql_from_measuringstations\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nsource: \"waterinfo\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\nsource (str): source (veld) waar de meetstations aan gekoppeld zijn.\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nmeasurement_location_description: str : naam van het meetstation\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_from_waterlevels(\n    input_config\n)\nHaalt belasting op uit de Continu Inzicht database voor het WhatIf scenario (tabel: waterstanden).\nYAML voorbeeld:\ntype: ci_postgresql_from_waterlevels\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nmeasurement_location_description: str : naam van het meetstation\nparameter_id: int64 : id van de parameter\nparameter_code: str : code van de parameter\nparameter_description: str : omschrijving van de parameter\nunit: str : unit van de parameter\ndate_time: datetime64 : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_measuringstation.input_ci_postgresql_measuringstation_data_table(\n    input_config\n)\nHaalt tijdreeks van belasting per meetstation op uit een Continu Inzicht database.\nYAML voorbeeld:\ntype: ci_postgresql_measuringstation_data_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nmeasurement_location_id: int64 : id van het meetstation\nmeasurement_location_code: str : code van het meetstation\nmeasurement_location_description: str : naam van het meetstation\nparameter_id: int64 : id van de parameter\nparameter_code: str : code van de parameter\nparameter_description: str : omschrijving van de parameter\nunit: str : unit van de parameter\ndate_time: datetime64 : datum/ tijd van het tijdreeksitem\nvalue: float64 : waarde van het tijdreeksitem\nvalue_type: str : type waarde van het tijdreeksitem (meting of verwacht)"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "Basis functionaliteit waar andere functies op verder bouwen\n\n\n\nConfig\nBasisfunctie om de configuratie in te laden.\n\n\nDataAdapter\nBasis DataAdapter\n\n\nproof_of_concept.example_module\n\n\n\nFragilityCurve\nClass met een aantal gemakkelijke methoden om fragility curves\n\n\n\n\n\n\nFuncties die belastingen inladen, classificeren of toekennen.\n\n\n\nLoadsCIWhatIf\nMet deze functie worden belasting opgehaald en weggeschreven.\n\n\nLoadsClassify\nMet deze functie worden de waterstanden met opgegeven grenzen geclassificeerd.\n\n\nLoadsFews\nMet deze functie worden gegevens uit de opgegeven FEWS omgeving opgehaald via REST.\n\n\nget_fews_locations\nHaal voor FEWS de locaties op voor de opgegeven parameters.\n\n\nget_fews_thresholds\nHaal voor FEWS de thresholds op voor de opgegeven parameter en locatie.\n\n\nLoadsMatroos\nHaalt matroos tijdserie informatie op uit de Noos, Matroos of Vitaal server.\n\n\nget_matroos_locations\nHaal alle matroos locaties op, indien gewenst ook bron en parameter.\n\n\nget_matroos_locations_map\nHaal alle matroos locaties op en maak een folium map.\n\n\nLoadsWaterwebservicesRWS\nBelastinggegevens ophalen van rijkswaterstaat waterwebservices\n\n\nget_rws_webservices_locations\nHaal locaties op die bekend zijn bij de RWS webservice.\n\n\nLoadsToMoments\nMet deze klasse kunnen waterstandsgegevens worden omgezet naar bepaalde momenten.\n\n\nLoadsWaterinfo\nBelastinggegevens ophalen van Rijkswaterstaat Waterinfo\n\n\nget_waterinfo_locations\nHaal voor Waterinfo de locaties op voor de opgegeven parameter.\n\n\nget_waterinfo_thresholds\nHaal voor Waterinfo de thresholds op voor de opgegegeven parameter.\n\n\n\n\n\n\nFuncties die betrekking hebben op dijkvakken\n\n\n\nSectionsLoads\nBepaal de belasting op een dijkvak gegeven een belasting\n\n\nSectionsCriticalFailureprobability\nBepaal de maatgevende faalkans van een dijkvak gegeven de technische faalkans, maatregel en beheerdersoordeel.\n\n\nSectionsTechnicalFailureprobability\nBepaal de technische faalkans van een dijkvak\n\n\nSectionsMeasureFailureprobability\nBepaal de faalkans door een maatregel van een dijkvak\n\n\nSectionsClassify\nBepaal de status van een dijkvak gegeven de faalkans en grenswaardes.\n\n\n\n\n\n\nFuncties voor het berekenen en aanpassen van Fragility curve\n\n\n\nFragilityCurveOvertopping\nMaakt een enkele fragility curve voor golf overslag.\n\n\nFragilityCurveOvertoppingMultiple\nMaakt een set van fragility curves voor golfoverslag voor een dijkvak.\n\n\nShiftFragilityCurveOvertopping\nVerschuift de fragility curve met een gegeven effect\n\n\nChangeCrestHeightFragilityCurveOvertopping\nVerschuift de kruinhoogte met het gegeven effect en berekent de fragility curve\n\n\nFragilityCurvePipingFixedWaterlevel\nMaakt een enkele fragility curve voor piping met een gegeven waterstand.\n\n\nFragilityCurvePipingMultiple\nMaakt een set van fragility curves voor piping voor een dijkvak.\n\n\nCombineFragilityCurvesIndependent\nCombineer meerdere fragility curves onafhankelijk tot een enkele fragility curve.\n\n\nCombineFragilityCurvesDependent\nCombineer meerdere fragility curves afhankelijk tot een enkele fragility curves.\n\n\nCombineFragilityCurvesWeightedSum\nCombineer meerdere fragility curves met een gewogen som tot een enkele fragility curve.\n\n\nIntegrateFragilityCurve\nIntegreert een waterniveau overschrijdingsfrequentielijn met een fragility curve\n\n\nIntegrateFragilityCurveMultiple\nIntegreert een waterniveau overschrijdingsfrequentielijn met een fragility curve voor reeks aan secties\n\n\n\n\n\n\nInvoer, verwerken en tonen van inspectieresultaten\n\n\n\nFilter\nFiltert een DataFrame aan de hand van de opgegeven configuratie.\n\n\nInspectionsToDatabase\nCombineert de inspectieresultaten met de opmaak en slaat deze op in de database.\n\n\nClassifyInspections\nClassificeert inspectieresultaten om weer te geven in de viewer.\n\n\n\n\n\n\nInvoer adapters voor Continu Inzicht meetstations/ dijkvak\n\n\n\ninput_measuringstation\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\ninput_section\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\ninput_fragilitycurve\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\n\n\n\n\nUitvoer adapters voor Continu Inzicht meetstations/ dijkvak\n\n\n\noutput_measuringstation\nData adapters voor het schrijven naar de Continu Inzicht database\n\n\noutput_section\nData adapters voor het schrijven naar de Continu Inzicht database\n\n\noutput_calculation\nData adapters voor het schrijven naar de Continu Inzicht database",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#basis",
    "href": "reference/index.html#basis",
    "title": "API Reference",
    "section": "",
    "text": "Basis functionaliteit waar andere functies op verder bouwen\n\n\n\nConfig\nBasisfunctie om de configuratie in te laden.\n\n\nDataAdapter\nBasis DataAdapter\n\n\nproof_of_concept.example_module\n\n\n\nFragilityCurve\nClass met een aantal gemakkelijke methoden om fragility curves",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#belastingen",
    "href": "reference/index.html#belastingen",
    "title": "API Reference",
    "section": "",
    "text": "Functies die belastingen inladen, classificeren of toekennen.\n\n\n\nLoadsCIWhatIf\nMet deze functie worden belasting opgehaald en weggeschreven.\n\n\nLoadsClassify\nMet deze functie worden de waterstanden met opgegeven grenzen geclassificeerd.\n\n\nLoadsFews\nMet deze functie worden gegevens uit de opgegeven FEWS omgeving opgehaald via REST.\n\n\nget_fews_locations\nHaal voor FEWS de locaties op voor de opgegeven parameters.\n\n\nget_fews_thresholds\nHaal voor FEWS de thresholds op voor de opgegeven parameter en locatie.\n\n\nLoadsMatroos\nHaalt matroos tijdserie informatie op uit de Noos, Matroos of Vitaal server.\n\n\nget_matroos_locations\nHaal alle matroos locaties op, indien gewenst ook bron en parameter.\n\n\nget_matroos_locations_map\nHaal alle matroos locaties op en maak een folium map.\n\n\nLoadsWaterwebservicesRWS\nBelastinggegevens ophalen van rijkswaterstaat waterwebservices\n\n\nget_rws_webservices_locations\nHaal locaties op die bekend zijn bij de RWS webservice.\n\n\nLoadsToMoments\nMet deze klasse kunnen waterstandsgegevens worden omgezet naar bepaalde momenten.\n\n\nLoadsWaterinfo\nBelastinggegevens ophalen van Rijkswaterstaat Waterinfo\n\n\nget_waterinfo_locations\nHaal voor Waterinfo de locaties op voor de opgegeven parameter.\n\n\nget_waterinfo_thresholds\nHaal voor Waterinfo de thresholds op voor de opgegegeven parameter.",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#dijkvak",
    "href": "reference/index.html#dijkvak",
    "title": "API Reference",
    "section": "",
    "text": "Functies die betrekking hebben op dijkvakken\n\n\n\nSectionsLoads\nBepaal de belasting op een dijkvak gegeven een belasting\n\n\nSectionsCriticalFailureprobability\nBepaal de maatgevende faalkans van een dijkvak gegeven de technische faalkans, maatregel en beheerdersoordeel.\n\n\nSectionsTechnicalFailureprobability\nBepaal de technische faalkans van een dijkvak\n\n\nSectionsMeasureFailureprobability\nBepaal de faalkans door een maatregel van een dijkvak\n\n\nSectionsClassify\nBepaal de status van een dijkvak gegeven de faalkans en grenswaardes.",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#fragility-curves",
    "href": "reference/index.html#fragility-curves",
    "title": "API Reference",
    "section": "",
    "text": "Functies voor het berekenen en aanpassen van Fragility curve\n\n\n\nFragilityCurveOvertopping\nMaakt een enkele fragility curve voor golf overslag.\n\n\nFragilityCurveOvertoppingMultiple\nMaakt een set van fragility curves voor golfoverslag voor een dijkvak.\n\n\nShiftFragilityCurveOvertopping\nVerschuift de fragility curve met een gegeven effect\n\n\nChangeCrestHeightFragilityCurveOvertopping\nVerschuift de kruinhoogte met het gegeven effect en berekent de fragility curve\n\n\nFragilityCurvePipingFixedWaterlevel\nMaakt een enkele fragility curve voor piping met een gegeven waterstand.\n\n\nFragilityCurvePipingMultiple\nMaakt een set van fragility curves voor piping voor een dijkvak.\n\n\nCombineFragilityCurvesIndependent\nCombineer meerdere fragility curves onafhankelijk tot een enkele fragility curve.\n\n\nCombineFragilityCurvesDependent\nCombineer meerdere fragility curves afhankelijk tot een enkele fragility curves.\n\n\nCombineFragilityCurvesWeightedSum\nCombineer meerdere fragility curves met een gewogen som tot een enkele fragility curve.\n\n\nIntegrateFragilityCurve\nIntegreert een waterniveau overschrijdingsfrequentielijn met een fragility curve\n\n\nIntegrateFragilityCurveMultiple\nIntegreert een waterniveau overschrijdingsfrequentielijn met een fragility curve voor reeks aan secties",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#inspectieresultaten",
    "href": "reference/index.html#inspectieresultaten",
    "title": "API Reference",
    "section": "",
    "text": "Invoer, verwerken en tonen van inspectieresultaten\n\n\n\nFilter\nFiltert een DataFrame aan de hand van de opgegeven configuratie.\n\n\nInspectionsToDatabase\nCombineert de inspectieresultaten met de opmaak en slaat deze op in de database.\n\n\nClassifyInspections\nClassificeert inspectieresultaten om weer te geven in de viewer.",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#continu-inzicht-adapters-invoer",
    "href": "reference/index.html#continu-inzicht-adapters-invoer",
    "title": "API Reference",
    "section": "",
    "text": "Invoer adapters voor Continu Inzicht meetstations/ dijkvak\n\n\n\ninput_measuringstation\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\ninput_section\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\ninput_fragilitycurve\nDataAdapters voor het lezen van data uit de Continu Inzicht database",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/index.html#continu-inzicht-adapters-uitvoer",
    "href": "reference/index.html#continu-inzicht-adapters-uitvoer",
    "title": "API Reference",
    "section": "",
    "text": "Uitvoer adapters voor Continu Inzicht meetstations/ dijkvak\n\n\n\noutput_measuringstation\nData adapters voor het schrijven naar de Continu Inzicht database\n\n\noutput_section\nData adapters voor het schrijven naar de Continu Inzicht database\n\n\noutput_calculation\nData adapters voor het schrijven naar de Continu Inzicht database",
    "crumbs": [
      "Python API",
      "API Reference"
    ]
  },
  {
    "objectID": "reference/get_waterinfo_locations.html",
    "href": "reference/get_waterinfo_locations.html",
    "title": "get_waterinfo_locations",
    "section": "",
    "text": "loads.get_waterinfo_locations(parameter_id='waterhoogte')\nHaal voor Waterinfo de locaties op voor de opgegeven parameter.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nparameter_id\nstr\nWaterinfo parameter bij geen waarde ‘waterhoogte’\n'waterhoogte'\n\n\n\n\n\n\nGebruikte API: https://waterinfo.rws.nl/api/point/latestmeasurement\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nPandas dataframe met locaties: pd.DataFrame\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nConnectionError\nAls de verbinding met de API niet lukt of geen locaties zijn gevonden"
  },
  {
    "objectID": "reference/get_waterinfo_locations.html#parameters",
    "href": "reference/get_waterinfo_locations.html#parameters",
    "title": "get_waterinfo_locations",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nparameter_id\nstr\nWaterinfo parameter bij geen waarde ‘waterhoogte’\n'waterhoogte'"
  },
  {
    "objectID": "reference/get_waterinfo_locations.html#notes",
    "href": "reference/get_waterinfo_locations.html#notes",
    "title": "get_waterinfo_locations",
    "section": "",
    "text": "Gebruikte API: https://waterinfo.rws.nl/api/point/latestmeasurement"
  },
  {
    "objectID": "reference/get_waterinfo_locations.html#returns",
    "href": "reference/get_waterinfo_locations.html#returns",
    "title": "get_waterinfo_locations",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nPandas dataframe met locaties: pd.DataFrame"
  },
  {
    "objectID": "reference/get_waterinfo_locations.html#raises",
    "href": "reference/get_waterinfo_locations.html#raises",
    "title": "get_waterinfo_locations",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nConnectionError\nAls de verbinding met de API niet lukt of geen locaties zijn gevonden"
  },
  {
    "objectID": "reference/get_matroos_locations_map.html",
    "href": "reference/get_matroos_locations_map.html",
    "title": "get_matroos_locations_map",
    "section": "",
    "text": "loads.get_matroos_locations_map(\n    source=None\n    parameter=None\n    endpoint='timeseries'\n)\nHaal alle matroos locaties op en maak een folium map.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsource\nstr | None\nBron in de matroos, None geeft alle terug\nNone\n\n\nparameter\nstr | None\nSpecifieke parameter waar voor je locaties zoekt, None geeft alle terug\nNone\n\n\nendpoint\nstr\nNaam van de endpoint, standaard ‘timeseries’, maar voor LoadsMatroosNetCDF gebruik je ‘maps1d’.\n'timeseries'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nFolium.map"
  },
  {
    "objectID": "reference/get_matroos_locations_map.html#parameters",
    "href": "reference/get_matroos_locations_map.html#parameters",
    "title": "get_matroos_locations_map",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsource\nstr | None\nBron in de matroos, None geeft alle terug\nNone\n\n\nparameter\nstr | None\nSpecifieke parameter waar voor je locaties zoekt, None geeft alle terug\nNone\n\n\nendpoint\nstr\nNaam van de endpoint, standaard ‘timeseries’, maar voor LoadsMatroosNetCDF gebruik je ‘maps1d’.\n'timeseries'"
  },
  {
    "objectID": "reference/get_matroos_locations_map.html#returns",
    "href": "reference/get_matroos_locations_map.html#returns",
    "title": "get_matroos_locations_map",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nFolium.map"
  },
  {
    "objectID": "reference/get_fews_thresholds.html",
    "href": "reference/get_fews_thresholds.html",
    "title": "get_fews_thresholds",
    "section": "",
    "text": "loads.get_fews_thresholds(\n    host\n    port\n    region\n    filter_id\n    parameter_id\n    location_id\n)\nHaal voor FEWS de thresholds op voor de opgegeven parameter en locatie.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nhost\nstr\nFEWS server host URL\nrequired\n\n\nport\nint\nPort waar de REST-service draait\nrequired\n\n\nregion\nstr\nIn FEWS gedefinieerde region\nrequired\n\n\nfilter_id\nstr\nFilter van de timeserie\nrequired\n\n\nparameter_id\nstr\nParameter van de timeserie\nrequired\n\n\nlocation_id\nstr\nLocatie van de timeserie\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nConnectionError\nAls er geen verbinding kan worden gemaakt of als de opgegeven parameter of locatie niet bestaat.\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nPandas dataframe met thresholds"
  },
  {
    "objectID": "reference/get_fews_thresholds.html#parameters",
    "href": "reference/get_fews_thresholds.html#parameters",
    "title": "get_fews_thresholds",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nhost\nstr\nFEWS server host URL\nrequired\n\n\nport\nint\nPort waar de REST-service draait\nrequired\n\n\nregion\nstr\nIn FEWS gedefinieerde region\nrequired\n\n\nfilter_id\nstr\nFilter van de timeserie\nrequired\n\n\nparameter_id\nstr\nParameter van de timeserie\nrequired\n\n\nlocation_id\nstr\nLocatie van de timeserie\nrequired"
  },
  {
    "objectID": "reference/get_fews_thresholds.html#raises",
    "href": "reference/get_fews_thresholds.html#raises",
    "title": "get_fews_thresholds",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nConnectionError\nAls er geen verbinding kan worden gemaakt of als de opgegeven parameter of locatie niet bestaat."
  },
  {
    "objectID": "reference/get_fews_thresholds.html#returns",
    "href": "reference/get_fews_thresholds.html#returns",
    "title": "get_fews_thresholds",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\npd.DataFrame\nPandas dataframe met thresholds"
  },
  {
    "objectID": "reference/FragilityCurvePipingMultiple.html",
    "href": "reference/FragilityCurvePipingMultiple.html",
    "title": "FragilityCurvePipingMultiple",
    "section": "",
    "text": "fragility_curves.FragilityCurvePipingMultiple()\nMaakt een set van fragility curves voor piping voor een dijkvak. De fragility curve wordt berekend met behulp van de probabilistic_piping package, zie de eigen documentatie voor meer informatie.\nDeze functie berekent ��n gecombineerde fragility curve voor de mechanismes uplift, heave en Sellmeijer.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_prob_input\nOptional[pd.DataFrame] | None\nDataFrame met input voor de probabilistische berekening.\n\n\ndf_hydraulicload\nOptional[pd.DataFrame] | None\nDataFrame met waterlevel data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de output van de fragility curve.\n\n\nfragility_curve_function_simple\nFragilityCurve\nFunctie die de fragility curve berekent. Standaard is de FragilityCurvePipingFixedWaterlevel.\n\n\n\n\n\n\nDe volgende bool opties kunnen worden ingesteld in de global_variables van de config:\n\nprogress, Standaard is False\ndebug, Standaard is False\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nfragility_curve_function_simple\nMaakt een enkele fragility curve voor piping met een gegeven waterstand.\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple()\nMaakt een enkele fragility curve voor piping met een gegeven waterstand.\nDe fragility curve wordt berekend met behulp van de probabilistic_piping package, zie de eigen documentatie voor meer informatie.\nDeze functie berekent fragility curves voor uplift, heave, Sellmeijer, en de gecombineerde mechanismes.\nVoor het combineren van de mechanismes wordt het minimum van de kansen van de drie sub-mechanismes genomen, De gecombineerde fragility curve is de standaard output, de andere kunnen worden opgevraagd met de df_result_uplift, df_result_heave, en df_result_sellmeijer attributen.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_prob_input\nOptional[pd.DataFrame] | None\nDataFrame containing probabilistic input data.\n\n\ndf_hydraulicload\nOptional[pd.DataFrame] | None\nDataFrame containing hydraulic load data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the final fragility curve.\n\n\ndf_result_uplift\nOptional[pd.DataFrame] | None\nDataFrame containing the uplift mechanism results.\n\n\ndf_result_heave\nOptional[pd.DataFrame] | None\nDataFrame containing the heave mechanism results.\n\n\ndf_result_sellmeijer\nOptional[pd.DataFrame] | None\nDataFrame containing the Sellmeijer mechanism results.\n\n\ndf_result_combined\nOptional[pd.DataFrame] | None\nDataFrame containing the combined mechanism results.\n\n\n\n\n\n\nDe volgende bool opties kunnen worden ingesteld in de global_variables van de config:\n\nprogress, Standaard is False\ndebug, Standaard is False\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor piping\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.as_array(\n)\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.as_dataframe(\n)\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand. Extra calculate functies is om overerving makkelijker te maken voor effecten.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.check_monotonic_curve(\n)\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.find_jump_indices(\n)\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.from_dataframe(\n    df\n)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.load(\n    input\n)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.log_exceptions(\n    method\n)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.run(\n    input\n    output\n)\nRunt de berekening van de fragility curve voor piping\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nZie de documentatie van probabilistic_piping.probabilistic_fixedwl.ProbPipingFixedWaterlevelSimple voor meer informatie.\n\nprob_input is afhankelijk van de probabilistische berekening die je wilt uitvoeren, zie externe documentatie.\nDe hydraulicload data adapter geeft de waterlevel data door, deze moet de kolom hydraulicload bevatten met floats.\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.shift(\n    effect\n)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.sort_curve(\n)\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de berekening van de fragility curves voor piping voor verschillende vakken\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.run(input, output)\nRunt de berekening van de fragility curves voor piping voor verschillende vakken\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nZie de documentatie van probabilistic_piping.probabilistic_fixedwl.ProbPipingFixedWaterlevelSimple voor meer informatie.\n\nprob_input is afhankelijk van de probabilistische berekening die je wilt uitvoeren, zie externe documentatie.\nDe hydraulicload data adapter geeft de waterlevel data door, deze moet de kolom hydraulicload bevatten met floats."
  },
  {
    "objectID": "reference/FragilityCurvePipingMultiple.html#attributes",
    "href": "reference/FragilityCurvePipingMultiple.html#attributes",
    "title": "FragilityCurvePipingMultiple",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_prob_input\nOptional[pd.DataFrame] | None\nDataFrame met input voor de probabilistische berekening.\n\n\ndf_hydraulicload\nOptional[pd.DataFrame] | None\nDataFrame met waterlevel data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de output van de fragility curve.\n\n\nfragility_curve_function_simple\nFragilityCurve\nFunctie die de fragility curve berekent. Standaard is de FragilityCurvePipingFixedWaterlevel."
  },
  {
    "objectID": "reference/FragilityCurvePipingMultiple.html#notes",
    "href": "reference/FragilityCurvePipingMultiple.html#notes",
    "title": "FragilityCurvePipingMultiple",
    "section": "",
    "text": "De volgende bool opties kunnen worden ingesteld in de global_variables van de config:\n\nprogress, Standaard is False\ndebug, Standaard is False"
  },
  {
    "objectID": "reference/FragilityCurvePipingMultiple.html#classes",
    "href": "reference/FragilityCurvePipingMultiple.html#classes",
    "title": "FragilityCurvePipingMultiple",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nfragility_curve_function_simple\nMaakt een enkele fragility curve voor piping met een gegeven waterstand.\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple()\nMaakt een enkele fragility curve voor piping met een gegeven waterstand.\nDe fragility curve wordt berekend met behulp van de probabilistic_piping package, zie de eigen documentatie voor meer informatie.\nDeze functie berekent fragility curves voor uplift, heave, Sellmeijer, en de gecombineerde mechanismes.\nVoor het combineren van de mechanismes wordt het minimum van de kansen van de drie sub-mechanismes genomen, De gecombineerde fragility curve is de standaard output, de andere kunnen worden opgevraagd met de df_result_uplift, df_result_heave, en df_result_sellmeijer attributen.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_prob_input\nOptional[pd.DataFrame] | None\nDataFrame containing probabilistic input data.\n\n\ndf_hydraulicload\nOptional[pd.DataFrame] | None\nDataFrame containing hydraulic load data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the final fragility curve.\n\n\ndf_result_uplift\nOptional[pd.DataFrame] | None\nDataFrame containing the uplift mechanism results.\n\n\ndf_result_heave\nOptional[pd.DataFrame] | None\nDataFrame containing the heave mechanism results.\n\n\ndf_result_sellmeijer\nOptional[pd.DataFrame] | None\nDataFrame containing the Sellmeijer mechanism results.\n\n\ndf_result_combined\nOptional[pd.DataFrame] | None\nDataFrame containing the combined mechanism results.\n\n\n\n\n\n\nDe volgende bool opties kunnen worden ingesteld in de global_variables van de config:\n\nprogress, Standaard is False\ndebug, Standaard is False\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor piping\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.as_array(\n)\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.as_dataframe(\n)\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand. Extra calculate functies is om overerving makkelijker te maken voor effecten.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.check_monotonic_curve(\n)\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.find_jump_indices(\n)\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.from_dataframe(\n    df\n)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.load(\n    input\n)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.log_exceptions(\n    method\n)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.run(\n    input\n    output\n)\nRunt de berekening van de fragility curve voor piping\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nZie de documentatie van probabilistic_piping.probabilistic_fixedwl.ProbPipingFixedWaterlevelSimple voor meer informatie.\n\nprob_input is afhankelijk van de probabilistische berekening die je wilt uitvoeren, zie externe documentatie.\nDe hydraulicload data adapter geeft de waterlevel data door, deze moet de kolom hydraulicload bevatten met floats.\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.shift(\n    effect\n)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.fragility_curve_function_simple.sort_curve(\n)\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/FragilityCurvePipingMultiple.html#methods-1",
    "href": "reference/FragilityCurvePipingMultiple.html#methods-1",
    "title": "FragilityCurvePipingMultiple",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de berekening van de fragility curves voor piping voor verschillende vakken\n\n\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurvePipingMultiple.run(input, output)\nRunt de berekening van de fragility curves voor piping voor verschillende vakken\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nZie de documentatie van probabilistic_piping.probabilistic_fixedwl.ProbPipingFixedWaterlevelSimple voor meer informatie.\n\nprob_input is afhankelijk van de probabilistische berekening die je wilt uitvoeren, zie externe documentatie.\nDe hydraulicload data adapter geeft de waterlevel data door, deze moet de kolom hydraulicload bevatten met floats."
  },
  {
    "objectID": "reference/FragilityCurveOvertoppingMultiple.html",
    "href": "reference/FragilityCurveOvertoppingMultiple.html",
    "title": "FragilityCurveOvertoppingMultiple",
    "section": "",
    "text": "fragility_curves.FragilityCurveOvertoppingMultiple()\nMaakt een set van fragility curves voor golfoverslag voor een dijkvak.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_slopes\nOptional[pd.DataFrame] | None\nDataFrame met hellingsdata.\n\n\ndf_bed_levels\nOptional[pd.DataFrame] | None\nDataFrame met bed level data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de resultaten van de berekening.\n\n\nfragility_curve_function\nFragilityCurve\nFragilityCurve object\n\n\neffect\nfloat | None\nEffect van de maatregel (niet gebruikt)\n\n\nmeasure_id\nint | None\nMaatregel id (niet gebruikt)\n\n\n\n\n\n\nVia de configuratie kunnen de volgende opties worden ingesteld, deze zijn float ten zij anders aangegeven. Onzekerheden:\n\ngh_onz_mu, GolfHoogte onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfhoogte (standaard 0.96)\ngh_onz_sigma, GolfHoogte onzekerheid sigma: standaard afwijking waarde (standaard 0.27)\ngp_onz_mu_tp, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tp, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngp_onz_mu_tspec, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tspec, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngh_onz_aantal, Aantal onzekerheden in de golfhoogte (standaard 7)\ngp_onz_aantal, Aantal onzekerheden in de golfperiode (standaard 7)\n\ntp_tspec, de verhouding tussen de piek periode van de golf ($T_p$) en de spectrale golfperiode ($Tm_{-1,0}$) (standaard 1.1).\nDe waterniveaus waarmee probablistisch gerekend wordt. Dit is verdeeld in twee delen: grof en fijn.\n\nlower_limit_coarse, De ondergrens van de waterstanden waarvoor de fragility scurve wordt berekend in grove stappen (standaard 4.0m onder de kruin)\nupper_limit_coarse, De bovengrens van de waterstanden waarvoor de fragility scurve wordt berekend in grove stappen (standaard 2.0m onder de kruin). Er is geen lower_limit_fine omdat deze altijd gelijk is aan upper_limit_coarse.\nupper_limit_fine, De bovengrens van de waterstanden waarvoor de fragility scurve wordt berekend in fijne stappen (standaard 1.01m boven de kruin)\nhstap, De fijne stapgrootte van de waterstanden waarvoor de fragility scurve wordt berekend (standaard 0.05), de grove stapgrootte is 2 * hstap.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nfragility_curve_function\nMaakt een enkele fragility curve voor golf overslag.\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function()\nMaakt een enkele fragility curve voor golf overslag.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_slopes\nOptional[pd.DataFrame] | None\nDataFrame met helling data.\n\n\ndf_profile\nOptional[pd.DataFrame] | None\nDataFrame met profiel data.\n\n\ndf_bed_levels\nOptional[pd.DataFrame] | None\nDataFrame met bed level data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de resultaten van de berekening.\n\n\n\n\n\n\nVia de configuratie kunnen de volgende opties worden ingesteld, deze zijn float ten zij anders aangegeven. Onzekerheden:\n\ngh_onz_mu, GolfHoogte onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfhoogte (standaard 0.96)\ngh_onz_sigma, GolfHoogte onzekerheid sigma: standaardafwijking waarde (standaard 0.27)\ngp_onz_mu_tp, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tp, GolfPerioden onzekerheid sigma: standaardafwijking waarde (standaard 0.13)\ngp_onz_mu_tspec, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tspec, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngh_onz_aantal, Aantal onzekerheden in de golfhoogte (standaard 7)\ngp_onz_aantal, Aantal onzekerheden in de golfperiode (standaard 7)\n\ntp_tspec, de verhouding tussen de piek periode van de golf ($T_p$) en de spectrale golfperiode ($Tm_{-1,0}$) (standaard 1.1).\nDe waterniveaus waarmee probabilistisch gerekend wordt is verdeeld in twee delen: grof en fijn.\n\nlower_limit_coarse, De ondergrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 4.0m onder de kruin)\nupper_limit_coarse, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 2.0m onder de kruin). Er is geen lower_limit_fine omdat deze altijd gelijk is aan upper_limit_coarse.\nupper_limit_fine, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in fijne stappen (standaard 1.01m boven de kruin)\nhstap, De fijne stapgrootte van de waterstanden waarvoor de fragility curve wordt berekend (standaard 0.05), de grove stapgrootte is 2 * hstap.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.as_array(\n)\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.as_dataframe(\n)\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.check_monotonic_curve(\n)\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.find_jump_indices(\n)\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.from_dataframe(\n    df\n)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.load(\n    input\n)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.log_exceptions(\n    method\n)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.run(\n    input\n    output\n)\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profiel data moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.shift(\n    effect\n)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.sort_curve(\n)\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.run(input, output)\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\n\nrequired"
  },
  {
    "objectID": "reference/FragilityCurveOvertoppingMultiple.html#attributes",
    "href": "reference/FragilityCurveOvertoppingMultiple.html#attributes",
    "title": "FragilityCurveOvertoppingMultiple",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_slopes\nOptional[pd.DataFrame] | None\nDataFrame met hellingsdata.\n\n\ndf_bed_levels\nOptional[pd.DataFrame] | None\nDataFrame met bed level data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de resultaten van de berekening.\n\n\nfragility_curve_function\nFragilityCurve\nFragilityCurve object\n\n\neffect\nfloat | None\nEffect van de maatregel (niet gebruikt)\n\n\nmeasure_id\nint | None\nMaatregel id (niet gebruikt)"
  },
  {
    "objectID": "reference/FragilityCurveOvertoppingMultiple.html#notes",
    "href": "reference/FragilityCurveOvertoppingMultiple.html#notes",
    "title": "FragilityCurveOvertoppingMultiple",
    "section": "",
    "text": "Via de configuratie kunnen de volgende opties worden ingesteld, deze zijn float ten zij anders aangegeven. Onzekerheden:\n\ngh_onz_mu, GolfHoogte onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfhoogte (standaard 0.96)\ngh_onz_sigma, GolfHoogte onzekerheid sigma: standaard afwijking waarde (standaard 0.27)\ngp_onz_mu_tp, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tp, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngp_onz_mu_tspec, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tspec, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngh_onz_aantal, Aantal onzekerheden in de golfhoogte (standaard 7)\ngp_onz_aantal, Aantal onzekerheden in de golfperiode (standaard 7)\n\ntp_tspec, de verhouding tussen de piek periode van de golf ($T_p$) en de spectrale golfperiode ($Tm_{-1,0}$) (standaard 1.1).\nDe waterniveaus waarmee probablistisch gerekend wordt. Dit is verdeeld in twee delen: grof en fijn.\n\nlower_limit_coarse, De ondergrens van de waterstanden waarvoor de fragility scurve wordt berekend in grove stappen (standaard 4.0m onder de kruin)\nupper_limit_coarse, De bovengrens van de waterstanden waarvoor de fragility scurve wordt berekend in grove stappen (standaard 2.0m onder de kruin). Er is geen lower_limit_fine omdat deze altijd gelijk is aan upper_limit_coarse.\nupper_limit_fine, De bovengrens van de waterstanden waarvoor de fragility scurve wordt berekend in fijne stappen (standaard 1.01m boven de kruin)\nhstap, De fijne stapgrootte van de waterstanden waarvoor de fragility scurve wordt berekend (standaard 0.05), de grove stapgrootte is 2 * hstap."
  },
  {
    "objectID": "reference/FragilityCurveOvertoppingMultiple.html#classes",
    "href": "reference/FragilityCurveOvertoppingMultiple.html#classes",
    "title": "FragilityCurveOvertoppingMultiple",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nfragility_curve_function\nMaakt een enkele fragility curve voor golf overslag.\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function()\nMaakt een enkele fragility curve voor golf overslag.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_slopes\nOptional[pd.DataFrame] | None\nDataFrame met helling data.\n\n\ndf_profile\nOptional[pd.DataFrame] | None\nDataFrame met profiel data.\n\n\ndf_bed_levels\nOptional[pd.DataFrame] | None\nDataFrame met bed level data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de resultaten van de berekening.\n\n\n\n\n\n\nVia de configuratie kunnen de volgende opties worden ingesteld, deze zijn float ten zij anders aangegeven. Onzekerheden:\n\ngh_onz_mu, GolfHoogte onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfhoogte (standaard 0.96)\ngh_onz_sigma, GolfHoogte onzekerheid sigma: standaardafwijking waarde (standaard 0.27)\ngp_onz_mu_tp, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tp, GolfPerioden onzekerheid sigma: standaardafwijking waarde (standaard 0.13)\ngp_onz_mu_tspec, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tspec, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngh_onz_aantal, Aantal onzekerheden in de golfhoogte (standaard 7)\ngp_onz_aantal, Aantal onzekerheden in de golfperiode (standaard 7)\n\ntp_tspec, de verhouding tussen de piek periode van de golf ($T_p$) en de spectrale golfperiode ($Tm_{-1,0}$) (standaard 1.1).\nDe waterniveaus waarmee probabilistisch gerekend wordt is verdeeld in twee delen: grof en fijn.\n\nlower_limit_coarse, De ondergrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 4.0m onder de kruin)\nupper_limit_coarse, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 2.0m onder de kruin). Er is geen lower_limit_fine omdat deze altijd gelijk is aan upper_limit_coarse.\nupper_limit_fine, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in fijne stappen (standaard 1.01m boven de kruin)\nhstap, De fijne stapgrootte van de waterstanden waarvoor de fragility curve wordt berekend (standaard 0.05), de grove stapgrootte is 2 * hstap.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.as_array(\n)\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.as_dataframe(\n)\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.check_monotonic_curve(\n)\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.find_jump_indices(\n)\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.from_dataframe(\n    df\n)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.load(\n    input\n)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.log_exceptions(\n    method\n)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.run(\n    input\n    output\n)\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profiel data moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.shift(\n    effect\n)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.fragility_curve_function.sort_curve(\n)\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/FragilityCurveOvertoppingMultiple.html#methods-1",
    "href": "reference/FragilityCurveOvertoppingMultiple.html#methods-1",
    "title": "FragilityCurveOvertoppingMultiple",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurveOvertoppingMultiple.run(input, output)\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\n\nrequired"
  },
  {
    "objectID": "reference/FragilityCurve.html",
    "href": "reference/FragilityCurve.html",
    "title": "FragilityCurve",
    "section": "",
    "text": "FragilityCurve()\nClass met een aantal gemakkelijke methoden om fragility curves op te slaan en aan te passen\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object om data in te laden\n\n\nhydraulicload\nOptional[np.ndarray] | None\nArray met de belastingen\n\n\nfailure_probability\nOptional[np.ndarray] | None\nArray met de faalkansen\n\n\nlower_limit\nfloat\nOndergrens voor de interpolatie van de faalkans, standaard 1e-200\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt\n\n\nenforce_monotonic\nbool\nForceert monotoon stijgende faalkansen, standaard True\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen:{hydraulicload: float, failure_probability: float}\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\n\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\n\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nFragilityCurve.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nFragilityCurve.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nFragilityCurve.calculate_fragility_curve(*args, **kwargs)\n\n\n\nFragilityCurve.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nFragilityCurve.find_jump_indices()\n\n\n\nFragilityCurve.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nFragilityCurve.interp_func(x, xp, fp, ll=1e-200, clip01=False)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nFragilityCurve.load(input)\nLaadt een fragility curve in\n\n\n\nFragilityCurve.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nFragilityCurve.refine(new_hydraulicload, add_steps=True)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nFragilityCurve.reliability_update(update_level, trust_factor=1)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nFragilityCurve.run(*args, **kwargs)\n\n\n\nFragilityCurve.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nFragilityCurve.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/FragilityCurve.html#attributes",
    "href": "reference/FragilityCurve.html#attributes",
    "title": "FragilityCurve",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object om data in te laden\n\n\nhydraulicload\nOptional[np.ndarray] | None\nArray met de belastingen\n\n\nfailure_probability\nOptional[np.ndarray] | None\nArray met de faalkansen\n\n\nlower_limit\nfloat\nOndergrens voor de interpolatie van de faalkans, standaard 1e-200\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt\n\n\nenforce_monotonic\nbool\nForceert monotoon stijgende faalkansen, standaard True\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen:{hydraulicload: float, failure_probability: float}"
  },
  {
    "objectID": "reference/FragilityCurve.html#methods",
    "href": "reference/FragilityCurve.html#methods",
    "title": "FragilityCurve",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\n\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\n\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nFragilityCurve.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nFragilityCurve.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nFragilityCurve.calculate_fragility_curve(*args, **kwargs)\n\n\n\nFragilityCurve.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nFragilityCurve.find_jump_indices()\n\n\n\nFragilityCurve.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nFragilityCurve.interp_func(x, xp, fp, ll=1e-200, clip01=False)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nFragilityCurve.load(input)\nLaadt een fragility curve in\n\n\n\nFragilityCurve.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nFragilityCurve.refine(new_hydraulicload, add_steps=True)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nFragilityCurve.reliability_update(update_level, trust_factor=1)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nFragilityCurve.run(*args, **kwargs)\n\n\n\nFragilityCurve.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nFragilityCurve.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/DataAdapter.html",
    "href": "reference/DataAdapter.html",
    "title": "DataAdapter",
    "section": "",
    "text": "DataAdapter(self, config)\nBasis DataAdapter\n\n\n\n\n\nName\nDescription\n\n\n\n\nconfig\n\n\n\ninput_types\n\n\n\nlogger\n\n\n\noutput_types\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_global_variable\nFunctie voor het ophalen van global variable.\n\n\ninit_logging\nInitialiseer de logger met de configuratie.\n\n\ninitialize_input_types\n\n\n\ninitialize_output_types\n\n\n\ninput\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\noutput\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\nset_dataframe_adapter\nFunctie om een DataFrame mee te geven aan een DataAdapter met type: python.\n\n\nset_global_variable\nFunctie voor het dynamisch overschrijven van global variabelen.\n\n\n\n\n\nDataAdapter.get_global_variable(key)\nFunctie voor het ophalen van global variable.\n\n\nkey: str naam van de waarde om op te overschrijven\n\n\n\nvalue: Any Global variable value\n\n\n\n\nDataAdapter.init_logging()\nInitialiseer de logger met de configuratie.\nVoor logging zijn de volgende instellingen mogelijk: - name: naam van de logger - level: logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL) - mode: schrijfwijze van de logfile (w, a) - file: bestands naam om naar weg te schrijven logfile - history_file: logfile voor de history\nAls file en history_file geen absolute path zijn, dan worden ze in de rootdir van de configuratie opgeslagen. In het geval dat file opgegeven is, maar geen valide pad is, dan wordt er een logfile hidden_logfile.log aangemaakt in de rootdir.\n\n\n\nDataAdapter.initialize_input_types()\n\n\n\nDataAdapter.initialize_output_types()\n\n\n\nDataAdapter.input(input, schema=None)\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\ninput: str Naam van de DataAdapter die gebruikt wordt.\nopties: dict Extra informatie die ook naar de functie moet om het bestand te lezen.\n\n\n\n\nDataAdapter.output(output, df)\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\noutput: Naam van de DataAdapter die gebruikt moet worden. df: pd.Dataframe pandas DataFrame om weg te schrijven.\nopties: dict Extra informatie die ook naar de functie moet om het bestand te schrijven.\n\n\n\n\nDataAdapter.set_dataframe_adapter(key, df, if_not_exist='raise')\nFunctie om een DataFrame mee te geven aan een DataAdapter met type: python. Let er zelf op dat de kolomnamen en datatypes overeenkomen met de beoogde functie.\n\n\nkey: str Naam van de DataAdapter zoals opgegeven in de configuratie-YAML\ndf: pd.Dataframe Object om mee te geven\nif_not_exist: str[raise, create] Geeft aan wat te doen als de DataAdapter niet bestaat, bij raise krijg je een error, bij create wordt er een nieuwe DataAdapter aangemaakt.\n\n\n\n\nDataAdapter.set_global_variable(key, value)\nFunctie voor het dynamisch overschrijven van global variabelen.\n\n\nkey: str Naam van de waarde om te overschrijven.\nvalue: Any Object om mee te geven."
  },
  {
    "objectID": "reference/DataAdapter.html#attributes",
    "href": "reference/DataAdapter.html#attributes",
    "title": "DataAdapter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nconfig\n\n\n\ninput_types\n\n\n\nlogger\n\n\n\noutput_types"
  },
  {
    "objectID": "reference/DataAdapter.html#methods",
    "href": "reference/DataAdapter.html#methods",
    "title": "DataAdapter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_global_variable\nFunctie voor het ophalen van global variable.\n\n\ninit_logging\nInitialiseer de logger met de configuratie.\n\n\ninitialize_input_types\n\n\n\ninitialize_output_types\n\n\n\ninput\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\noutput\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\nset_dataframe_adapter\nFunctie om een DataFrame mee te geven aan een DataAdapter met type: python.\n\n\nset_global_variable\nFunctie voor het dynamisch overschrijven van global variabelen.\n\n\n\n\n\nDataAdapter.get_global_variable(key)\nFunctie voor het ophalen van global variable.\n\n\nkey: str naam van de waarde om op te overschrijven\n\n\n\nvalue: Any Global variable value\n\n\n\n\nDataAdapter.init_logging()\nInitialiseer de logger met de configuratie.\nVoor logging zijn de volgende instellingen mogelijk: - name: naam van de logger - level: logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL) - mode: schrijfwijze van de logfile (w, a) - file: bestands naam om naar weg te schrijven logfile - history_file: logfile voor de history\nAls file en history_file geen absolute path zijn, dan worden ze in de rootdir van de configuratie opgeslagen. In het geval dat file opgegeven is, maar geen valide pad is, dan wordt er een logfile hidden_logfile.log aangemaakt in de rootdir.\n\n\n\nDataAdapter.initialize_input_types()\n\n\n\nDataAdapter.initialize_output_types()\n\n\n\nDataAdapter.input(input, schema=None)\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\ninput: str Naam van de DataAdapter die gebruikt wordt.\nopties: dict Extra informatie die ook naar de functie moet om het bestand te lezen.\n\n\n\n\nDataAdapter.output(output, df)\nGegeven de config, stuurt de juiste inputwaarde aan\n\n\noutput: Naam van de DataAdapter die gebruikt moet worden. df: pd.Dataframe pandas DataFrame om weg te schrijven.\nopties: dict Extra informatie die ook naar de functie moet om het bestand te schrijven.\n\n\n\n\nDataAdapter.set_dataframe_adapter(key, df, if_not_exist='raise')\nFunctie om een DataFrame mee te geven aan een DataAdapter met type: python. Let er zelf op dat de kolomnamen en datatypes overeenkomen met de beoogde functie.\n\n\nkey: str Naam van de DataAdapter zoals opgegeven in de configuratie-YAML\ndf: pd.Dataframe Object om mee te geven\nif_not_exist: str[raise, create] Geeft aan wat te doen als de DataAdapter niet bestaat, bij raise krijg je een error, bij create wordt er een nieuwe DataAdapter aangemaakt.\n\n\n\n\nDataAdapter.set_global_variable(key, value)\nFunctie voor het dynamisch overschrijven van global variabelen.\n\n\nkey: str Naam van de waarde om te overschrijven.\nvalue: Any Object om mee te geven."
  },
  {
    "objectID": "reference/CombineFragilityCurvesWeightedSum.html",
    "href": "reference/CombineFragilityCurvesWeightedSum.html",
    "title": "CombineFragilityCurvesWeightedSum",
    "section": "",
    "text": "fragility_curves.CombineFragilityCurvesWeightedSum()\nCombineer meerdere fragility curves met een gewogen som tot een enkele fragility curve.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\nlst_fragility_curves\nlist[pd.DataFrame]\nLijst van fragility curves die worden gecombineerd\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de gecombineerde fragility curve\n\n\ncombine_func\nCallable\nFunctie die wordt gebruikt om de fragility curves te combineren\n\n\nweights\nlist[float] | None\nGewichten voor de weighted sum methode, in de zelfde volgorde als de lijst van fragility curves\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen: hydraulicload: float, failure_probability: float\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt in FragilityCurve\n\n\n\n\n\n\nBij het combineren van de fragility curves moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen via de config worden ingesteld:\n\nextend_past_max. Hoever de nieuwe waterstanden verder gaan dan de maximale waterstanden van de inputcurves. Default is 0.01.\nrefine_step_size. De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncalculate_combined_curve\n\n\n\ncombine_func\nCombineer afhankelijk: P(fail,comb|h) = SUM(w_i * P(fail,i|h))\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nCombineert meerdere fragility curves onafhankelijk\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.calculate_combined_curve(\n    extend_past_max\n    refine_step_size\n)\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.combine_func(\n    lst_fragility_curves\n    weights=None\n)\nCombineer afhankelijk: P(fail,comb|h) = SUM(w_i * P(fail,i|h))\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.run(input, output)\nCombineert meerdere fragility curves onafhankelijk\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van namen van de DataAdapters met fragility curves. De laatste lijst hiervan in de gewichten.\nrequired\n\n\noutput\nstr\nNaam van de output DataAdapter.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de lengte van de gewichten niet gelijk is aan het aantal fragility curves, de laatste waarde van de input lijst moet de gewichten bevatten."
  },
  {
    "objectID": "reference/CombineFragilityCurvesWeightedSum.html#attributes",
    "href": "reference/CombineFragilityCurvesWeightedSum.html#attributes",
    "title": "CombineFragilityCurvesWeightedSum",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\nlst_fragility_curves\nlist[pd.DataFrame]\nLijst van fragility curves die worden gecombineerd\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de gecombineerde fragility curve\n\n\ncombine_func\nCallable\nFunctie die wordt gebruikt om de fragility curves te combineren\n\n\nweights\nlist[float] | None\nGewichten voor de weighted sum methode, in de zelfde volgorde als de lijst van fragility curves\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen: hydraulicload: float, failure_probability: float\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt in FragilityCurve"
  },
  {
    "objectID": "reference/CombineFragilityCurvesWeightedSum.html#notes",
    "href": "reference/CombineFragilityCurvesWeightedSum.html#notes",
    "title": "CombineFragilityCurvesWeightedSum",
    "section": "",
    "text": "Bij het combineren van de fragility curves moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen via de config worden ingesteld:\n\nextend_past_max. Hoever de nieuwe waterstanden verder gaan dan de maximale waterstanden van de inputcurves. Default is 0.01.\nrefine_step_size. De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05."
  },
  {
    "objectID": "reference/CombineFragilityCurvesWeightedSum.html#methods",
    "href": "reference/CombineFragilityCurvesWeightedSum.html#methods",
    "title": "CombineFragilityCurvesWeightedSum",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncalculate_combined_curve\n\n\n\ncombine_func\nCombineer afhankelijk: P(fail,comb|h) = SUM(w_i * P(fail,i|h))\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nCombineert meerdere fragility curves onafhankelijk\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.calculate_combined_curve(\n    extend_past_max\n    refine_step_size\n)\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.combine_func(\n    lst_fragility_curves\n    weights=None\n)\nCombineer afhankelijk: P(fail,comb|h) = SUM(w_i * P(fail,i|h))\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.CombineFragilityCurvesWeightedSum.run(input, output)\nCombineert meerdere fragility curves onafhankelijk\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van namen van de DataAdapters met fragility curves. De laatste lijst hiervan in de gewichten.\nrequired\n\n\noutput\nstr\nNaam van de output DataAdapter.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de lengte van de gewichten niet gelijk is aan het aantal fragility curves, de laatste waarde van de input lijst moet de gewichten bevatten."
  },
  {
    "objectID": "reference/CombineFragilityCurvesDependent.html",
    "href": "reference/CombineFragilityCurvesDependent.html",
    "title": "CombineFragilityCurvesDependent",
    "section": "",
    "text": "fragility_curves.CombineFragilityCurvesDependent()\nCombineer meerdere fragility curves afhankelijk tot een enkele fragility curves.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\nlst_fragility_curves\nlist[pd.DataFrame]\nLijst van fragility curves die worden gecombineerd\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de gecombineerde fragility curve\n\n\ncombine_func\nCallable\nFunctie die wordt gebruikt om de fragility curves te combineren\n\n\nweights\nNone\nAlleen van toepassing bij de weighted sum methode, hier None\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen: hydraulicload: float, failure_probability: float\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt in FragilityCurve\n\n\n\n\n\n\nBij het combineren van de fragility curves moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen via de config worden ingesteld:\n\nextend_past_max, Hoever de nieuwe waterstanden verder gaan dan de maximale waterstanden van de inputcurves. Default is 0.01.\nrefine_step_size, De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncalculate_combined_curve\n\n\n\ncombine_func\nCombineer afhankelijk: P(fail,comb|h) = MAX(P(fail,i|h))\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nCombineert meerdere fragility curves\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.calculate_combined_curve(\n    extend_past_max\n    refine_step_size\n)\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.combine_func(\n    lst_fragility_curves\n    **kwargs\n)\nCombineer afhankelijk: P(fail,comb|h) = MAX(P(fail,i|h))\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.run(input, output)\nCombineert meerdere fragility curves\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van namen van de DataAdapters met fragility curves.\nrequired\n\n\noutput\nstr\nNaam van de output DataAdapter.\nrequired"
  },
  {
    "objectID": "reference/CombineFragilityCurvesDependent.html#attributes",
    "href": "reference/CombineFragilityCurvesDependent.html#attributes",
    "title": "CombineFragilityCurvesDependent",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\nlst_fragility_curves\nlist[pd.DataFrame]\nLijst van fragility curves die worden gecombineerd\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de gecombineerde fragility curve\n\n\ncombine_func\nCallable\nFunctie die wordt gebruikt om de fragility curves te combineren\n\n\nweights\nNone\nAlleen van toepassing bij de weighted sum methode, hier None\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen: hydraulicload: float, failure_probability: float\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt in FragilityCurve"
  },
  {
    "objectID": "reference/CombineFragilityCurvesDependent.html#notes",
    "href": "reference/CombineFragilityCurvesDependent.html#notes",
    "title": "CombineFragilityCurvesDependent",
    "section": "",
    "text": "Bij het combineren van de fragility curves moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen via de config worden ingesteld:\n\nextend_past_max, Hoever de nieuwe waterstanden verder gaan dan de maximale waterstanden van de inputcurves. Default is 0.01.\nrefine_step_size, De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05."
  },
  {
    "objectID": "reference/CombineFragilityCurvesDependent.html#methods",
    "href": "reference/CombineFragilityCurvesDependent.html#methods",
    "title": "CombineFragilityCurvesDependent",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncalculate_combined_curve\n\n\n\ncombine_func\nCombineer afhankelijk: P(fail,comb|h) = MAX(P(fail,i|h))\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nCombineert meerdere fragility curves\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.calculate_combined_curve(\n    extend_past_max\n    refine_step_size\n)\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.combine_func(\n    lst_fragility_curves\n    **kwargs\n)\nCombineer afhankelijk: P(fail,comb|h) = MAX(P(fail,i|h))\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.CombineFragilityCurvesDependent.run(input, output)\nCombineert meerdere fragility curves\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van namen van de DataAdapters met fragility curves.\nrequired\n\n\noutput\nstr\nNaam van de output DataAdapter.\nrequired"
  },
  {
    "objectID": "reference/ChangeCrestHeightFragilityCurveOvertopping.html",
    "href": "reference/ChangeCrestHeightFragilityCurveOvertopping.html",
    "title": "ChangeCrestHeightFragilityCurveOvertopping",
    "section": "",
    "text": "fragility_curves.ChangeCrestHeightFragilityCurveOvertopping()\nVerschuift de kruinhoogte met het gegeven effect en berekent de fragility curve\n\n\n\n\n\nName\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_bed_levels\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton.\n\n\ndf_profile\nThe type of the None singleton.\n\n\ndf_slopes\nThe type of the None singleton.\n\n\nenforce_monotonic\nReturns True when the argument is true, False otherwise.\n\n\nfailure_probability\nThe type of the None singleton.\n\n\nfragility_curve_schema\ndict() -&gt; new empty dictionary\n\n\nhydraulicload\nThe type of the None singleton.\n\n\nlower_limit\nConvert a string or number to a floating-point number, if possible.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag & past de kruinhoogte aan met een gegeven effect\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.check_monotonic_curve(\n)\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.find_jump_indices()\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.log_exceptions(\n    method\n)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.run(\n    input\n    output\n    effect\n)\nRunt de berekening van de fragility curve voor golfoverslag & past de kruinhoogte aan met een gegeven effect\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\neffect\nfloat\nVerschuiving van de fragility curve\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profieldata moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/ChangeCrestHeightFragilityCurveOvertopping.html#attributes",
    "href": "reference/ChangeCrestHeightFragilityCurveOvertopping.html#attributes",
    "title": "ChangeCrestHeightFragilityCurveOvertopping",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_bed_levels\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton.\n\n\ndf_profile\nThe type of the None singleton.\n\n\ndf_slopes\nThe type of the None singleton.\n\n\nenforce_monotonic\nReturns True when the argument is true, False otherwise.\n\n\nfailure_probability\nThe type of the None singleton.\n\n\nfragility_curve_schema\ndict() -&gt; new empty dictionary\n\n\nhydraulicload\nThe type of the None singleton.\n\n\nlower_limit\nConvert a string or number to a floating-point number, if possible."
  },
  {
    "objectID": "reference/ChangeCrestHeightFragilityCurveOvertopping.html#methods",
    "href": "reference/ChangeCrestHeightFragilityCurveOvertopping.html#methods",
    "title": "ChangeCrestHeightFragilityCurveOvertopping",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag & past de kruinhoogte aan met een gegeven effect\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.check_monotonic_curve(\n)\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.find_jump_indices()\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.log_exceptions(\n    method\n)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.run(\n    input\n    output\n    effect\n)\nRunt de berekening van de fragility curve voor golfoverslag & past de kruinhoogte aan met een gegeven effect\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\neffect\nfloat\nVerschuiving van de fragility curve\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profieldata moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.ChangeCrestHeightFragilityCurveOvertopping.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "overig/tests.html",
    "href": "overig/tests.html",
    "title": "Testprotocol",
    "section": "",
    "text": "Elk ontwikkeld script wordt getest. Dit testprotocol bestaat uit unittesten en integratietesten. Met unittesten testen we of de individuele componenten van de broncode goed werken (bijv. als de gebruiker foutieve data opgeeft). Bij het maken van unittesten is het doel om een totale dekking van 80% te halen over de gehele code, dit kan gecontroleerd worden met pytest -cov. Bij sommige modules is dit het makkelijk om alle code te vatten in een test, in die gevallen is dit dan ook de bedoeling om dit te doen. Doordat de interactie met een PostgreSQL database of FEWS REST-API niet makkelijk te verwerken is in een automatische test, is er per functie geen strikte eis. Om toch de interactie met componenten die beveiligd zijn en om de samenwerking tussen de verschillende scripts te controleren, worden integratietesten uitgevoerd. In de ontwikkelfase vinden deze integratietesten plaats aan het einde van de sprints door een deel van de project groep die niet de code actief heeft ontwikkeld. In de beheerfase zal het team dat de code blijft beheren deze integratie testen blijven uitvoeren.",
    "crumbs": [
      "Overig",
      "Testprotocol"
    ]
  },
  {
    "objectID": "overig/changelog.html",
    "href": "overig/changelog.html",
    "title": "Changelog",
    "section": "",
    "text": "Alle noemenswaardige veranderingen worden hier bijgehouden. Dit project gebruikt Semantic Versioning. Het format is beschreven op keepachangelog.com.\n\n\n\n\n\nWerkende Quarto documentatie #7\nProof of concept met csv en database #9\nVoeg notebook toe om te laten zien hoe het werkt #12\nMaak map structuur overzichtelijker #19\n\n\n\n\nIn sprint 2 is gebruikt gemaakt van aparte ‘feature branches’ met een grote pull request naar main #36.\nAllereerst zijn er nog restpunten uit sprint 1 aangepast:\n\nhet specificeren van delimiter deed het niet, dit moet sep zijn. Daarnaast worden nu alle opties die in de configuratie zijn gespecificeerd doorgegeven aan de data adapters.\npath is nu file, waarbij file altijd een bestand is in de rootdir. ‘path’ mag ook een ander absoluut pad zijn: bijvoorbeeld een bestand op een andere locatie. Er wordt ook gecheckt of de paden bestaan voor het runnen van een functie.\n.env bestand is niet meer verplicht, maar geeft wel een warning\nutil map aangemaakt voor generieke functies als tijd en post/get functies\npytest.skipif voor testen die alleen op het HKV-netwerk draaien door FEWS/postgreSQL verbindingen.\nde keywords input=.. en output=.. worden nu alleen aan de .run() functie doorgegeven, niet aan de class zelf.\n\nDaarnaast zijn er toevoegingen gedaan ten behoeve van het inlezen van belastingen:\n\nInlezen en ophalen van locaties, parameters en grenswaardes(waar mogelijk) uit:\n\n(Noos/Vitaal) Matroos\nFEWS\nRWS waterinfo\nRWS waterwebservices\n\n\nDeze inleesfuncties gebruiken allemaal de Aquo-standaard naam en code (WATHTE).\n\nClassificeren van belastingen aan de hand van opgehaalde/opgegeven grenswaardes.\nToekennen van belastingen aan secties.\nAggregeren van tijdreeksen naar momenten of bij het getij naar maxima over de getijperiode.\n\n\n\n\n\n\nIn sprint 3 is weer gebruikt gemaakt van aparte ‘feature branches’ met een grote pull request naar main #45.\nDe nadruk lag vooral op het toevoegen van fragility curves. Fragility curves kunnen worden gemaakt voor GEKB (golfoverslag) en STPH (piping). Ook kunnen ze afhankelijk, onafhankelijk en met een gewogen gemiddelde worden gecombineerd. Hiervoor zijn de packages respectievelijk pydra_core en probabilistic piping gebruikt.\nDaarnaast zijn er een heel aantal data adapters toegevoegd en veel voorbeelden hoe je het kan linken aan een continu inzicht database, daar data op kan zetten en vervolgens gebruiken in functies.\n\n\n\nDe pre-commit uitgebreid en toegevoegd aan de github actions, dit run je voor je een aanpassingen doorvoer met pixi run pre-commit. De tests en publiceren van docs is nu in een windows action omgeving zodat de Dll’s van pydra_core het doen, de pixi.lock is geupdate om nieuwe packages toe te laten.\n\n\n\n\n\n\nAlle aanpassingen zijn te vinden in pull request #54\nWaar in sprint 3 een groot deel van het werk lag in ‘nieuwe’ inhoud, was dit wat beperkter in sprint 4. Er zijn toevoegingen gedaan aan de FragilityCurve base class waarmee het nu ook mogelijk is om met een overschrijdingsfrequentie lijn de conditionele kans te integreren. Hiermee kunnen verschillende varianten (combinatie van fragility curve en overschrijdingsfrequentie) worden vergeleken.\nWel is veel werk verricht om een het integreren van de curve mooi weer te geven in de viewer. Hier is ook aan een fast-api implementatie gewerkt.\n\n\n\nPubliceren op PyPi is nu mogelijk en gaat volledig automatisch via github actions, dit run je door een tag aan te maken op de github.\nDaarnaast checkt de pre-commit nu ook op docstring format zodat het netter in de ‘API reference’ komt in de documentatie. Hierdoor zijn een hele hoop docstrings aangepast.\nHet verschil tussen waterlevel(s) en hydaulicload(s) aangepakt, we voeren nu overal hydaulicload.\nMatroos was al beschikbaar, maar maakte gebruik van de timeseries endpoint. Omdat timeseries de vertaling naar reeks al op de server van matroos doet, kan dit wat traag zijn. Om dit op te lossen is na contact met het beheer van Matroos ook de maps1d endpoint toegevoegd, deze leest de ‘ruwe’ NetCDF bestanden in en vertaald ze naar een tijdreeks die in de toolbox kan worden gebruikt.\n\n\n\n\n\n\nAlle aanpassingen zijn te vinden in pull request #57\nIn Sprint 5 is gekeken naar het filteren, ontsluiten en visualiseren van inspectieresultaten. Er zijn meerdere vormen van ontsluiting toegevoegd in de Continu Inzicht Viewer:\n\nWMS-laag via link\nGeoJSON-objecten in een kaartweergave\nTabelweergave met inspectiegegevens\n\nDaarnaast zijn er diverse restpunten opgepakt, waaronder:\n\nCentrale logging: Afvangen van alle fouten tijdens de run()-uitvoering, met uitgebreide configuratiemogelijkheden.\nFragility curves functionaliteit is uitgebreid:\n\nBetere interpolatie functie\nOndersteuning voor stapfuncties\nCorrect omgaan met kleine kansen\nValidatie op monotoon stijgende curves\n\nEen integratie test is uitgevoerd om de snelheid te bepalen van de rekenmodules en waar nodig aanpassingen geweest.\n\n\n\n\nDe opmaak informatie voor kaartlagen nu uit de database opgehaald door de viewer, dit was een handmatige configuratie stap. Gebruikers kunnen op deze manier makkelijker aanpassingen doorvoeren in de viewer.\nDe logging gebruikt een nieuwe ‘baseClass’: ToolboxBase, inherit deze om logging automatische toe te voegen aan de run() functie.",
    "crumbs": [
      "Overig",
      "Changelog"
    ]
  },
  {
    "objectID": "overig/changelog.html#development",
    "href": "overig/changelog.html#development",
    "title": "Changelog",
    "section": "",
    "text": "Werkende Quarto documentatie #7\nProof of concept met csv en database #9\nVoeg notebook toe om te laten zien hoe het werkt #12\nMaak map structuur overzichtelijker #19\n\n\n\n\nIn sprint 2 is gebruikt gemaakt van aparte ‘feature branches’ met een grote pull request naar main #36.\nAllereerst zijn er nog restpunten uit sprint 1 aangepast:\n\nhet specificeren van delimiter deed het niet, dit moet sep zijn. Daarnaast worden nu alle opties die in de configuratie zijn gespecificeerd doorgegeven aan de data adapters.\npath is nu file, waarbij file altijd een bestand is in de rootdir. ‘path’ mag ook een ander absoluut pad zijn: bijvoorbeeld een bestand op een andere locatie. Er wordt ook gecheckt of de paden bestaan voor het runnen van een functie.\n.env bestand is niet meer verplicht, maar geeft wel een warning\nutil map aangemaakt voor generieke functies als tijd en post/get functies\npytest.skipif voor testen die alleen op het HKV-netwerk draaien door FEWS/postgreSQL verbindingen.\nde keywords input=.. en output=.. worden nu alleen aan de .run() functie doorgegeven, niet aan de class zelf.\n\nDaarnaast zijn er toevoegingen gedaan ten behoeve van het inlezen van belastingen:\n\nInlezen en ophalen van locaties, parameters en grenswaardes(waar mogelijk) uit:\n\n(Noos/Vitaal) Matroos\nFEWS\nRWS waterinfo\nRWS waterwebservices\n\n\nDeze inleesfuncties gebruiken allemaal de Aquo-standaard naam en code (WATHTE).\n\nClassificeren van belastingen aan de hand van opgehaalde/opgegeven grenswaardes.\nToekennen van belastingen aan secties.\nAggregeren van tijdreeksen naar momenten of bij het getij naar maxima over de getijperiode.\n\n\n\n\n\n\nIn sprint 3 is weer gebruikt gemaakt van aparte ‘feature branches’ met een grote pull request naar main #45.\nDe nadruk lag vooral op het toevoegen van fragility curves. Fragility curves kunnen worden gemaakt voor GEKB (golfoverslag) en STPH (piping). Ook kunnen ze afhankelijk, onafhankelijk en met een gewogen gemiddelde worden gecombineerd. Hiervoor zijn de packages respectievelijk pydra_core en probabilistic piping gebruikt.\nDaarnaast zijn er een heel aantal data adapters toegevoegd en veel voorbeelden hoe je het kan linken aan een continu inzicht database, daar data op kan zetten en vervolgens gebruiken in functies.\n\n\n\nDe pre-commit uitgebreid en toegevoegd aan de github actions, dit run je voor je een aanpassingen doorvoer met pixi run pre-commit. De tests en publiceren van docs is nu in een windows action omgeving zodat de Dll’s van pydra_core het doen, de pixi.lock is geupdate om nieuwe packages toe te laten.\n\n\n\n\n\n\nAlle aanpassingen zijn te vinden in pull request #54\nWaar in sprint 3 een groot deel van het werk lag in ‘nieuwe’ inhoud, was dit wat beperkter in sprint 4. Er zijn toevoegingen gedaan aan de FragilityCurve base class waarmee het nu ook mogelijk is om met een overschrijdingsfrequentie lijn de conditionele kans te integreren. Hiermee kunnen verschillende varianten (combinatie van fragility curve en overschrijdingsfrequentie) worden vergeleken.\nWel is veel werk verricht om een het integreren van de curve mooi weer te geven in de viewer. Hier is ook aan een fast-api implementatie gewerkt.\n\n\n\nPubliceren op PyPi is nu mogelijk en gaat volledig automatisch via github actions, dit run je door een tag aan te maken op de github.\nDaarnaast checkt de pre-commit nu ook op docstring format zodat het netter in de ‘API reference’ komt in de documentatie. Hierdoor zijn een hele hoop docstrings aangepast.\nHet verschil tussen waterlevel(s) en hydaulicload(s) aangepakt, we voeren nu overal hydaulicload.\nMatroos was al beschikbaar, maar maakte gebruik van de timeseries endpoint. Omdat timeseries de vertaling naar reeks al op de server van matroos doet, kan dit wat traag zijn. Om dit op te lossen is na contact met het beheer van Matroos ook de maps1d endpoint toegevoegd, deze leest de ‘ruwe’ NetCDF bestanden in en vertaald ze naar een tijdreeks die in de toolbox kan worden gebruikt.\n\n\n\n\n\n\nAlle aanpassingen zijn te vinden in pull request #57\nIn Sprint 5 is gekeken naar het filteren, ontsluiten en visualiseren van inspectieresultaten. Er zijn meerdere vormen van ontsluiting toegevoegd in de Continu Inzicht Viewer:\n\nWMS-laag via link\nGeoJSON-objecten in een kaartweergave\nTabelweergave met inspectiegegevens\n\nDaarnaast zijn er diverse restpunten opgepakt, waaronder:\n\nCentrale logging: Afvangen van alle fouten tijdens de run()-uitvoering, met uitgebreide configuratiemogelijkheden.\nFragility curves functionaliteit is uitgebreid:\n\nBetere interpolatie functie\nOndersteuning voor stapfuncties\nCorrect omgaan met kleine kansen\nValidatie op monotoon stijgende curves\n\nEen integratie test is uitgevoerd om de snelheid te bepalen van de rekenmodules en waar nodig aanpassingen geweest.\n\n\n\n\nDe opmaak informatie voor kaartlagen nu uit de database opgehaald door de viewer, dit was een handmatige configuratie stap. Gebruikers kunnen op deze manier makkelijker aanpassingen doorvoeren in de viewer.\nDe logging gebruikt een nieuwe ‘baseClass’: ToolboxBase, inherit deze om logging automatische toe te voegen aan de run() functie.",
    "crumbs": [
      "Overig",
      "Changelog"
    ]
  },
  {
    "objectID": "modules_index.html",
    "href": "modules_index.html",
    "title": "Modules",
    "section": "",
    "text": "De Toolbox Continu Inzicht is in sprints ontwikkeld waarbij één of meerdere modules is ontwikkeld. Voor elke module worden Python-scripts ontwikkeld waarmee een functie kan worden uitgevoerd. Deze modules kunnen los gebruikt worden of vormen samen een geheel. Naast de functies is per module een beschrijving beschikbaar en zijn er voorbeelden hoe de code gebruikt kan worden met uitleg.\n\nBasis architectuur Toolbox Continu Inzicht\nIn de toolbox continu inzicht is een belangrijk uitgangspunt dat verschillende data formaten gebruikt kunnen worden, de functie zijn zo opgezet dat elk formaat als in of uitvoer kan dienen.\nBelastingen inlezen en classificeren\nOm inzicht te krijgen in de veiligheid van waterkeringen is het van belang om de belastingen op de waterkeringen in kaart te brengen. Dit kunnen waterstanden op het buitenwater (zee, rivieren of meren) zijn, maar ook grondwaterstanden. Er zijn verschillende functies geïmplementeerd voor het inlezen, opslaan en classificeren van historische en voorspelde belastingen.\nBepalen fragility curves\nFragility curves kunnen voor verschillende faalmechanismes worden opgesteld. In de toolbox wordt voor GEKB (overloop en golfoverslag van dijken) en STPH (piping en heave bij dijken) een functionaliteit aangeboden voor het afleiden van fragility curves. Daarnaast is het mogelijk om voor andere faalmechanismen een door de gebruiker vooraf opgestelde fragility curve te importeren.\nBijstellen fragility curves\nIn sommige gevallen is het gewenst om een fragility curve aan te passen vanwege nieuwe inzichten, bijv. vanuit beheer, na grondonderzoek of dijkverbetering. Denk hierbij aan aanpassen van het dijkprofiel of de sterkte van de ondergrond of de bekleding. Het is mogelijk om een nieuwe fragility curve te berekenen of de conditionele faalkansen aan te passen.\nConditionele kansen en status waterkering per sectie\nPer dijkvak (sectie) wordt een statusbeeld bepaald op basis van de actuele of voorspelde belasting en de fragility curve. Dit statusbeeld is voor elk dijkvak te bepalen voor elk individueel faalmechanisme of een totaalbeeld o.b.v. alle faalmechanismen.\nImpactanalyse: effect nieuwe statistiek en rekenregels op de faalkans\nEen fragility curve beschrijft de conditionele kans gegeven een belasting, zoals een waterstand. Om inzicht te krijgen in de faalkans per jaar moet de fragility curve gecombineerd worden met de kans van voorkomen van verschillende waterstanden (overschrijdingsfrequentielijn waterstanden). Hiermee is het mogelijk om het effect van veranderingen in de statistiek van de belasting, bijvoorbeeld door klimaatverandering, een systeemmaatregel zoals rivierverruiming of nieuwe rekenregels, op de faalkans per jaar te vergelijken met een referentiesituatie. De duiding van de verandering van de faalkans is in klassen van grote kansafname tot grote kanstoename. Deze klassen zijn door de gebruiker zelf te definieren.\nInspectieresultaten inlezen en weergeven\nHet statusbeeld van de dijken op basis van fragility curves, eventueel bijgesteld met een beheerdersoordeel, is te verrijken met informatie uit de inspecties. Dit kunnen historische waarnemingen zijn, maar ook de voorjaarsinspectie of een melding tijdens een calamiteiteninspectie. Met de Toolbox Continu Inzicht is het mogelijk om de inspectiedata te filteren, classificeren en kaart te tonen in de viewer van de Toolbox Continu Inzicht.",
    "crumbs": [
      "Modules"
    ]
  },
  {
    "objectID": "modules/inspectieresultaten.html",
    "href": "modules/inspectieresultaten.html",
    "title": "Inspectieresultaten inlezen en weergeven",
    "section": "",
    "text": "Filteren\nVoor het inlezen van inspectieresultaten is het wenselijk om de invoerdata te kunnen filteren. In sommige gevallen zal dit al in de data adapter gebeuren. Voor het filteren zijn drie opties te configureren:\n\nquery: SQL-achtige query om het DataFrame te filteren, zie ook pandas.DataFrame.query;\ndrop_columns: Lijst van de te verwijderen kolommen;\nkeep_columns: Lijst van de te behouden kolommen.\n\nAls de gebruiker meerdere opties configureert, zal deze in bovenstaande volgorde achtereenvolgens worden toegepast.\n\nConfiguratie queryConfiguratie kolommen behoudenConfiguratie kolommen verwijderenCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    Filter:\n        query: \"measurement_location_id == 1\"\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    inspectie_resultaten:\n        type: csv\n        path: \"resultaten.csv\"\n    inspectie_resultaten_filter:\n        type: csv\n        path: \"filter_resultaten.csv\"\n        index: False\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    Filter:\n        keep_columns:\n            - \"measurement_location_id\"\n            - \"measurement_location_code\"\n...\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    Filter:\n        drop_columns:\n            - \"unwanted_columns\"\n...\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.inspections import Filter\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nfilter = Filter(data_adapter=data_adapter)\nfilter.run(\n    input=\"inspectie_resultaten\",\n    output=\"inspectie_resultaten_filter\",\n)\n\n\n\n\n\nClassificeren van inspectieresultaten\nInspectieresultaten zijn te classificeren afhankelijk van eigenschappen in de tabel. Ook is het mogelijk om op basis van deze eigenschappen een bepaalde opmaak te tonen. Bijvoorbeeld een opmaak voor het element van de waterkering dat is geïnspecteerd (grasbekleding, steenbekleding, asfaltbekleding) of de toegekende prioriteit (score 1, 2, 3 etc) een kleur of lijndikte aan te geven. Hiervoor is een laag met resultaten nodig en een definitie van de klassegrenzen voor de te geclassificeren data, inclusief de definitie van de bijbehorende opmaak. De resultaten bevatten een geografische laag of een platte teksttabel met geometrie of x,y-coördinaten. De geografische informatie wordt altijd omgezet naar WGS84 om ondersteund te worden in de viewer. De classificatie wordt gedaan op basis van de kolom ‘classify_column’ opgegeven in de GlobalVariables. Deze kolom wordt vergeleken met de waardes in de legenda en vervolgens wordt de opmaak uit de legenda overgenomen. De waardes op basis waarvan de legenda wordt bepaald kan bestaan uit getallen of tekst. Bij tekst wordt de ‘lower_boundary’ kolom gebruikt. De viewer verwacht een heel aantal kolommen, als deze niet worden opgegeven neemt de toolbox standaardwaardes over (get_possible_styling()). Deze standaardswaardes kunnen ook aangepast worden door de gebruiker.\n\nConfiguratie getallenConfiguratie textCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    ...\n    ClassifyInspections:\n        classify_column: \"prioriteit\"\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    styling_example:\n        type: csv\n        path: \"styling_example.csv\"\n    inspectie_resultaten_filter:\n        type: csv\n        path: \"inspectie_resultaten_filter.csv\"\n        index: False\n    classify_resultaten:\n        type: shape\n        path: \"classify_resultaten.geojson\"\n        index: False\n    legenda:\n        type: csv\n        path: \"legenda.csv\"\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    ...\n    ClassifyInspections:\n        classify_column: \"opmerkingen\"\n        match_text_on: \"contains\"\n        # kan zijn: contains, equals, startswith, endswith\n...\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.inspections import Filter\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nclassify_inspections_styling = ClassifyInspections(data_adapter=data_adapter)\nclassify_inspections_styling.run(\n    input=[\"filter_resultaten\", \"styling_example\"], output=[\"classify_resultaten\", \"legenda\"]\n)\n\n\n\n\nStandaardopmaak\nDaarnaast kan de functie ook gebruikt worden om een standaardopmaak toe te kennen aan een kaartlaag. Hierdoor wordt de viewer gebruiksvriendelijker. Het invoerbestand wordt aangevuld met het benodigde aantal kolommen voor de opmaak en bijbehorende waardes. Om de standaardopmaak aan een kaartlaag-tabel toe te kennen, kan de volgende configuratie gebruikt worden:\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    kaartlaag:\n        type: csv\n        path: \"kaartlaag.csv\"\n    kaartlaag_met_opmaak:\n        type: csv\n        path: \"kaartlaag_met_opmaak.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.inspections import Filter\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nclassify_inspections_styling = ClassifyInspections(data_adapter=data_adapter)\nclassify_inspections_styling.run(\n    input=[\"kaartlaag\"], output=[\"kaartlaag_met_opmaak\"]\n)\n\n\n\n\n\n\nInspectieresultaten en de viewer\nDe kaartlagen van inspectieresultaten zijn in de viewer weer te geven. Naast de kaartlaag die in de Toolbox Continu Inzicht is geclassificeerd, kan ook een eigen WMS-kaartlaag worden gebruikt. Voor kaartlagen die relatief klein zijn, kan alle informatie in één databaseveld gestopt gedefinieerd. Bij grotere kaartlagen is het aan te raden om een nieuwe tabel te maken, waar vervolgens naar verwezen kan worden. Voor deze drie opties zal een voorbeeld worden weergegeven. De kolommen group_name, layer_name en layer_visible kunnen gebruik worden om de groepen, namen van kaartlaag en de zichtbaarheid in de viewer te configureren. De layer_type moet voor ‘geojson’, ‘wms’ en ‘table’ worden ingesteld.\n\nKleine kaartlaag in de viewer\nOm de verschillende databronnen te combineren tot één tabel kan de functie InspectionsToDatabase gebruikt worden. De input hiervoor zijn de inspectieresultaten, opmaak en kaartlagen. layers is een tabel waarin de gegevens over de verschillende kaartlagen staat beschreven. Als deze niet wordt opgegeven, wordt een standaardtabel gebruikt. De inspectieresultaten wordt toegevoegd aan de tabel layers. Indien de tabel layers meerdere rijen bevat, kan rij-index worden aangepast met index. Het maximum aantal inspectieresultaten kan aangepast worden met max_rows. Standaard is dit 10.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    ...\n    InspectionsToDatabase:\n        index: 0\n        max_rows: 10\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    classify_resultaten:\n        type: shape\n        path: \"hidden_classify_resultaten.geojson\"\n        index: False\n    legenda:\n        type: csv\n        path: \"hidden_legend.csv\"\n        index: False\n    layers:\n        type: csv\n        path: \"layers.csv\"\n    to_ci_database:\n        type: postgresql_database\n        schema: continuinzicht_demo_realtime\n        database: \"continuinzicht\"\n        table: layers\n        if_exists: append\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.inspections import InspectionsToDatabase\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\ninspections_to_database = InspectionsToDatabase(data_adapter=data_adapter)\ninspections_to_database.run(\n    input=[\"classify_resultaten\", \"legenda\", \"layers\"],\n    output=\"to_ci_database\",\n)\n\n\n\n\n\nWMS lagen in de viewer\nDe definitie voor WMS-lagen is simpeler. Hiervoor is alleen een url (layer_wms_url) nodig. In sommige gevallen is ook de layer_wms_layer, layer_wms_style en layer_wms_legend_url nodig om voldoende informatie aan de viewer te geven. Dit is een voorbeeld waarbij de data-adapter gebruikt kan worden om de database te vullen.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    ...\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    layers:\n        type: csv\n        path: \"layers.csv\"\n    to_ci_database:\n        type: postgresql_database\n        schema: continuinzicht_demo_realtime\n        database: \"continuinzicht\"\n        table: layers\n        if_exists: append\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nlayer_table = data_adapter.input('layers')\ndata_adapter.output('to_ci_database', layer_table)\n\n\n\n\n\nGrote tabel in de viewer\nOm grote kaartlagen in de viewer te tonen, is het advies om dit via een losse tabel in database te doen. Deze tabel kan dan gekoppeld worden aan de viewer op dezelfde manier als een WMS-laag via de tabel layers.",
    "crumbs": [
      "Modules",
      "Inspectieresultaten inlezen en weergeven"
    ]
  },
  {
    "objectID": "modules/bijstellen_fragility_curves.html",
    "href": "modules/bijstellen_fragility_curves.html",
    "title": "Bijstellen fragility curves",
    "section": "",
    "text": "Verschuiven van een curve\nVoor het verschuiven van een fragility curve over een opgegeven waterstandsbereik is voor alle type fragility curves de functie Shift* beschikbaar, waarbij * de naam van de functie is. Zo schuift ShiftFragilityCurveOvertopping de curve van FragilityCurveOvertopping naar links of rechts met een opgegeven stapgrootte (bijv. 0,5 voor een verschuiving van de fragility curve met 0,5m naar rechts). Belangrijk om hier te benoemen is dat de opties in GlobalVariables nog steeds moeten verwijzen naar de originele functie, ook alle andere configuraties blijven hetzelfde.\nIn het voorbeeld hieronder wordt gebruik gemaakt vanFragilityCurveOvertopping in de GlobalVariables, ook al wordt de ShiftFragilityCurveOvertopping functie aangeroepen. De verschuiving van 0,5 meter is in het ‘Code’ tabblad terug te vinden als de effect parameter (effect=0.5).\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    # default waardes, kunnen worden overschreven\n    FragilityCurveOvertopping:\n        gh_onz_mu: 0.96\n        gh_onz_sigma: 0.27\n        gp_onz_mu_tp: 1.03\n        gp_onz_sigma_tp: 0.13\n        gp_onz_mu_tspec: 1.03\n        gp_onz_sigma_tspec: 0.13\n        gh_onz_aantal: 7\n        gp_onz_aantal: 7\n        tp_tspec: 1.1\n        lower_limit_coarse: 4.0\n        upper_limit_coarse: 2.0\n        upper_limit_fine: 1.0\n        hstap: 0.05\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    slopes:\n        type: csv\n        file: \"slopes.csv\"\n    profiles:\n        type: csv\n        file: \"profiles.csv\"\n    bedlevel_fetch:\n        type: csv\n        file: \"bedlevelfetch.csv\"\n    fragility_curves:\n        type: csv\n        file: \"fragility_curves.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.fragility_curves import ShiftFragilityCurveOvertopping\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nshifted_fragility_curve_overtopping = ShiftFragilityCurveOvertopping(data_adapter=data_adapter)\nshifted_fragility_curve_overtopping.run(\n    input=[\"slopes\", \"profiles\", \"bedlevel_fetch\"],\n    output=\"fragility_curves\",\n    effect=0.5\n)\n\n\n\n\n\nAanpassen van de kruinhoogte\nVoor het aanpassen van de kruinhoogte bij een GEKB is de functie ChangeCrestHeightFragilityCurveOvertopping beschikbaar, hier kan als effect mee gegeven worden wat de verandering van kruinhoogte is. De zelfde berekening als bij FragilityCurveOvertopping wordt dan uitgevoerd, maar met de aangepaste kruin hoogte.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\n    # default waardes, kunnen worden overschreven\n    FragilityCurveOvertopping:\n        gh_onz_mu: 0.96\n        gh_onz_sigma: 0.27\n        gp_onz_mu_tp: 1.03\n        gp_onz_sigma_tp: 0.13\n        gp_onz_mu_tspec: 1.03\n        gp_onz_sigma_tspec: 0.13\n        gh_onz_aantal: 7\n        gp_onz_aantal: 7\n        tp_tspec: 1.1\n        lower_limit_coarse: 4.0\n        upper_limit_coarse: 2.0\n        upper_limit_fine: 1.0\n        hstap: 0.05\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    slopes:\n        type: csv\n        file: \"slopes.csv\"\n    profiles:\n        type: csv\n        file: \"profiles.csv\"\n    bedlevel_fetch:\n        type: csv\n        file: \"bedlevelfetch.csv\"\n    fragility_curves:\n        type: csv\n        file: \"fragility_curves.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.fragility_curves import ChangeCrestHeightFragilityCurveOvertopping\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nchange_crest_fragility_curve_overtopping = ChangeCrestHeightFragilityCurveOvertopping(data_adapter=data_adapter)\nchange_crest_fragility_curve_overtopping.run(\n    input=[\"slopes\", \"profiles\", \"bedlevel_fetch\"],\n    output=\"fragility_curves\",\n    effect=1\n)",
    "crumbs": [
      "Modules",
      "Bijstellen fragility curves"
    ]
  },
  {
    "objectID": "modules/belastingen.html",
    "href": "modules/belastingen.html",
    "title": "Belastingen inlezen en classificeren",
    "section": "",
    "text": "Om inzicht te krijgen in de veiligheid van waterkeringen is het van belang om de belastingen op de waterkeringen in kaart te brengen. Dit kunnen waterstanden op het buitenwater (zee, rivieren of meren) zijn, maar ook grondwaterstanden. De belastingen worden eerst ingelezen uit verschillende databronnen en vervolgens geclassificeerd. De belastingen worden ingelezen voor verschillende momenten (bijv. gister, nu, morgen of overmorgen etc.), zodat naast metingen ook voorspellingen van belastingen worden ingelezen.\n\nBelastingen inlezen\nDe volgende databronnen worden op dit moment in de Toolbox Continu Inzicht ondersteund:\n\nDelft-FEWS\n(Noos)Matroos\nRWS waterwebservices\nRWS waterinfo\n\n\nAquo standaard\nDe standaard ondersteunde belastingen zetten de parameters om in het Aquo standaard formaat met parameter id, code en omschrijving (naam). Elke functie roept de functie base.aquo.read_aquo() aan, hierbij wordt ook gekeken naar de GlobalVariables voor een aquo_allias. Op die manier is het ook mogelijk om andere parameters, bijvoorbeeld uit FEWS, te koppelen aan een Aquo grootheid. De meta data die gebruikt wordt voor deze standaard is te vinden onder Aquo grootheden.\n\n\nDelft-FEWS\nVeel waterschappen gebruiken een Delft - Forecast Early Warning System (FEWS) implementatie voor het beheren van verschillende interne en externe informatiebronnen. Via de REST API van FEWS kunnen verschillende belastingen worden ingelezen. Toegang verkrijgen tot een FEWS is complexer dan andere bronnen, waardoor het noodzakelijk is om extra parameters te definiëren in het configuratiebestand. De functie get_fews_locations() kan worden gebruikt om de beschikbare locaties te tonen.\nGlobalVariables:\n    rootdir: \"data_sets\"  \n    moments: [-24,0,24,48]\n    aquo_allias:\n        WNSHDB1: \"WATHTE\"\n\n\n    LoadsFews:\n        host: \"https:**********\"\n        port: ****\n        region: \"fewspiservice\"\n        version: \"1.25\"\n        filter: \"HKV_WV_1\"\n        parameters: [\"WNSHDB1\"]  \n       \n\nDataAdapter:\n    ...\n\nGlobalVariables:\n\nrootdir: Bestandslocatie van de invoer- en uitvoerbestanden\nmoments: Momenten in uren waar gegevens voor opgehaald moet worden (bijv. -24, 0, +24, +48, +72 uur)\n\n\n\nLoadsFews:\n\nhost: FEWS PI REST URL\nport: FEWS PI REST poortnummer\nregion: FEWS PI REST regionaam\nversion: FEWS PI versienummer\nfilter: Filternaam zoals deze in FEWS wordt gebruikt\nparameters: Parameternaam zoals deze in FEWS wordt gebruikt\n\n\n\nInvoer schema locaties:\n\nmeasurement_location_id (int): Meetlocatie id\nmeasurement_location_code (str): Meetlocatie code\nmeasurement_location_description (str): Meetlocatie omschrijving/naam\n\n\n\nUitvoer schema:\n\nmeasurement_location_id (int): Meetlocatie id\nmeasurement_location_code (str): Meetlocatie code\nmeasurement_location_description (str): Meetlocatie omschrijving/naam\nparameter_id (int): Parameter id overeenkomstig Aquo-standaard\nparameter_code (str): Parameter code overeenkomstig Aquo-standaard\nparameter_description (str): Parameter omschrijving overeenkomstig Aquo-standaard\nunit (str): Eenheid van de waarde\ndate_time (datetime): Datum en tijd van de waarde\nvalue (float): Waarde\nvalue_type (str): Type waarde: meting of verwachting\n\n\n\n\nMatroos\nMatroos of Multifunctional Access Tool for Operational Oceandata Services is een webbased distributiesysteem van de operationele verwachtingen van waterstanden, stroming, debieten en golven, van onder meer het Watermanagementcentrum Nederland. Matroos is beschikbaar voor verschillende doelgroepen, waarvan er op dit moment drie relevant zijn voor de ontwikkeling van de Toolbox Continu Inzicht. De verschillende versies worden in de tabel hieronder toegelicht. Voor meer informatie verwijzen we naar de nieuwsbrief op iplo.nl. In de Toolbox wordt nu alleen de series API gebruikt, dus volstaat NOOS.\n\n\n\nURL\nType\nInhoud\nDoelgroep\n\n\n\n\nvitaal.matroos.rws.nl\nextern, vitaal\n21 dagen\nKustwacht, Waterschappen\n\n\nmatroos.rws.nl\nextern\nVolledige historie\nWaterschappen, universiteiten, externe\n\n\nnoos.matroos.rws.nl\nextern, open\nBeperkte set; series:volledig; maps: 14 dagen\nNOOS internationaal, Open Data\n\n\n\nIn Matroos zijn verschillende bronnen beschikbaar, met get_matroos_sources() kan een lijst van deze worden gegeneerd. De beschikbare locaties kunnen worden weergegeven met get_matroos_locations(), met mogelijkheid om te filteren op een bron en parameter.\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    moments: [-24,0,24,48]\n    ...\n\n    LoadsMatroos:\n        website: \"noos\" # noos, vitaal of matroos\n        model: \"observed\"\n        parameters: [\"WATHTE\"]\n\nDataAdapter:\n    ...\nVoor het gebruik van vitaal.matroos en matroos is een gebruikersnaam en wachtwoord nodig. Deze moeten in de environmental variables worden meegegeven (.env bestand).\nvitaal_user: \"...\"\nvitaal_password: \"...\"\n# of\nmatroos_user: \"...\"\nmatroos_password: \"...\"\n\n\nRWS WaterWebservices\nVia de RWS WaterWebservices zijn metingen en verwachtingen van o.a. waterstanden beschikbaar via de WaterWebservices API. Vooral langs de rivieren zijn veel meetpunten beschikbaar. Deze API is openbaar en vereist weinig configuratie. De MISSING_VALUE kan in de configuratie worden aangepast, maar staat al standaard ingesteld.\n    LoadsWaterwebservicesRWS:\n        parameters:  [\"WATHTE\"]\nBeschikbare locaties kunnen worden weergegeven met get_rws_webservices_locations().\n\n\nRWS Waterinfo\nNaast de RWS WaterWebservices is alle informatie van Rijkswaterstaat ook verkrijgbaar via waterinfo.rws.nl. Waterinfo is bedoeld als informatieportaal, en niet als API om data op te halen. Voordat de WaterWebservices API beschikbaar was, werd de Waterinfo-website gebruikt in verschillende Continu Inzicht systemen. Om de comptabiliteit met deze oudere Continu Inzicht systemen te behouden, is deze functie nu nog wel beschikbaar in de Toolbox Continu Inzicht. Wel is in de toekomst mogelijk dat door veranderingen aan de Waterinfo-website deze ondersteuning komt te vervallen.\n GlobalVariables:\n    rootdir: \"data_sets\"\n    moments: [-24,48]\n\n    LoadsWaterinfo:\n        parameters: [\"waterhoogte\"]\nOmdat data ophalen uit Waterinfo gevoeliger is, worden de verschillende parameters hieronder weergegeven.\n\nWaterhoogteWindsnelheidGolfhoogteWatertemperatuurLuchttemperatuurAstronomisch getijStroomsnelheidDebietChloride\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nWaterhoogte in cm\nwaterhoogte\n2d terug, 2d vooruit: -48,486u terug, 3u vooruit: -6,39d terug, 2d vooruit: -216,4828d terug: -672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nWindsnelheid in m/s\nwind\n2d terug: -48,486u terug: -6,39d terug: -216,4828d terug: -672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nGolfhoogte in cm\ngolfhoogte\n2d terug, 2d vooruit: -48,486u terug, 3u vooruit: -6,39d terug, 2d vooruit: -216,4828d terug: -672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nWatertemperatuur in °C\nwatertemperatuur\n2d terug: -48,06u terug: -6,09d terug: -216,028d terug:-672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nLuchttemperatuur in °C\nluchttemperatuur\n2d terug: -48,06u terug: -6,09d terug: -216,028d terug:-672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nAstronomisch getij\nastronomische-getij\n2d terug, 2d vooruit: -48,486u terug, 3u vooruit:-6,39d terug, 2d vooruit: -216,4828d terug:-672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nStroomsnelheid in m/s\nstroming\n2d terug: -48,06u terug:-6,09d terug: -216,028d terug:-672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nDebiet in m3/s\nwaterafvoer\n2d terug, 2d vooruit: -48,486u terug, 3u vooruit: -6,39d terug, 2d vooruit:-216,4828d terug:-672,0\n\n\n\n\n\n\n\n\n\n\n\n\n\nomschrijving\nmaptype\nperiode\n\n\n\n\nChloride in mg/l\nzouten\n2d terug: -48,06u terug: -6,09d terug: -216,028d terug:-672,0\n\n\n\n\n\n\n\n\nInvoer schema locaties:\n\nmeasurement_location_id (int): Meetlocatie id\nmeasurement_location_code (str): Meetlocatie code\nmeasurement_location_description (str): Meetlocatie omschrijving/naam\n\n\n\nUitvoer schema:\n\nmeasurement_location_id (int): Meetlocatie id\nmeasurement_location_code (str): Meetlocatie code\nmeasurement_location_description (str): Meetlocatie omschrijving/naam\nparameter_id (int): Parameter id overeenkomstig Aquo-standaard\nparameter_code (str): Parameter code overeenkomstig Aquo-standaard\nparameter_description (str): Parameter omschrijving overeenkomstig Aquo-standaard\nunit (str): Eenheid van de waarde\ndate_time (datetime): Datum en tijd van de waarde\nvalue (float): Waarde\nvalue_type (str): Type waarde: meting of verwachting\n\n\n\n\n\nClassificeren van belastingen\nDe verschillende hierboven benoemde functies voor het inlezen van belastingen geven een tijdreeks terug op bepaalde punten. Deze kunnen omgezet worden naar moment, geclassificeerd met grenswaardes en toegekend aan dijkvakken.\n\nTijdreeks naar momenten\nDe ingelezen tijdsreeks met belastingen wordt omgezet naar belastingen op specifieke momenten met LoadsToMoments.\nVoor gebieden waar het getij van invloed is, is een aanvullende configuratie nodig. Bij getij wordt de maximale belasting tijdens een getijdencyclus (+/-12.25 uur) bepaald. Zonder deze configuratie wordt de belasting exact op het vooraf gedefinieerde moment bepaald.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    moments: [-24,0,24,48]\n\n    LoadsToMoments:\n        tide: true\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    waterstanden_waterinfo:\n        type: csv\n        path: \"waterstanden_waterinfo.csv\"\n    waterstanden_waterinfo_maxima:\n        type: csv\n        path: \"waterstanden_waterinfo_maxima.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.loads import LoadsToMoments\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nmoments = LoadsToMoments(data_adapter=data_adapter)\nmoments.run(input=\"waterstanden_waterinfo\", output=\"waterstanden_waterinfo_maxima\")\n\n\n\n\n\nClassificeren van belastingen\nMet LoadsClassify kunnen met vooraf gedefinieerde grenswaardes de belastingen worden geclassificeerd, bijvoorbeeld als waterstand die 1 keer per 100 jaar voorkomt. Hierbij moeten de data-adapters van de grenswaardes en belastingen worden doorgegeven in een lijst. Hierbij is de volgorde van de lijst belangrijk: eerst grenswaardes en dan belastingen. De belastingen moeten voor het classificeren aangeleverd worden als momentwaardes.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_demo\"\n    moments: [-24,0,24,48]\n\n    LoadsMaxima:\n        tide: False\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    waterstanden_waterinfo_maxima:\n        type: csv\n        path: \"waterstanden_waterinfo_maxima.csv\"\n    waterinfo_klassengrenzen:\n        type: csv\n        path: \"klassengrenzen.csv\"\n    waterstanden_waterinfo_klassen:\n        type: csv\n        path: \"waterstanden_waterinfo_klassen.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.loads import LoadsClassify\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nclassify = LoadsClassify(data_adapter=data_adapter)\nclassify.run(\n    input=[\"waterinfo_klassengrenzen\", \"waterstanden_waterinfo_maxima\"],\n    output=\"waterstanden_waterinfo_klassen\",\n)\n\n\n\n\n\nToekennen van belastingen aan secties\nDe belastingen zijn nu beschikbaar op de meetlocaties van FEWS, Matroos, RWS Waterinfo of RWS WaterWebServices. De volgende stap is het vertalen van de belastingen in de meetpunten naar de secties (dijkvakken of kunstwerken) via SectionsLoads. Voor het toekennen van belastingen aan secties zijn drie databronnen nodig: de dijkvakken, de belastingen en een koppeling tussen dijkvakken en belastinglocaties. De drie data-adapters worden vervolgens doorgegeven als een lijst. Hierbij is de eerder genoemde volgorde van belang: dijkvakken, belastingen en koppeling dijkvakken en belastinglocaties. Als een sectie tussen twee meetpunten ligt, wordt een interpolatiealgoritme (bijv. 25% waarde in meetpunt 1 + 75% waarde in meetpunt 2) toegepast. Omdat dit lokaal kan verschillen hoe deze interpolatie wordt gemaakt, is er geen automatische script voor. De interpolatie moet dus vooraf gedefinieerd worden door de gebruiker en wordt meegegeven bij de koppeling tussen dijkvakken en belastinglocaties. Hierbij wordt gebruik gemaakt van fractionup en fractiondown om het gewicht van de bovenstroomse en benedenstroomse belastinglocatie te bepalen.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_demo\"\n    moments: [-24,0,24,48]\n\n    SectionsLoads:\n        MISSING_VALUE: -9999.0\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    dijkvakken:\n        type: csv\n        path: \"dijkvakken.csv\"\n    waterstanden:\n        type: csv\n        path: \"waterstanden_waterinfo.csv\"\n    koppeling_dijkvak_belastinglocatie:\n        type: csv\n        path: \"dijkvak_belastinglocatie.csv\"\n    waterstanden_per_dijkvak:\n        type: csv\n        path: \"waterstanden_per_dijkvak.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.sections import SectionsLoads\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nsections_loads = SectionsLoads(data_adapter=data_adapter)\nsections_loads.run(\n    input=[\"dijkvakken\", \"waterstanden\", \"koppeling_dijkvak_belastinglocatie\"],\n    output=\"waterstanden_per_dijkvak\",\n)",
    "crumbs": [
      "Modules",
      "Belastingen inlezen en classificeren"
    ]
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installatie-instructies",
    "section": "",
    "text": "De Toolbox Continu Inzicht kan op verschillende manieren worden gebruikt:\n\nAls vervanging van de huidige Continu Inzicht back-end\nAls losstaande modules\nAls ontwikkelaar\n\n\n\nOm de toolbox als vervanging van de huidige Continu Inzicht back-end te gebruiken, zal in de toekomst meer informatie beschikbaar gesteld worden. De oude back-end kan met weinig aanpassingen worden vervangen door de nieuwe code. Verdere aanpassingen die in de toolbox worden gedaan, kunnen dan worden meegenomen.\n\n\n\nOm de toolbox als losstaande modules te gebruiken kan je de code downloaden van PyPi.\npip install toolbox-continu-inzicht\nVanwege het aantal afhankelijkheden is het aan te raden om een nieuwe conda environment te gebruiken. Hiervoor kan gebruik gemaakt worden van de requirements.yaml in de source map op GitHub. Met het volgende conda commando kan deze worden geïnstalleerd.\nconda env create --file=https://raw.githubusercontent.com/continu-inzicht/toolbox-continu-inzicht/refs/heads/main/src/requirements.yaml\n\n\n\nWe maken gebruik van pixi om de conda environment te beheren en delen, dit kent een wat steilere leer curve en wordt daarom vooral aan ontwikkelaar aangeboden.\n\n\niwr -useb https://pixi.sh/install.ps1 | iex\n\n\n\ncurl -fsSL https://pixi.sh/install.sh | bash\n\n\n\nMet het Pixi commando in powershell kun je vervolgens de juiste python bestanden installeren:\n cd ..../toolbox-continu-inzicht\n pixi install\nDit kan even duren, Pixi gebruikt het pixi.lock bestand op de juiste packages te laden en zet deze in de .pixi map.\nZie de ‘Richtlijnen voor bijdragen aan Toolbox Continu Inzicht’ voor meer informatie.",
    "crumbs": [
      "Installeren",
      "Installatie-instructies"
    ]
  },
  {
    "objectID": "install.html#vervanging",
    "href": "install.html#vervanging",
    "title": "Installatie-instructies",
    "section": "",
    "text": "Om de toolbox als vervanging van de huidige Continu Inzicht back-end te gebruiken, zal in de toekomst meer informatie beschikbaar gesteld worden. De oude back-end kan met weinig aanpassingen worden vervangen door de nieuwe code. Verdere aanpassingen die in de toolbox worden gedaan, kunnen dan worden meegenomen.",
    "crumbs": [
      "Installeren",
      "Installatie-instructies"
    ]
  },
  {
    "objectID": "install.html#losstaande-modules",
    "href": "install.html#losstaande-modules",
    "title": "Installatie-instructies",
    "section": "",
    "text": "Om de toolbox als losstaande modules te gebruiken kan je de code downloaden van PyPi.\npip install toolbox-continu-inzicht\nVanwege het aantal afhankelijkheden is het aan te raden om een nieuwe conda environment te gebruiken. Hiervoor kan gebruik gemaakt worden van de requirements.yaml in de source map op GitHub. Met het volgende conda commando kan deze worden geïnstalleerd.\nconda env create --file=https://raw.githubusercontent.com/continu-inzicht/toolbox-continu-inzicht/refs/heads/main/src/requirements.yaml",
    "crumbs": [
      "Installeren",
      "Installatie-instructies"
    ]
  },
  {
    "objectID": "install.html#als-ontwikkelaar",
    "href": "install.html#als-ontwikkelaar",
    "title": "Installatie-instructies",
    "section": "",
    "text": "We maken gebruik van pixi om de conda environment te beheren en delen, dit kent een wat steilere leer curve en wordt daarom vooral aan ontwikkelaar aangeboden.\n\n\niwr -useb https://pixi.sh/install.ps1 | iex\n\n\n\ncurl -fsSL https://pixi.sh/install.sh | bash\n\n\n\nMet het Pixi commando in powershell kun je vervolgens de juiste python bestanden installeren:\n cd ..../toolbox-continu-inzicht\n pixi install\nDit kan even duren, Pixi gebruikt het pixi.lock bestand op de juiste packages te laden en zet deze in de .pixi map.\nZie de ‘Richtlijnen voor bijdragen aan Toolbox Continu Inzicht’ voor meer informatie.",
    "crumbs": [
      "Installeren",
      "Installatie-instructies"
    ]
  },
  {
    "objectID": "examples/notebooks/5.inspectieresultaten.html",
    "href": "examples/notebooks/5.inspectieresultaten.html",
    "title": "Inspectieresultaten",
    "section": "",
    "text": "from pathlib import Path\n\nfrom toolbox_continu_inzicht.base.config import Config\nfrom toolbox_continu_inzicht.base.data_adapter import DataAdapter\n\n\npath = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=path / \"example_inspection.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\n\n\ndata_adapter.input(\"inspections_results\")\n\n\n\n\n\n\n\n\nlocation_id\nprioriteit\nx\ny\nopmerking\ndatum\ntijd\nwaterschap\n\n\n\n\n0\n0\n0\n5.533930\n52.596911\nfoutje\n2-4-2025\n09:08\nZuiderzeeland\n\n\n1\n1\n1\n5.451603\n52.540697\nscheurvorming\n28-3-2025\n15:48\nZuiderzeeland\n\n\n2\n2\n3\n5.407599\n52.497642\nopschot\n28-3-2025\n15:50\nZuiderzeeland\n\n\n3\n3\n11\n5.616243\n52.602794\nbeginnende scheurvorming\n31-3-2025\n09:02\nZuiderzeeland\n\n\n\n\n\n\n\nFilter resultaten uit de input tabel:\nGlobalVariables:\n    \n    ...\n\n    Filter:\n        query: \"prioriteit &gt; 0\"\n        drop_columns:\n            - \"waterschap\"\n            - \"location_id\"\n\nfrom toolbox_continu_inzicht.inspections.filter import Filter\n\n\nfilter = Filter(data_adapter=data_adapter)\nfilter.run(input=\"inspections_results\", output=\"filter_resultaten\")\n\n\nfilter.df_out\n\n\n\n\n\n\n\n\nprioriteit\nx\ny\nopmerking\ndatum\ntijd\n\n\n\n\n1\n1\n5.451603\n52.540697\nscheurvorming\n28-3-2025\n15:48\n\n\n2\n3\n5.407599\n52.497642\nopschot\n28-3-2025\n15:50\n\n\n3\n11\n5.616243\n52.602794\nbeginnende scheurvorming\n31-3-2025\n09:02\n\n\n\n\n\n\n\nDe gefilterde tabel kunnen we vervolgens classificeren Als we geen opmaak informatie meegeven in de input wordt de standaard opmaak toegepast\n\nfrom toolbox_continu_inzicht.inspections.inspections import ClassifyInspections\n\n\nclassify_inspections = ClassifyInspections(data_adapter=data_adapter)\nclassify_inspections.run(input=\"filter_resultaten\", output=\"classify_resultaten\")\n\n\nclassify_inspections.df_out\n\n\n\n\n\n\n\n\nprioriteit\nx\ny\nopmerking\ndatum\ntijd\ngeometry\nsymbol\nweight\nradius\nfillColor\ndashArray\nfillOpacity\ncolor\nopacity\n\n\n\n\n0\n1\n5.451603\n52.540697\nscheurvorming\n28-3-2025\n15:48\nPOINT (5.4516 52.5407)\nCircleMarker\n3.0\n10.0\n#9e9e9e\nNaN\n0.2\n#9e9e9e\n1.0\n\n\n1\n3\n5.407599\n52.497642\nopschot\n28-3-2025\n15:50\nPOINT (5.4076 52.49764)\nCircleMarker\n3.0\n10.0\n#9e9e9e\nNaN\n0.2\n#9e9e9e\n1.0\n\n\n2\n11\n5.616243\n52.602794\nbeginnende scheurvorming\n31-3-2025\n09:02\nPOINT (5.61624 52.60279)\nCircleMarker\n3.0\n10.0\n#9e9e9e\nNaN\n0.2\n#9e9e9e\n1.0\n\n\n\n\n\n\n\nAls we wel styling mee geven wordt dit toegepast\n\ndata_adapter.input(\"styling_example\")\n\n\n\n\n\n\n\n\nid\nname\ndescription\ncolor\nlower_boundary\nupper_boundary\n\n\n\n\n0\n2\n1\nNaN\n#a9070f\n0.9\n1.1\n\n\n1\n3\n2\nNaN\n#07a9a1\n1.9\n2.1\n\n\n2\n4\n3\nNaN\n#0760a9\n2.9\n3.1\n\n\n3\n4\n4\nNaN\n#5007a9\n3.9\n4.1\n\n\n\n\n\n\n\nIn de config moeten we alleen de kolom opgeven waarop geclassificeerd wordt.\nGlobalVariables:\n    \n    ...\n\n    ClassifyInspections:\n        classify_column: \"prioriteit\"\n\nclassify_inspections_styling = ClassifyInspections(data_adapter=data_adapter)\nclassify_inspections_styling.run(\n    input=[\"filter_resultaten\", \"styling_example\"], output=\"classify_resultaten\"\n)\n\n\nclassify_inspections_styling.df_out\n\n\n\n\n\n\n\n\nprioriteit\nx\ny\nopmerking\ndatum\ntijd\ngeometry\nsymbol\ncolor\ndashArray\nfillOpacity\nopacity\nweight\nradius\nfillColor\n\n\n\n\n0\n1\n5.451603\n52.540697\nscheurvorming\n28-3-2025\n15:48\nPOINT (5.4516 52.5407)\nCircleMarker\n#a9070f\nNaN\n0.2\n1.0\n3.0\n10.0\n#9e9e9e\n\n\n1\n3\n5.407599\n52.497642\nopschot\n28-3-2025\n15:50\nPOINT (5.4076 52.49764)\nCircleMarker\n#0760a9\nNaN\n0.2\n1.0\n3.0\n10.0\n#9e9e9e\n\n\n2\n11\n5.616243\n52.602794\nbeginnende scheurvorming\n31-3-2025\n09:02\nPOINT (5.61624 52.60279)\nCircleMarker\n#9e9e9e\nNaN\n0.2\n1.0\n3.0\n10.0\n#9e9e9e\n\n\n\n\n\n\n\nStel we willen naast color ook fillColor toevoegen en een Marker met symbool in plaats van rondje, dan zetten we deze kolom ook in de opmaak tabel\n\ndata_adapter.input(\"more_styling_example\")\n\n\n\n\n\n\n\n\nid\nname\ndescription\ncolor\nfillColor\ngeometry_type\nlower_boundary\nupper_boundary\n\n\n\n\n0\n2\n1\nNaN\n#a9070f\n#a9070f\nMarker\n0.9\n1.1\n\n\n1\n3\n2\nNaN\n#07a9a1\n#07a9a1\nMarker\n1.9\n2.1\n\n\n2\n4\n3\nNaN\n#0760a9\n#0760a9\nMarker\n2.9\n3.1\n\n\n3\n5\n4\nNaN\n#5007a9\n#5007a9\nMarker\n3.9\n4.1\n\n\n\n\n\n\n\n\nclassify_inspections_more_styling = ClassifyInspections(data_adapter=data_adapter)\nclassify_inspections_more_styling.run(\n    input=[\"filter_resultaten\", \"more_styling_example\"], output=\"classify_resultaten\"\n)\n\nEn dan zien we dat fillColor nu ook geclassificeerd is:\n\ndata_adapter.input(\"inspections_results\")\n\n\n\n\n\n\n\n\nlocation_id\nprioriteit\nx\ny\nopmerking\ndatum\ntijd\nwaterschap\n\n\n\n\n0\n0\n0\n5.533930\n52.596911\nfoutje\n2-4-2025\n09:08\nZuiderzeeland\n\n\n1\n1\n1\n5.451603\n52.540697\nscheurvorming\n28-3-2025\n15:48\nZuiderzeeland\n\n\n2\n2\n3\n5.407599\n52.497642\nopschot\n28-3-2025\n15:50\nZuiderzeeland\n\n\n3\n3\n11\n5.616243\n52.602794\nbeginnende scheurvorming\n31-3-2025\n09:02\nZuiderzeeland\n\n\n\n\n\n\n\n\nclassify_inspections_more_styling.df_out\n\n\n\n\n\n\n\n\nprioriteit\nx\ny\nopmerking\ndatum\ntijd\ngeometry\nsymbol\ncolor\nfillColor\nopacity\n\n\n\n\n0\n1\n5.451603\n52.540697\nscheurvorming\n28-3-2025\n15:48\nPOINT (5.4516 52.5407)\nMarker\n#a9070f\n#a9070f\n1.0\n\n\n1\n3\n5.407599\n52.497642\nopschot\n28-3-2025\n15:50\nPOINT (5.4076 52.49764)\nMarker\n#0760a9\n#0760a9\n1.0\n\n\n2\n11\n5.616243\n52.602794\nbeginnende scheurvorming\n31-3-2025\n09:02\nPOINT (5.61624 52.60279)\nMarker\n#9e9e9e\n#9e9e9e\n1.0\n\n\n\n\n\n\n\nDit is al een geo object wat we hier kunnen tonen\n\nimport geopandas as gpd\n\n\nax = classify_inspections_more_styling.df_out.plot()\ngpd.read_file(path / \"provincie_flevoland.geojson\").plot(\n    ax=ax, color=\"white\", edgecolor=\"black\", zorder=-1\n)\n\n\n\n\n\n\n\n\nVoor de viewer is een legenda tabel ook nuttig, deze kan als extra output worden opgegeven\n\nclassify_inspections_more_styling = ClassifyInspections(data_adapter=data_adapter)\nclassify_inspections_more_styling.run(\n    input=[\"filter_resultaten\", \"more_styling_example\"],\n    output=[\"classify_resultaten\", \"legenda\"],\n)\n\n\nclassify_inspections_more_styling.df_legend_out\n\n\n\n\n\n\n\n\nid\nname\ndescription\ncolor\nfillColor\ngeometry_type\nlower_boundary\nupper_boundary\nopacity\n\n\n\n\n0\n2\n1\nNaN\n#a9070f\n#a9070f\nMarker\n0.9\n1.1\n1.0\n\n\n1\n3\n2\nNaN\n#07a9a1\n#07a9a1\nMarker\n1.9\n2.1\nNaN\n\n\n2\n4\n3\nNaN\n#0760a9\n#0760a9\nMarker\n2.9\n3.1\nNaN\n\n\n3\n5\n4\nNaN\n#5007a9\n#5007a9\nMarker\n3.9\n4.1\nNaN\n\n\n\n\n\n\n\nVervolgens kan de output van de inspecties klaar gezet worden voor de database\n\nfrom toolbox_continu_inzicht.inspections.inspections import InspectionsToDatabase\n\n\ninspections_to_database = InspectionsToDatabase(data_adapter=data_adapter)\ninspections_to_database.run(\n    input=[\"classify_resultaten\", \"legenda\"],\n    output=\"example_to_database\",\n)\n\nSkipping field tijd: unsupported OGR type: 10\n\n\n\ninspections_to_database.df_out\n\n\n\n\n\n\n\n\ngroup_name\nlayer_name\nlayer_visible\nlayer_type\nlayer_data\nlayer_legend\n\n\n\n\n0\nExtra Kaartlagen\nInspectieresultaten\ntrue\ngeojson\n{\"type\": \"FeatureCollection\", \"features\": [{\"i...\n[{\"id\": 2, \"name\": 1, \"description\": \"\", \"colo...\n\n\n\n\n\n\n\nAls we niks op geven in de als layers wordt er automatisch een aantal standaard opties overgenomen\n\ninspections_to_database.df_in_layers\n\n\n\n\n\n\n\n\ngroup_name\nlayer_name\nlayer_visible\nlayer_type\n\n\n\n\n0\nExtra Kaartlagen\nInspectieresultaten\ntrue\ngeojson\n\n\n\n\n\n\n\nDeze kan ook uitgebreider\n\ndata_adapter.input(\"layers\")\n\n\n\n\n\n\n\n\ngroup_name\nlayer_name\nlayer_visible\nlayer_type\nlayer_table\nlayer_wms_url\nlayer_wms_layer\nlayer_wms_style\nlayer_wms_legend_url\nlayer_data\nlayer_legend\n\n\n\n\n0\nExtra Kaartlagen\nGeojson met data\nTrue\ngeojson\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nExtra Kaartlagen\nWMS test\nTrue\nwms\nNaN\nhttps://geo.hkvservices.nl/geoserver/wms\nWaterdiepte\nliwo_waterdiepte_band1\nNaN\nNaN\nNaN\n\n\n2\nExtra Kaartlagen\ntable test\nTrue\ntable\nareas\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nGlobalVariables:\n    \n    ...\n\n    InspectionsToDatabase:\n        index: 2\n\ninspections_to_database = InspectionsToDatabase(data_adapter=data_adapter)\ninspections_to_database.run(\n    input=[\"classify_resultaten\", \"legenda\", \"layers\"],\n    output=\"example_to_database\",\n)\n\nSkipping field tijd: unsupported OGR type: 10\n\n\n\ninspections_to_database.df_out\n\n\n\n\n\n\n\n\ngroup_name\nlayer_name\nlayer_visible\nlayer_type\nlayer_table\nlayer_wms_url\nlayer_wms_layer\nlayer_wms_style\nlayer_wms_legend_url\nlayer_data\nlayer_legend\n\n\n\n\n0\nExtra Kaartlagen\nGeojson met data\nTrue\ngeojson\nNaN\nNaN\nNaN\nNaN\nNaN\n{\"type\": \"FeatureCollection\", \"features\": [{\"i...\n[{\"id\": 2, \"name\": 1, \"description\": \"\", \"colo...\n\n\n1\nExtra Kaartlagen\nWMS test\nTrue\nwms\nNaN\nhttps://geo.hkvservices.nl/geoserver/wms\nWaterdiepte\nliwo_waterdiepte_band1\nNaN\n\n\n\n\n2\nExtra Kaartlagen\ntable test\nTrue\ntable\nareas\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nTot nu toe was alles lokaal naar csv, maar dit kan juist naar de database\n\npath = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=path / \"example_inspection_db.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\n\n\ninspections_to_database.df_in_layers\n\n\n\n\n\n\n\n\ngroup_name\nlayer_name\nlayer_visible\nlayer_type\nlayer_table\nlayer_wms_url\nlayer_wms_layer\nlayer_wms_style\nlayer_wms_legend_url\nlayer_data\nlayer_legend\n\n\n\n\n0\nExtra Kaartlagen\nGeojson met data\nTrue\ngeojson\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nExtra Kaartlagen\nWMS test\nTrue\nwms\nNaN\nhttps://geo.hkvservices.nl/geoserver/wms\nWaterdiepte\nliwo_waterdiepte_band1\nNaN\nNaN\nNaN\n\n\n2\nExtra Kaartlagen\ntable test\nTrue\ntable\nareas\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nOmdat database interactie op GitHub niet mogelijk wordt de onderstaande cell niet uitgevoerd, lokaal kan dit uiteraard wel\n\n# inspections_to_database = InspectionsToDatabase(data_adapter=data_adapter)\n# inspections_to_database.run(\n#     input=[\"classify_resultaten\", \"legenda\", \"layers\"],\n#     output=\"to_ci_database\",\n# )",
    "crumbs": [
      "Voorbeelden",
      "Inspectieresultaten"
    ]
  },
  {
    "objectID": "examples/notebooks/3.fragility_curve_overtopping.html",
    "href": "examples/notebooks/3.fragility_curve_overtopping.html",
    "title": "Fragility Curve Overtopping",
    "section": "",
    "text": "Voor het berekenen van een fragility curve voor het mechanisme GEKB wordt gebruikt gemaakt van de pydra_core module, meer documentatie over de pydra_core module is hier te vinden.\nDe module wordt gebruikt om een overslag debiet te berekenen voor verschillende omstandigheden en op basis hiervan wordt een fragility curve opgesteld.\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\n\nfrom toolbox_continu_inzicht.fragility_curves import (\n    ChangeCrestHeightFragilityCurveOvertopping,\n    FragilityCurveOvertopping,\n    ShiftFragilityCurveOvertopping,\n)\nfrom toolbox_continu_inzicht.base.data_adapter import Config, DataAdapter\n\npath = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=path / \"test_fragility_curve_overtopping.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nDe volgende configuratie wordt gebruikt voor het maken van een GEKB curve\nGlobalVariables:\n    rootdir: \"data_sets\"\n    moments: [-24,0,24,48]\n\n    # default waardes, kunnen hier worden overschreven\n    FragilityCurveOvertopping:\n        gh_onz_mu: 0.96 \n        gh_onz_sigma: 0.27\n        gp_onz_mu_tp: 1.03\n        gp_onz_sigma_tp: 0.13\n        gp_onz_mu_tspec: 1.03\n        gp_onz_sigma_tspec: 0.13\n        gh_onz_aantal: 7\n        gp_onz_aantal: 7\n        tp_tspec: 1.1\n        lower_limit_coarse: 4.0\n        upper_limit_coarse: 2.0\n        upper_limit_fine: 1.0\n        hstap: 0.05\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    slopes:\n        type: csv\n        file: \"slopes_5.csv\"\n    profiles:\n        type: csv\n        file: \"profiles_new.csv\"\n    bedlevel_fetch:\n        type: csv\n        file: \"bedlevelfetch_11.csv\"\n    fragility_curves:\n        type: csv\n        file: \"fragility_curves_5.csv\"\nEr zijn drie verschillende data bestanden nodig. Ten eerst een table met de informatie over de helling (slope) waarvoor de curve wordt afgeleid\ndata_adapter.input(\"slopes\")\n\n\n\n\n\n\n\nprofileid\nslopetypeid\nx\ny\nr\ndamheight\n\n\n\n\n0\n5\n1\n-12.59\n10.76\n1\n0\n\n\n1\n5\n1\n0.00\n14.63\n1\n0\n\n\n2\n5\n2\n-68.82\n10.00\n1\n0\n\n\n3\n5\n2\n-12.59\n10.76\n1\n0\n\n\n\n\n\nTen tweede informatie over de hoogte van de kruin, de oriëntatie, of er een dam is, maatgevende windsnelheid enz.\ndata_adapter.input(\"profiles\")\n\n\n\n\n\n\n\nparameters\nvalues\n\n\n\n\n0\nsectionid\n11\n\n\n1\ncrestlevel\n14.63\n\n\n2\norientation\n167\n\n\n3\ndam\n0\n\n\n4\ndamheight\n0\n\n\n5\nqcr\nclosed\n\n\n6\nwindspeed\n20\n\n\n7\nsectormin\n180.0\n\n\n8\nsectorsize\n90.0\n\n\n9\nclosing_situation\n0\n\n\n\n\n\nTen derde informatie over het bodemprofiel:\ndata_adapter.input(\"bedlevel_fetch\").head(4)  # (ingekorte versie)\n\n\n\n\n\n\n\nsectionid\ndirection\nbedlevel\nfetch\n\n\n\n\n0\n11\n22.5\n10.39860\n83.2947\n\n\n1\n11\n45.0\n10.06460\n411.6820\n\n\n2\n11\n67.5\n9.52596\n797.4780\n\n\n3\n11\n90.0\n9.18148\n1078.2800\n\n\n\n\n\nDeze informatie wordt mee gegeven aan de FragilityCurveOvertopping voor het genereren van een curve\nfragility_curve_overtopping = FragilityCurveOvertopping(data_adapter=data_adapter)\nfragility_curve_overtopping.run(\n    input=[\"slopes\", \"profiles\", \"bedlevel_fetch\"],\n    output=\"fragility_curves\",\n)\nDeze curve kunnen we vervolgens weergeven:\nfig, ax = plt.subplots()\nfragility_curve_overtopping.as_dataframe().set_index(\"hydraulicload\").plot(ax=ax)\nax.set_ylabel(\"Failure probability\");\n\nIn sommige gevallen wil je een fragility curve ook aan kunnen passen, om dit mogelijk te maken zijn verschillende functie beschikbaar die het zelfde doen als de originele functie maar een kleine, door de gebruiker opgelegde, aanpassingen doen.  Zo verschuift de functie ShiftFragilityCurveOvertopping de fragility curve met een effect.\nshift_fragility_curve_overtopping = ShiftFragilityCurveOvertopping(\n    data_adapter=data_adapter\n)\n\nshift_fragility_curve_overtopping.run(\n    input=[\"slopes\", \"profiles\", \"bedlevel_fetch\"],\n    output=\"fragility_curves\",\n    effect=0.5,\n)\nfig, ax = plt.subplots(1, 1)\n\n# pas de namen van de kolommen aan voor de plot\ndf_overtopping = (\n    fragility_curve_overtopping.as_dataframe()\n    .set_index(\"hydraulicload\")\n    .rename(columns={\"failure_probability\": \"original\"})\n)\ndf_overtopping_shift = (\n    shift_fragility_curve_overtopping.as_dataframe()\n    .set_index(\"hydraulicload\")\n    .rename(columns={\"failure_probability\": \"shifted\"})\n)\n\n# plotten\ndf_overtopping.plot(ax=ax)\ndf_overtopping_shift.plot(ax=ax, linestyle=\"--\", label=\"shifted\")\nax.set_ylabel(\"Failure probability\");\n\nWaar verschuiven een relatief simple nabewerking op de data is, kunnen aanpassingen aan de berekening zelf ‘on-the-fly’ plaatsvinden.  Zo kan als maatregel de kruinhoogte worden verhoogt, met de functie ChangeCrestHeightFragilityCurveOvertopping is dit mogelijk.\nchange_crest_fragility_curve_overtopping = ChangeCrestHeightFragilityCurveOvertopping(\n    data_adapter=data_adapter\n)\n\nchange_crest_fragility_curve_overtopping.run(\n    input=[\"slopes\", \"profiles\", \"bedlevel_fetch\"],\n    output=\"fragility_curves\",\n    effect=0.5,\n)\nfig, ax = plt.subplots(1, 1)\n\n# pas de namen van de kolom aan voor de plot\ndf_overtopping_change_crest = (\n    change_crest_fragility_curve_overtopping.as_dataframe()\n    .set_index(\"hydraulicload\")\n    .rename(columns={\"failure_probability\": \"change crest\"})\n)\n\n# plotten\ndf_overtopping.plot(ax=ax)\ndf_overtopping_change_crest.plot(ax=ax, linestyle=\"--\")\nax.set_ylabel(\"Failure probability\");",
    "crumbs": [
      "Voorbeelden",
      "Fragility Curve Overtopping"
    ]
  },
  {
    "objectID": "examples/notebooks/101.WMS_laag_naar_database.html",
    "href": "examples/notebooks/101.WMS_laag_naar_database.html",
    "title": "WMS laag toevoegen aan database voor viewer",
    "section": "",
    "text": "from pathlib import Path\n\nfrom toolbox_continu_inzicht.base.config import Config\nfrom toolbox_continu_inzicht.base.data_adapter import DataAdapter\n\n\npath = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=path / \"example_inspection.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\n\n\ndata_adapter.input(\"inspections_results\")\n\n\n\n\n\n\n\n\nlocation_id\nprioriteit\nx\ny\nopmerking\ndatum\ntijd\nwaterschap\n\n\n\n\n0\n0\n0\n5.533930\n52.596911\nfoutje\n2-4-2025\n09:08\nZuiderzeeland\n\n\n1\n1\n1\n5.451603\n52.540697\nscheurvorming\n28-3-2025\n15:48\nZuiderzeeland\n\n\n2\n2\n3\n5.407599\n52.497642\nopschot\n28-3-2025\n15:50\nZuiderzeeland\n\n\n3\n3\n11\n5.616243\n52.602794\nbeginnende scheurvorming\n31-3-2025\n09:02\nZuiderzeeland\n\n\n\n\n\n\n\nWe willen de volgende data toevoegen aan de viewer:\n\nurl = \"https://basisinformatie-overstromingen.nl/geoserver/LIWO_Basis/infrastructuur_dijkringen/ows?SERVICE=WMS&\"\nlegend_url = \"https://geodata.basisinformatie-overstromingen.nl/geoserver/LIWO_Basis/infrastructuur_dijkringen/ows?service=WMS&version=1.3.0&request=GetLegendGraphic&format=image/png&width=20&height=20&layer=infrastructuur_dijkringen&\"\nlayer_wms_layer = \"infrastructuur_dijkringen\"\nlayer_wms_style = \"LIWO_Basis_Dijkringen\"\n\nHet layers bestand bevat de standaard opties\n\ndf_layers = data_adapter.input(\"layers\")\n\n\ndf_layers\n\n\n\n\n\n\n\n\ngroup_name\nlayer_name\nlayer_visible\nlayer_type\nlayer_table\nlayer_wms_url\nlayer_wms_layer\nlayer_wms_style\nlayer_wms_legend_url\nlayer_data\nlayer_legend\n\n\n\n\n0\nExtra Kaartlagen\nGeojson met data\nTrue\ngeojson\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nExtra Kaartlagen\nWMS test\nTrue\nwms\nNaN\nhttps://geo.hkvservices.nl/geoserver/wms\nWaterdiepte\nliwo_waterdiepte_band1\nNaN\nNaN\nNaN\n\n\n2\nExtra Kaartlagen\ntable test\nTrue\ntable\nareas\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nWe vullen alleen de eerste kolom met de dijkringen informatie\n\ndf_wms_laag = df_layers.iloc[[1]].copy()\ndf_wms_laag.reset_index(drop=True, inplace=True)\ndf_wms_laag.loc[0, \"group_name\"] = \"Dijkringen Nederland\"\ndf_wms_laag.loc[0, \"layer_wms_url\"] = url\ndf_wms_laag.loc[0, \"layer_wms_layer\"] = layer_wms_layer\ndf_wms_laag.loc[0, \"layer_wms_style\"] = layer_wms_style\ndf_wms_laag[\"layer_wms_legend_url\"] = df_wms_laag[\"layer_legend\"].astype(str)\ndf_wms_laag.loc[0, \"layer_wms_legend_url\"] = legend_url\ndf_wms_laag = df_wms_laag.fillna(\"\")\ndf_wms_laag\n\n\n\n\n\n\n\n\ngroup_name\nlayer_name\nlayer_visible\nlayer_type\nlayer_table\nlayer_wms_url\nlayer_wms_layer\nlayer_wms_style\nlayer_wms_legend_url\nlayer_data\nlayer_legend\n\n\n\n\n0\nDijkringen Nederland\nWMS test\nTrue\nwms\n\nhttps://basisinformatie-overstromingen.nl/geos...\ninfrastructuur_dijkringen\nLIWO_Basis_Dijkringen\nhttps://geodata.basisinformatie-overstromingen...\n\n\n\n\n\n\n\n\n\nOmdat database interactie op GitHub niet mogelijk wordt de onderstaande cell niet uitgevoerd, lokaal kan dit uiteraard wel\nEn vervolgens kunnen we deze naar de database zetten\n\n# data_adapter.output(\"to_ci_database\", df_wms_laag)",
    "crumbs": [
      "Voorbeelden",
      "WMS laag toevoegen aan database voor viewer"
    ]
  },
  {
    "objectID": "examples/notebooks/1.proof_of_concept.html",
    "href": "examples/notebooks/1.proof_of_concept.html",
    "title": "Architectuur voorbeeld",
    "section": "",
    "text": "Hieronder wordt één voorbeeld gegeven van hoe de architectuur werkt. In de linker balk zijn nog een aantal voorbeelden te vinden van hoe de toolbox gebruikt kan worden.\nDe voorbeelden die hier in de documentatie te vinden zijn staan met de juiste data en configuratie bestanden op GitHub onder toolbox-continu-inzicht/docs/examples/notebooks/.\nDaarnaast zijn tijden het ontwikkelen ook demo’s en integratie testen te vinden onder toolbox-continu-inzicht/tests/examples/.\nOm de architectuur weer te geven wordt een simple voorbeeld gegeven met de proof_of_concept functie. Deze functie doet niks anders dan vermenigvuldigen en delen maar dit geeft wel de werking van de opzet weer.\nDe verschillende bouwstenen van de code is hier onder weergegeven:\nDe architectuur is ontworpen om het principe van een data adapter dier er voor zorgt dat het format waar de functie vanuit leest en naar toe wegschrijft makkelijk aangepast kan worden door de gebruiker.\nEen voorbeeld van hoe dit er uitziet voor het inladen van CSV en wegschrijven naar csv is hieronder weergegeven.",
    "crumbs": [
      "Voorbeelden",
      "Architectuur voorbeeld"
    ]
  },
  {
    "objectID": "examples/notebooks/1.proof_of_concept.html#voorbeeld-met-csv",
    "href": "examples/notebooks/1.proof_of_concept.html#voorbeeld-met-csv",
    "title": "Architectuur voorbeeld",
    "section": "Voorbeeld met CSV",
    "text": "Voorbeeld met CSV\nHet uitgangspunt van een architectuur is dat de verschillende functies werken met verschillende data formaten. Om dit mogelijk te maken wordt gebruik gemaakt van data adapters. Deze lezen data die de functie in gaat en schrijven het vervolgens weg. Om duidelijk te maken in welk formaat je weg wilt schrijven of wilt inlezen wordt gebruik gemaakt van een configuratie bestand. Dit is een .yaml bestand, hieronder wordt een voorbeeld gegeven hoe je dit zou opzetten met het configuratie bestand test_config.yaml.\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    default_options:\n        postgresql_database:\n            database: \"citoolbox\"\n            schema: \"citoolbox_schema\"\n    \n    my_csv_in: \n        type: csv\n        file: \"test_csv_in.csv\"\n    my_csv_out: \n        type: csv\n        file: \"test_csv_out.csv\"\n    my_postgresql: \n        type: postgresql_database\n        table: data\n\n...\nIn een configuratie bestand zijn een aantal instellingen verplicht. Het moet GlobalVariables bevatten met een root_dir en minimaal één DataAdapter. In sommige gevallen kan je ook met één DataAdapter uit de voeten, je gebruik dan dezelfde instellingen om te lezen en schrijven. Bij CSV is dit dan hetzelfde bestand, bij een database dezelfde tabel.\nEen heel aantal data adapters worden standaard ondersteund en je kan makkelijk je eigen data adapter toevoegen. Onder het kopje modules/architectuur in de documentatie vindt je meer informatie over data adapters.\nOnder GlobalVariables zijn instellingen voor specifieke functies te vinden, maar ook instellingen die in meerdere functies gebruikt worden. Bijvoorbeeld de huidige berekening tijd (calc_time) of de tijden waarvoor voorspellingen worden berekend (moments).\nDe configuratie kunnen we inlezen:\nconfig = Config(config_path=\"data_sets/test_config.yaml\")\nconfig.lees_config()\nEn de config mee geven aan de data adapter die we gebruiken\nfrom toolbox_continu_inzicht import DataAdapter\n\ndata_adapter = DataAdapter(config=config)\nDe data adapter geef je vervolgens mee bij het aanmaken van een functie\nfrom toolbox_continu_inzicht.proof_of_concept import ValuesTimesTwo\n\nkeer_twee = ValuesTimesTwo(data_adapter=data_adapter)\nEn vervolgens run je de module met een input en een output data adapter, dit bied flexibiliteit in welke in en uitvoer bestanden je gebruikt\nkeer_twee.run(input=\"my_csv_in\", output=\"my_csv_out\")\nkeer_twee.df_in\n\n\n\n\n\n\n\nobjectid\nobjecttype\nparameterid\ndate_time\nvalue\n\n\n\n\n0\n1\nmeasuringstation\n1\n1726227377000\n4.8\n\n\n1\n2\nmeasuringstation\n1\n1726227377000\n5.0\n\n\n2\n3\nmeasuringstation\n1\n1726227377000\n5.2\n\n\n3\n4\nmeasuringstation\n1\n1726227377000\n5.4\n\n\n4\n5\nmeasuringstation\n1\n1726227377000\n5.6\n\n\n\n\n\nkeer_twee.df_out\n\n\n\n\n\n\n\nobjectid\nobjecttype\nparameterid\ndate_time\nvalue\n\n\n\n\n0\n1\nmeasuringstation\n1\n1726227377000\n9.6\n\n\n1\n2\nmeasuringstation\n1\n1726227377000\n10.0\n\n\n2\n3\nmeasuringstation\n1\n1726227377000\n10.4\n\n\n3\n4\nmeasuringstation\n1\n1726227377000\n10.8\n\n\n4\n5\nmeasuringstation\n1\n1726227377000\n11.2\n\n\n\n\n\nde values waardes uit de vorige table zijn vermenigvuldigd met twee\nZelf proberen? Dit voorbeeld is te vinden op Github",
    "crumbs": [
      "Voorbeelden",
      "Architectuur voorbeeld"
    ]
  },
  {
    "objectID": "contributing.html",
    "href": "contributing.html",
    "title": "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht",
    "section": "",
    "text": "Het ontwikkelen van de Toolbox Continu Inzicht bestaat uit twee delen. Eerst ontwikkelt HKV de basisfunctionaliteit. Deze ontwikkeling is voor iedereen te volgen op GitHub, maar toevoegingen worden nog niet geaccepteerd. Daarna blijft het project open source beschikbaar en kan het verder worden ontwikkeld. De term ‘ontwikkelaars’ duidt in de eerste ontwikkelfase op het team van HKV, later op anderen die een bijdrage willen leveren. Een bijdrage kan uiteenlopen van een vraag tot een grote wijziging via een pull request.\nEen bijdrage kan een van de volgend zaken zijn:\n\nJe hebt een vraag\nJe denkt een probleem (bug) te hebben gevonden (of onverwachte functionaliteit)\nJe wilt een aanpassing maken (bug fixen, nieuwe functionaliteit, update aan de documentatie)\nJe wilt een nieuwe versie publiceren\n\nDe onderstaande secties behandelen de stappen per geval.\n\n\n\nGebruik de zoekfunctie hier om te kijken of iemand anders dezelfde vraag heeft.\nAls je niks vergelijkbaars kan vinden, maak een nieuwe issue aan.\nVoeg het \"Question” label toe; voeg andere labels toe waar nodig.\n\n\n\n\n\nGebruik de zoekfunctie hier om te kijken of iemand anders dezelfde vraag/probleem heeft.\nAls je niks vergelijkbaars kan vinden, maak een nieuwe issue aan. Zorg dat je genoeg informatie meegeeft zodat andere ontwikkelaars je probleem begrijpen en genoeg context hebben om je te helpen. Afhankelijk van je probleem, kan je de SHA hashcode van de commit die problemen veroorzaakt toevoegen. Denk daarnaast ook aan versie- en besturingssysteeminformatie.\nVoeg labels toe die relevant zijn voor je probleem.\n\n\n\n\n\n(Belangrijk) Communiceer aan de rest van de ontwikkelaars voor je begint dat je een aanpassing wilt maken. Dit laat je weten door een issue aan te maken.\n(Belangrijk) Bereik consensus over je idee.\nDe hoofdontwikkelaars hebben rechten om nieuwe branches aan te maken. Als je deze rechten niet hebt, maak een 'fork' (kopie) in je eigen account. In deze fork maak je een eigen branch van de laatste commit in main. Probeer om veranderingen die in de tussentijd worden doorgevoerd op main al mee te nemen. Dit doe je door te pullen van de 'upstream' repository, (zie instructies hier en hier);\nVoor Visual Studio Code staat er een voorbeeldconfiguratie.\nInstalleer de benodigde python packages in een pixi omgeving met pixi install, volg de uitleg van de pixi. Pixi zorgt er voor dat iedereen dezelfde versies van python packages heeft.\nZorg dat de format van je code correct is met pixi run pre-commit. Pre-commit haalt opmaak fouten uit je code en zorgt voor een fijne manier van samenwerken. Hier onder vallen een aantal zaken als spaties, haakjes etc, maar ook docstrings. Door het installeren van pre-commit met de volgende commando: pre-commit install --hook-type pre-commit --hook-type pre-push runt deze lokaal automatisch met git commit actie.\nZorg dat alle bestaande testen werken met pixi run pytest. Met pixi run pytest-cov wordt (lokaal) een html overzicht gegenereerd in de map tests/hidden_test_cov/index.html.\nZorg dat alle documentatie automatisch genereert met pixi run quarto-render. Quarto is al onderdeel van de zojuist aangemaakte pixi omgeving.\nVoeg bij nieuwe functionaliteit altijd nieuwe tests toe.\nUpdate en voeg documentatie toe. Gebruik Numpy Style Python docstrings. Zorg dat je code leesbaar en begrijpelijk is voor anderen. De pydoclint checkt de doctring format voor je.\nHeb je nieuwe termen toegevoegd? Update dan de vertalingen in tabel\nPush je branch. naar (jouw fork van) de toolbox continu inzicht repo op GitHub;\nMaak een pull request aan, bijvoorbeeld volgens deze instructies. Pull requests die worden ontvangen, krijgen altijd een review.\n\nAls je het idee heb dat je iets nuttig heb toegevoegd, maar je weet niet hoe je tests schrijft of runt of hoe je documentatie aanmaakt: geen probleem. Maak een pull request en dan kijken we hoe we kunnen helpen.\n\n\n\nDit is een stukje voor de hoofdontwikkelaars van toolbox continu inzicht.\n\nCheckout HEAD van de main branch met git checkout main en git pull.\nBeslis welke nieuwe versie (major, minor or patch) gebruikt gaat worden. We gebruiken semantic versioning.\nOmdat je niet direct naar de main branch kan schrijven (protected), maak een nieuwe branch aan met git checkout -b release-&lt;version&gt;.\nIndien dependencies zijn aangepast, maak een nieuw pixi lock bestand.\nPas de versie aan in src/toolbox_continu_inzicht/__init__.py, de pyptoject.toml leest deze uit.\nPas de [docs/overig/changelog.qmd](overig/changelog.qmd) aan met de veranderingen. Vergeet de link naar de pull request niet.\nZorg dat de format van je code correct is met pixi run ruff check.\nZorg dat alle bestaande testen werken met pixi run pytest.\nCommit & push je aanpassingen naar GitHub.\nMaak een pull request aan, laat iemand het reviewen, wacht op alle acties, deze worden groen, en merge de pull request.\nWacht tot de GitHub-acties op de main branch klaar zijn en er een groen vinkje bij staat.\nMaak een nieuwe 'release' aan op GitHub\n\nGebruik de versie als titel en pas een versie tag toe.\nAls beschrijving gebruik de intro van de README.md en veranderingen uit de changelog.qmd.\n\nCheck\n\nIs de wiki bijgewerkt?\nHeeft de GitHub actie alles naar PyPI gestuurd?\nWerkt de nieuwe versie met: pip3 install toolbox_continu_inzicht==&lt;new version&gt;?\n\nVier je nieuwe versie!",
    "crumbs": [
      "Bijdragen",
      "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht"
    ]
  },
  {
    "objectID": "contributing.html#je-hebt-een-vraag",
    "href": "contributing.html#je-hebt-een-vraag",
    "title": "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht",
    "section": "",
    "text": "Gebruik de zoekfunctie hier om te kijken of iemand anders dezelfde vraag heeft.\nAls je niks vergelijkbaars kan vinden, maak een nieuwe issue aan.\nVoeg het \"Question” label toe; voeg andere labels toe waar nodig.",
    "crumbs": [
      "Bijdragen",
      "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht"
    ]
  },
  {
    "objectID": "contributing.html#je-denkt-een-probleem-bug-te-hebben-gevonden",
    "href": "contributing.html#je-denkt-een-probleem-bug-te-hebben-gevonden",
    "title": "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht",
    "section": "",
    "text": "Gebruik de zoekfunctie hier om te kijken of iemand anders dezelfde vraag/probleem heeft.\nAls je niks vergelijkbaars kan vinden, maak een nieuwe issue aan. Zorg dat je genoeg informatie meegeeft zodat andere ontwikkelaars je probleem begrijpen en genoeg context hebben om je te helpen. Afhankelijk van je probleem, kan je de SHA hashcode van de commit die problemen veroorzaakt toevoegen. Denk daarnaast ook aan versie- en besturingssysteeminformatie.\nVoeg labels toe die relevant zijn voor je probleem.",
    "crumbs": [
      "Bijdragen",
      "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht"
    ]
  },
  {
    "objectID": "contributing.html#je-wilt-een-aanpassing-maken",
    "href": "contributing.html#je-wilt-een-aanpassing-maken",
    "title": "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht",
    "section": "",
    "text": "(Belangrijk) Communiceer aan de rest van de ontwikkelaars voor je begint dat je een aanpassing wilt maken. Dit laat je weten door een issue aan te maken.\n(Belangrijk) Bereik consensus over je idee.\nDe hoofdontwikkelaars hebben rechten om nieuwe branches aan te maken. Als je deze rechten niet hebt, maak een 'fork' (kopie) in je eigen account. In deze fork maak je een eigen branch van de laatste commit in main. Probeer om veranderingen die in de tussentijd worden doorgevoerd op main al mee te nemen. Dit doe je door te pullen van de 'upstream' repository, (zie instructies hier en hier);\nVoor Visual Studio Code staat er een voorbeeldconfiguratie.\nInstalleer de benodigde python packages in een pixi omgeving met pixi install, volg de uitleg van de pixi. Pixi zorgt er voor dat iedereen dezelfde versies van python packages heeft.\nZorg dat de format van je code correct is met pixi run pre-commit. Pre-commit haalt opmaak fouten uit je code en zorgt voor een fijne manier van samenwerken. Hier onder vallen een aantal zaken als spaties, haakjes etc, maar ook docstrings. Door het installeren van pre-commit met de volgende commando: pre-commit install --hook-type pre-commit --hook-type pre-push runt deze lokaal automatisch met git commit actie.\nZorg dat alle bestaande testen werken met pixi run pytest. Met pixi run pytest-cov wordt (lokaal) een html overzicht gegenereerd in de map tests/hidden_test_cov/index.html.\nZorg dat alle documentatie automatisch genereert met pixi run quarto-render. Quarto is al onderdeel van de zojuist aangemaakte pixi omgeving.\nVoeg bij nieuwe functionaliteit altijd nieuwe tests toe.\nUpdate en voeg documentatie toe. Gebruik Numpy Style Python docstrings. Zorg dat je code leesbaar en begrijpelijk is voor anderen. De pydoclint checkt de doctring format voor je.\nHeb je nieuwe termen toegevoegd? Update dan de vertalingen in tabel\nPush je branch. naar (jouw fork van) de toolbox continu inzicht repo op GitHub;\nMaak een pull request aan, bijvoorbeeld volgens deze instructies. Pull requests die worden ontvangen, krijgen altijd een review.\n\nAls je het idee heb dat je iets nuttig heb toegevoegd, maar je weet niet hoe je tests schrijft of runt of hoe je documentatie aanmaakt: geen probleem. Maak een pull request en dan kijken we hoe we kunnen helpen.",
    "crumbs": [
      "Bijdragen",
      "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht"
    ]
  },
  {
    "objectID": "contributing.html#je-wilt-een-nieuwe-versie-publiceren",
    "href": "contributing.html#je-wilt-een-nieuwe-versie-publiceren",
    "title": "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht",
    "section": "",
    "text": "Dit is een stukje voor de hoofdontwikkelaars van toolbox continu inzicht.\n\nCheckout HEAD van de main branch met git checkout main en git pull.\nBeslis welke nieuwe versie (major, minor or patch) gebruikt gaat worden. We gebruiken semantic versioning.\nOmdat je niet direct naar de main branch kan schrijven (protected), maak een nieuwe branch aan met git checkout -b release-&lt;version&gt;.\nIndien dependencies zijn aangepast, maak een nieuw pixi lock bestand.\nPas de versie aan in src/toolbox_continu_inzicht/__init__.py, de pyptoject.toml leest deze uit.\nPas de [docs/overig/changelog.qmd](overig/changelog.qmd) aan met de veranderingen. Vergeet de link naar de pull request niet.\nZorg dat de format van je code correct is met pixi run ruff check.\nZorg dat alle bestaande testen werken met pixi run pytest.\nCommit & push je aanpassingen naar GitHub.\nMaak een pull request aan, laat iemand het reviewen, wacht op alle acties, deze worden groen, en merge de pull request.\nWacht tot de GitHub-acties op de main branch klaar zijn en er een groen vinkje bij staat.\nMaak een nieuwe 'release' aan op GitHub\n\nGebruik de versie als titel en pas een versie tag toe.\nAls beschrijving gebruik de intro van de README.md en veranderingen uit de changelog.qmd.\n\nCheck\n\nIs de wiki bijgewerkt?\nHeeft de GitHub actie alles naar PyPI gestuurd?\nWerkt de nieuwe versie met: pip3 install toolbox_continu_inzicht==&lt;new version&gt;?\n\nVier je nieuwe versie!",
    "crumbs": [
      "Bijdragen",
      "Richtlijnen voor bijdragen aan Toolbox Continu Inzicht"
    ]
  },
  {
    "objectID": "examples/notebooks/100.logging.html",
    "href": "examples/notebooks/100.logging.html",
    "title": "Gebruik van logging",
    "section": "",
    "text": "Om fouten beter af te vangen en te verwerken in de toolbox kan logging worden ingesteld via de data adapter\nimport logging\nfrom pathlib import Path\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nBij het aanmaken van een data adapter voegen we een basis logger object toe.\nHier zitten verder geen instelling aan gekoppeld, maar wordt de log ‘terug gegeven’ aan de gebruiker.\nGlobalVariables:\n    rootdir: 'data_sets'\n\nDataAdapter:\n    mycsv_in:\n        type: csv\n        file: 'test_csv_in.csv'\ndata_path = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=data_path / \"test_config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nHet standaard niveau is WARNING, test en info zien we dan niet\ndata_adapter.logger.info(\"test\")\ndata_adapter.logger.warning(\"test\")\n2025-05-23 07:51:49 WARNING - 666804439: test\nZo kunnen we bijvoorbeeld het niveau aanpassen:\nGlobalVariables:\n    rootdir: 'data_sets'\n    logging:\n        level: DEBUG\n\nDataAdapter:\n    mycsv_in:\n        type: csv\n        file: 'test_csv_in.csv'\ndata_path = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=data_path / \"test_config_debug_logging.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\n2025-05-23 07:51:49 DEBUG - data_adapter: Logging is ingesteld.\nDan zien we ineens meer logging informatie\ndata_adapter.input(\"mycsv_in\")\n2025-05-23 07:51:49 DEBUG - data_adapter: DataAdapter input: function_input_config={'type': 'csv', 'file': 'test_csv_in.csv'}\n\n\n\n\n\n\n\nobjectid\nobjecttype\nparameterid\ndate_time\nvalue\n\n\n\n\n0\n1\nmeasuringstation\n1\n1726227377000\n4.8\n\n\n1\n2\nmeasuringstation\n1\n1726227377000\n5.0\n\n\n2\n3\nmeasuringstation\n1\n1726227377000\n5.2\n\n\n3\n4\nmeasuringstation\n1\n1726227377000\n5.4\n\n\n4\n5\nmeasuringstation\n1\n1726227377000\n5.6\n\n\n\n\n\nHet logging object heeft standaard de naam “toolbox_continu_inzicht”, met de standaard python functionaliteit kunnen we er bij\nget_log = logging.getLogger(\"toolbox_continu_inzicht\")\nget_log\n&lt;Logger toolbox_continu_inzicht (DEBUG)&gt;\nof via de data adapter\ndata_adapter.logger\n&lt;Logger toolbox_continu_inzicht (DEBUG)&gt;\nMaken we een nieuwe data adapter aan, dan gaat de logging naar het zelfde object, mits we de naam niet aanpassen.\nfrom toolbox_continu_inzicht.proof_of_concept import ValuesDivideTwo\ndata_path = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=data_path / \"test_config_debug_logging.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nvalues_divide_two = ValuesDivideTwo(data_adapter=data_adapter)\nvalues_divide_two.run(input=\"mycsv_in\", output=\"mycsv_out\")\n2025-05-23 07:51:49 DEBUG - data_adapter: Logging is ingesteld.\n2025-05-23 07:51:49 DEBUG - data_adapter: DataAdapter input: function_input_config={'type': 'csv', 'file': 'test_csv_in.csv'}\n2025-05-23 07:51:49 INFO - example_module: Division started for 5 rows\n2025-05-23 07:51:49 DEBUG - example_module: Division with dataframe containing 'Index(['objectid', 'objecttype', 'parameterid', 'date_time', 'value'], dtype='object')' as columns\nTot nu toe ging de logging alleen naar de gebruiker (stderr), maar we kunnen het ook opslaan\nGlobalVariables:\n    rootdir: 'data_sets'\n    logging:\n        name:  toolbox_continu_inzicht  # default\n        level: DEBUG\n        mode:  w                        # default\n        file:  hidden_logfile_advanced.log\n        \nDataAdapter:\n    mycsv_in:\n        type: csv\n        file: 'test_csv_in.csv'\ndata_path = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=data_path / \"test_config_advanced_logging.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\n2025-05-23 07:51:49 DEBUG - data_adapter: Logging is ingesteld.\nZo zien we nu naast de StreamHandler ook een FileHandler\nget_log.handlers\n[&lt;StreamHandler stderr (NOTSET)&gt;,\n &lt;FileHandler D:\\a\\toolbox-continu-inzicht\\toolbox-continu-inzicht\\continu_inzicht\\docs\\examples\\notebooks\\data_sets\\hidden_logfile_advanced.log (NOTSET)&gt;]\ndata_adapter.logger.debug(\"add own error\")\n2025-05-23 07:51:49 DEBUG - 393206663: add own error\nOok deze blijft hetzelfde ookal maken wij een nieuw object aan\ndata_path = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=data_path / \"test_config_advanced_logging.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nget_log.handlers\n2025-05-23 07:51:49 DEBUG - data_adapter: Logging is ingesteld.\n[&lt;StreamHandler stderr (NOTSET)&gt;,\n &lt;FileHandler D:\\a\\toolbox-continu-inzicht\\toolbox-continu-inzicht\\continu_inzicht\\docs\\examples\\notebooks\\data_sets\\hidden_logfile_advanced.log (NOTSET)&gt;]\nJe hoeft ook maar één keer een bestand op te geven, de andere nemen de instellingen over omdat het object telkens wordt ‘opgehaald’\ndata_path = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=data_path / \"test_config_debug_logging.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nget_log.handlers\n2025-05-23 07:51:49 DEBUG - data_adapter: Logging is ingesteld.\n[&lt;StreamHandler stderr (NOTSET)&gt;,\n &lt;FileHandler D:\\a\\toolbox-continu-inzicht\\toolbox-continu-inzicht\\continu_inzicht\\docs\\examples\\notebooks\\data_sets\\hidden_logfile_advanced.log (NOTSET)&gt;]\nDe naam en het niveau wordt wel aangepast, dus als we toch geen debug meer willen kan dat op deze manier:\ndata_path = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=data_path / \"test_config_debug_logging.yaml\")\nconfig.lees_config()\nconfig.global_variables[\"logging\"][\"level\"] = \"WARNING\"\ndata_adapter = DataAdapter(config=config)\nget_log.handlers\n[&lt;StreamHandler stderr (NOTSET)&gt;,\n &lt;FileHandler D:\\a\\toolbox-continu-inzicht\\toolbox-continu-inzicht\\continu_inzicht\\docs\\examples\\notebooks\\data_sets\\hidden_logfile_advanced.log (NOTSET)&gt;]\nAdvies is dan ook om op een plek je ‘advanced’ log te definiëren, en bij alle andere data adapters de standaard waarde te behouden.",
    "crumbs": [
      "Voorbeelden",
      "Gebruik van logging"
    ]
  },
  {
    "objectID": "examples/notebooks/2.belastingen_inladen.html",
    "href": "examples/notebooks/2.belastingen_inladen.html",
    "title": "Belastingen inladen",
    "section": "",
    "text": "Om inzicht te krijgen in de veiligheid van waterkeringen is het van belang om de belastingen op de waterkeringen in kaart te brengen. Dit kunnen waterstanden op het buitenwater (zee, rivieren of meren) zijn, maar ook grondwaterstanden.\nIn dit voorbeeld wordt het inlezen van waterstanden uit verschillende bronsystemen getoond: - RWS Waterinfo - FEWS - (Noos) Matroos - RWS WaterWebServices\nHierbij wordt gebruik gemaakt van csv bestanden voor uitwisselen van data.\n\nBenodigde generieke Python packages\nfrom pathlib import Path\n\n\nDefinitie configuratie: CSV bestanden\nGlobalVariables:\n    rootdir: \"data_demo\" \n    moments: [-24,0,24,48]  \n\n    LoadsWaterinfo:\n        parameters: [\"waterhoogte\"]\n        MISSING_VALUE: 999\n\n    LoadsFews:\n        host: \"https://fews.hhnk.nl\"\n        port: 443\n        region: \"fewspiservice\"\n        version: \"1.25\"\n        filter: \"HHNK_WEB\"\n        parameters: [\"WATHTE [m][NAP][OW]\", \"WINDRTG [deg]\"]\n        aquo_equivalent: [\"WATHTE\",\"WINDRTG\"]\n        MISSING_VALUE: 999\n    \n    LoadsMatroos:\n        website: \"vitaal\"\n        model: \"dcsm6_kf\"\n        parameters: [\"WATHTE\"]\n        MISSING_VALUE: 999\n    \n    LoadsWaterwebservicesRWS:\n        parameters: [\"WATHTE\"]\n        MISSING_VALUE: 999\n\nDataAdapter: \n    default_options:\n        csv_source:\n            sep: \";\"\n        csv:\n            sep: \",\"\n    BelastingLocaties_WaterInfo: \n        type: csv_source\n        filter: \"WaterInfo\"\n        path: \"locaties.csv\"\n    Waterstanden_WaterInfo: \n        type: csv\n        path: \"waterstanden_waterinfo.csv\"\n    BelastingLocaties_FEWS: \n        type: csv_source\n        filter: \"FEWS\"\n        path: \"locaties.csv\"\n    Waterstanden_FEWS: \n        type: csv\n        path: \"waterstanden_fews.csv\"\n    BelastingLocaties_Matroos: \n        type: csv_source\n        filter: \"NOOS Matroos\"\n        path: \"locaties.csv\"\n    Waterstanden_Matroos: \n        type: csv\n        path: \"waterstanden_matroos.csv\"\n    BelastingLocaties_Waterwebservices_RWS: \n        type: csv_source\n        filter: \"RWS Waterwebservices\"\n        path: \"locaties.csv\"\n    Waterstanden_Waterwebservices_RWS: \n        type: csv\n        path: \"waterstanden_waterwebservices_rws.csv\"\n\n\nLees configuratie in en maak dictionary base.Config aan\nfrom toolbox_continu_inzicht import Config\n\nyaml_config_file = \"demo_sprint2-I.yaml\"\npath = Path.cwd() / \"data_demo\" / yaml_config_file\nconfig = Config(config_path=path)\nconfig.lees_config()\n\n\nGeef config mee aan base.Adapter\nfrom toolbox_continu_inzicht import DataAdapter\n\ndata = DataAdapter(config=config)\nprint(f\"Folder met data: {data.config.config_path}\")\nprint(f\"Globale variabelen: {data.config.global_variables}\")\nfor data_adapter in data.config.data_adapters:\n    print(f\"Data apdater: {data_adapter}\")\nFolder met data: D:-continu-inzicht-continu-inzicht_inzicht_demo_sprint2-I.yaml Globale variabelen: {‘rootdir’: ‘data_demo’, ‘moments’: [-24, 0, 24, 48], ‘aquo_allias’: {‘WATHTE [m][NAP][OW]’: ‘WATHTE’}, ‘LoadsWaterinfo’: {‘parameters’: [‘waterhoogte’], ‘MISSING_VALUE’: 999}, ‘LoadsFews’: {‘host’: ‘https://fews.hhnk.nl’, ‘port’: 443, ‘region’: ‘fewspiservice’, ‘version’: ‘1.25’, ‘filter’: ‘HHNK_WEB’, ‘parameters’: [‘WATHTE [m][NAP][OW]’], ‘MISSING_VALUE’: 999}, ‘LoadsMatroos’: {‘website’: ‘noos’, ‘model’: ‘dcsm6_kf’, ‘parameters’: [‘WATHTE’], ‘MISSING_VALUE’: 999}, ‘LoadsWaterwebservicesRWS’: {‘parameters’: [‘WATHTE’], ‘MISSING_VALUE’: 999}, ‘calc_time’: datetime.datetime(2025, 5, 23, 7, 0, tzinfo=datetime.timezone.utc)} Data apdater: default_options Data apdater: BelastingLocaties_WaterInfo Data apdater: Waterstanden_WaterInfo Data apdater: BelastingLocaties_FEWS Data apdater: Waterstanden_FEWS Data apdater: BelastingLocaties_Matroos Data apdater: Waterstanden_Matroos Data apdater: BelastingLocaties_Waterwebservices_RWS Data apdater: Waterstanden_Waterwebservices_RWS\n\n\nInvoerbestand (CSV) met data van belastinglocaties\nDe functie verwacht de volgende verplichte velden, dit wordt ook wel een schema genoemd in de code: - measurement_location_id: int64 - measurement_location_code: object (string) - measurement_location_description: object (string)\nHet csv bestand ziet er als volgt uit:\nmeasurement_location_id;measurement_location_code;measurement_location_description;source;tide\\\n1;Pannerdense-kop(PANN);Pannerdense kop;WaterInfo;false\\\n2;MPN-N-24;Meetpunt Spijkerboor;FEWS;false\\\n3;hoekvanholland;Hoek van Holland;NOOS Matroos;true\\\n4;9889;Hintham beneden;RWS Waterwebservices;false\n\n\nLaad module (functie) LoadsWaterinfo voor inlezen belastingen uit RWS Waterinfo\nfrom toolbox_continu_inzicht.loads import LoadsWaterinfo\n\nwaterinfo = LoadsWaterinfo(data_adapter=data)\n\n\nRun module (functie) LoadsWaterinfo voor inlezen waterstanden uit Waterinfo\nZoek op basis van een measurement_location_code die in RWS WaterInfo overeenkomt met ‘locationCodes’\nds = waterinfo.run(input=\"BelastingLocaties_WaterInfo\", output=\"Waterstanden_WaterInfo\")\nmeasuringlocations = waterinfo.df_in\nmeasuringlocations\n\n\n\n\n\n\n\nmeasurement_location_id\nmeasurement_location_code\nmeasurement_location_description\nsource\ntide\n\n\n\n\n0\n1\nPannerdense-kop(PANN)\nPannerdense kop\nWaterInfo\nFalse\n\n\n\n\n\nwaterlevels = waterinfo.df_out\nwaterlevels\n\n\n\n\n\n\n\nmeasurement_location_id\nmeasurement_location_code\nmeasurement_location_description\nparameter_id\nparameter_code\nparameter_description\nunit\ndate_time\nvalue\nvalue_type\n\n\n\n\n150\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte Oppervlaktewater t.o.v. Normaal Am...\ncm\n2025-05-22 07:00:00+00:00\n714.0\nmeting\n\n\n151\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte Oppervlaktewater t.o.v. Normaal Am...\ncm\n2025-05-22 07:10:00+00:00\n713.0\nmeting\n\n\n152\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte Oppervlaktewater t.o.v. Normaal Am...\ncm\n2025-05-22 07:20:00+00:00\n714.0\nmeting\n\n\n153\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte Oppervlaktewater t.o.v. Normaal Am...\ncm\n2025-05-22 07:30:00+00:00\n714.0\nmeting\n\n\n154\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte Oppervlaktewater t.o.v. Normaal Am...\ncm\n2025-05-22 07:40:00+00:00\n715.0\nmeting\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n570\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte verwacht Oppervlaktewater t.o.v. N...\ncm\n2025-05-25 02:20:00+00:00\n716.0\nverwachting\n\n\n571\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte verwacht Oppervlaktewater t.o.v. N...\ncm\n2025-05-25 02:30:00+00:00\n716.0\nverwachting\n\n\n572\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte verwacht Oppervlaktewater t.o.v. N...\ncm\n2025-05-25 02:40:00+00:00\n716.0\nverwachting\n\n\n573\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte verwacht Oppervlaktewater t.o.v. N...\ncm\n2025-05-25 02:50:00+00:00\n716.0\nverwachting\n\n\n574\n1\nPannerdense-kop(PANN)\nPannerdense kop\n4724\nWATHTE\nWaterhoogte verwacht Oppervlaktewater t.o.v. N...\ncm\n2025-05-25 03:00:00+00:00\n716.0\nverwachting\n\n\n\n\n425 rows × 10 columns\n\n\n\nLaad en run module (functie) LoadsFEWS voor inlezen belastingen uit FEWS\nZoek op basis van een measurement_location_code die in FEWS overeenkomt met ‘locationId’ \nFEWS is niet extern bereikbaar en kan dus niet in de documentatie worden getoond\n# from toolbox_continu_inzicht.loads import LoadsFews\n\n# fews = LoadsFews(data_adapter=data)\n# ds = fews.run(input=\"BelastingLocaties_FEWS\", output=\"Waterstanden_FEWS\")\n# measuringlocations = fews.df_in\n# measuringlocations\n# waterlevels = fews.df_out\n# waterlevels\n\n\nLaad en run module (functie) LoadsMatroos voor inlezen belastingen uit Matroos\nZoek op basis van een measurement_location_code die in (NOOS) Matroos overeenkomt met ‘Location’ -&gt; loc_id!\nfrom toolbox_continu_inzicht.loads import LoadsMatroos\n\nmatroos = LoadsMatroos(data_adapter=data)\nds = matroos.run(input=\"BelastingLocaties_Matroos\", output=\"Waterstanden_Matroos\")\nmeasuringlocations = matroos.df_in\nmeasuringlocations\n\n\n\n\n\n\n\nmeasurement_location_id\nmeasurement_location_code\nmeasurement_location_description\nsource\ntide\n\n\n\n\n2\n3\nHoek van Holland\nHoek van Holland\nNOOS Matroos\nTrue\n\n\n\n\n\nwaterlevels = matroos.df_out\nwaterlevels\n\n\n\n\n\n\n\nmeasurement_location_id\nmeasurement_location_code\nmeasurement_location_description\nparameter_id\nparameter_code\ndate_time\nunit\nvalue\nvalue_type\n\n\n\n\n0\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-22 07:00:00+00:00\ncm\n33.90\nmeting\n\n\n1\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-22 07:10:00+00:00\ncm\n44.79\nmeting\n\n\n2\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-22 07:20:00+00:00\ncm\n57.31\nmeting\n\n\n3\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-22 07:30:00+00:00\ncm\n71.18\nmeting\n\n\n4\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-22 07:40:00+00:00\ncm\n84.47\nmeting\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n404\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-25 02:20:00+00:00\ncm\n28.44\nverwachting\n\n\n405\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-25 02:30:00+00:00\ncm\n19.95\nverwachting\n\n\n406\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-25 02:40:00+00:00\ncm\n11.89\nverwachting\n\n\n407\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-25 02:50:00+00:00\ncm\n3.49\nverwachting\n\n\n408\n3\nHoek van Holland\nHoek van Holland\n4724\nWATHTE\n2025-05-25 03:00:00+00:00\ncm\n-5.49\nverwachting\n\n\n\n\n409 rows × 9 columns\n\n\n\nLaad en run module (functie) LoadsWaterwebservicesRWS voor inlezen belastingen uit RWS Waterwebservices\nZoek op basis van een measurement_location_code die in RWS WaterWebservices overeenkomt met Locatie_MessageID!\n\nfrom toolbox_continu_inzicht.loads import LoadsWaterwebservicesRWS\n\nwaterwebservices_rws = LoadsWaterwebservicesRWS(data_adapter=data)\nds = waterwebservices_rws.run(\n    input=\"BelastingLocaties_Waterwebservices_RWS\",\n    output=\"Waterstanden_Waterwebservices_RWS\",\n)\nmeasuringlocations = waterwebservices_rws.df_in\nmeasuringlocations\n\n\n\n\n\n\n\nmeasurement_location_id\nmeasurement_location_code\nmeasurement_location_description\nsource\ntide\n\n\n\n\n3\n4\n9889\nHintham beneden\nRWS Waterwebservices\nFalse\n\n\n\n\n\nwaterlevels = waterwebservices_rws.df_out\nwaterlevels\n\n\n\n\n\n\n\nmeasurement_location_id\nmeasurement_location_code\nmeasurement_location_description\nparameter_id\nparameter_code\ndate_time\nunit\nvalue\nvalue_type\n\n\n\n\n0\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-22 09:00:00+01:00\ncm\n201.0\nmeting\n\n\n1\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-22 09:10:00+01:00\ncm\n199.0\nmeting\n\n\n2\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-22 09:20:00+01:00\ncm\n203.0\nmeting\n\n\n3\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-22 09:30:00+01:00\ncm\n201.0\nmeting\n\n\n4\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-22 09:40:00+01:00\ncm\n201.0\nmeting\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n138\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-23 08:00:00+01:00\ncm\n194.0\nmeting\n\n\n139\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-23 08:10:00+01:00\ncm\n195.0\nverwachting\n\n\n140\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-23 08:20:00+01:00\ncm\n193.0\nverwachting\n\n\n141\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-23 08:30:00+01:00\ncm\n193.0\nverwachting\n\n\n142\n4\n9889\nHintham beneden\n4724\nWATHTE\n2025-05-23 08:40:00+01:00\ncm\n191.0\nverwachting\n\n\n\n\n143 rows × 9 columns",
    "crumbs": [
      "Voorbeelden",
      "Belastingen inladen"
    ]
  },
  {
    "objectID": "examples/notebooks/4.adjust_integrated_statistics.html",
    "href": "examples/notebooks/4.adjust_integrated_statistics.html",
    "title": "Aanpassen van geïntegreerde faalkans",
    "section": "",
    "text": "Voor de module impactanalyse kan een totale of geïntegreerde faalkans worden berekend. Dit is een combinatie van een overschrijdingsfrequentielijn en een fragility curve. Om het mogelijk te maken om de fragility curve aan te passen kan de functie FragilityCurve.reliability_update() worden gebruikt. Het process van combineren, aanpassen en weer combineren wordt hier weergegeven.\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\npath = Path.cwd() / \"data_sets\"\nconfig = Config(config_path=path / \"integrate_statistics.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nfrom toolbox_continu_inzicht.fragility_curves import IntegrateFragilityCurve\nVoor het bepalen van een totale jaarlijkse kans combineren we een conditionele kans (fragility curve, wat iets zegt over de sterkte) met een kans dat die belasting optreedt (waterstands frequentiecurve). Hiervoor maken we gebruik van de functie IntegrateFragilityCurve.\nfig, ax = plt.subplots(1)\nfragility_curve_df = data_adapter.input(\"fragility_curve_csv\")\nexceedance_curve_df = data_adapter.input(\"exceedance_curve_csv\")\n\nfragility_curve_df.plot(x=\"hydraulicload\", ax=ax)\nax.set_ylabel(\"Failure probability\")\nax2 = ax.twinx()\nexceedance_curve_df.plot(x=\"hydraulicload\", ax=ax2, color=\"C1\")\n\n# maak een mooie legenda\nax2.legend().remove()\nhandles, labels = ax.get_legend_handles_labels()\nhandles_, labels_ = ax2.get_legend_handles_labels()\nax.legend(handles + handles_, labels + labels_);\n\nMet de functie IntegrateFragilityCurve integreren we de fragility curve uit\nintegrate_statistics_per_section = IntegrateFragilityCurve(data_adapter=data_adapter)\nintegrate_statistics_per_section.run(\n    input=[\"exceedance_curve_csv\", \"fragility_curve_csv\"], output=\"result\"\n)\nDeze kans voor een gegeven waterstand kunnen we weergeven in een grafiek\ninitial_integrated_curve = integrate_statistics_per_section.df_out\nfig, ax = plt.subplots()\nax.bar(\n    initial_integrated_curve[\"hydraulicload\"],\n    initial_integrated_curve[\"probability_contribution\"],\n    width=0.1,\n)\nax.set_xlim([0, 10])\nax.set_xlabel(\"Water level\")\nax.set_ylabel(\"Probability contribution\");\n\nIn sommige gevallen wil een beheerder dit aanpassen, bijvoorbeeld omdat hij weet dat een bepaalde waterstand al is opgetreden. Dit aanpassen kan met de functie FragilityCurve.reliability_update()\nfrom toolbox_continu_inzicht.base.fragility_curve import FragilityCurve\nupdate_level = 4.3\ntrust_factor = 1\n\nfragility_curve = FragilityCurve(data_adapter=data_adapter)\nfragility_curve.load(\"fragility_curve_csv\")\nfragility_curve.reliability_update(update_level=update_level, trust_factor=trust_factor)\nHier komt een nieuwe curve uit\ndata_adapter.set_dataframe_adapter(\n    \"updated_fragility_curve\", fragility_curve.as_dataframe(), if_not_exist=\"create\"\n)\nHier kunnen we opnieuw voor integreren en en we zien dat de curve naar rechts is opgeschoven.\nintegrate_statistics_per_section = IntegrateFragilityCurve(data_adapter=data_adapter)\nintegrate_statistics_per_section.run(\n    input=[\"exceedance_curve_csv\", \"updated_fragility_curve\"], output=\"result\"\n)\ndf_out = integrate_statistics_per_section.df_out\nfig, ax = plt.subplots()\nax.bar(\n    initial_integrated_curve[\"hydraulicload\"],\n    initial_integrated_curve[\"probability_contribution\"],\n    width=0.1,\n)\nax.bar(df_out[\"hydraulicload\"], df_out[\"probability_contribution\"], width=0.1)\nax.set_xlim([0, 10])\nax.set_xlabel(\"Water level\")\nax.set_ylabel(\"Probability contribution\");",
    "crumbs": [
      "Voorbeelden",
      "Aanpassen van geïntegreerde faalkans"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Toolbox Continu Inzicht",
    "section": "",
    "text": "Waterkeringbeheerders zijn gewend om hun waterkeringen te laten voldoen aan vastgestelde normen: daar baseren ze het ontwerp en hun beheer en onderhoud op. In een situatie met extreme droogte of extreem hoge waterstanden is er meer nodig. Dan is het belangrijk continu inzicht te hebben in de actuele risico’s voor het gebied in de eerstvolgende dagen. De methode ‘continu inzicht’ is precies daarop gericht: ervoor zorgen dat de beheerder 24/7 in control is. Met slimme monitoring en rekenmodellen wordt de actuele situatie geanalyseerd. De beheerder ziet hoe groot het risico is en waar de zwakke plekken zitten, zodat hij of zij gericht maatregelen kan nemen. De ‘Toolbox Continu Inzicht’ is door HKV lijn in water ontwikkeld voor waterschappen en Rijkswaterstaat. Door middel van deze toolbox worden de systemen achter ‘continu inzicht’ herontwikkeld in python en open source aangeboden."
  },
  {
    "objectID": "modules/architectuur.html",
    "href": "modules/architectuur.html",
    "title": "Basis architectuur Toolbox Continu Inzicht",
    "section": "",
    "text": "De architectuur van de Toolbox Continu Inzicht is ontworpen om flexibel te zijn.\n\nConfiguratie\nPer systeem kunnen de wensen van de gebruiker veranderen. Het systeem is dan ook te configureren voor verschillende databronnen. Door middel van een yaml configuratiebestand wordt de juist informatie meegegeven aan de modules en de data-adapter.\nHet kopje GlobalVariables is verplicht met minimaal een rootdir: dit is een map waarin de data bestanden staan en weggeschreven worden. De DataAdapter is ook verplicht, met minimaal één data adapter. De naam van de data adapter is vrij te kiezen. Er kunnen zoveel data adapters aangemaakt worden als gewenst.\nGlobalVariables:\n    rootdir: \"C:/data/toobox/\"\n\nDataAdapter:\n    EenTypeDataAdapter:\n        type: csv\n        file: \"eerste_voorbeeld.csv\"\nOnder GlobalVariables kan per datatype een variabele worden meegegeven die voor alle adapters van dit type gelden. Voor csv kan dit bijvoorbeeld het scheidingsteken zijn. Alle data adapters met het type csv krijgen nu de extra variabele mee.\nGlobalVariables:\n    rootdir: \"C:/data/toobox/\"\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \";\"\n    EenTypeDataAdapter:\n        type: csv\n        file: \"eerste_voorbeeld.csv\"\n    CSV_output:\n        type: csv\n        file: \"voorbeeld_output.csv\"\nNaast de data-adapters worden modules ook geconfigureerd in de GlobalVariables. Zo worden de opties voor de module LoadsMatroos ook mee gegeven in de GlobalVariables.\nGlobalVariables:\n    rootdir: \"C:/data/toobox/\"\n\n    LoadsMatroos:\n        website: \"noos\"\n        source: \"dcsm6_kf\"\n        parameters: [\"waterlevel\"]\n        MISSING_VALUE: 999\n\nDataAdapter:\n    ...\nDe tijd waarop de berekening van de toolbox plaatsvindt is ook te configureren met calc_time. Deze tijd moet in het ISO 8601 format zijn en wordt uitgelezen met datetime.datetime.fromisoformat. Indien geen tijd wordt meegegeven, maakt de Config klasse deze zelf aan met het tijdstip van runnen.\nGlobalVariables:\n    rootdir: \"C:/data/toobox/\"\n    calc_time: '2024-11-18 08:00:00'\n\n    LoadsMatroos:\n        website: \"noos\"\n        source: \"dcsm6_kf\"\n        parameters: [\"waterlevel\"]\n        MISSING_VALUE: 999\n\nDataAdapter:\n    ...\n\n\nData-adapter\nDe data-adapter wordt gebruikt om verschillende datatypes in en uit te lezen. Op dit moment zijn dit de volgende dataformaten:\n\nCSV\nNetCDF\nPostgreSQL\nExcel\nShape\n\nDeze wordt geconfigureerd in de een .yaml configuratiebestand. Een voorbeeld van een csv-bestand wordt hieronder weergegeven. Hierbij zijn type en file of path verplicht. In het voorbeeld hieronder wordt een relatief pad meegegeven als rootdir, dit wordt ook ondersteund.\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    my_csv_in:\n        type: csv\n        file: \"test_csv_in.csv\"\n    my_csv_out:\n        type: csv\n        file: \"test_csv_out.csv\"\n...\nIndien een bestand buiten de root directory valt kan in plaats van file ook een absoluut path worden meegegeven.\nDataAdapter:\n    MyCSV_anders:\n        type: csv\n        path: \"C:/data/Ander/pad_naar_csv.csv\"\n...\nNaast de verplichte waardes van een data-adapter worden ook alle overige opties doorgegeven. Voor de generieke data-adapters is er een check of de extra opgegeven opties ondersteund worden. Zo maakt de csv data adapter gebruik van pandas.read_csv en de NetCDF data adapter xarray.open_dataset. Voor PostgreSQL zijn alleen drie standaardopties beschikbaar: database, schema en table.\n\nZelf adapter locaties doorgeven\nIn de python module worden alles bestanden vanuit de map base.adapters gebruikt, mits ze beginnen met input_ of output_ om de twee uit elkaar te houden. Naast de geleverde data adapters, kan je via de global_variables ook een input_plugin_path en output_plugin_path definiëren. Alle python bestanden (.py) in deze mappen worden ingelezen en functies met input_ of output_ worden toegevoegd aan de mogelijke opties.\n\nVoorbeeld data adapterConfiguratieCode\n\n\ndef input_test_text(input_config: dict):\n    \"\"\"Function to read a text file given a path\"\"\"\n    # input_config contains all the information from reading the config file\n    path = input_config[\"abs_path\"]\n    # we check with `get_kwargs` which options are compatible\n    kwargs = get_kwargs(open, input_config)\n    kwargs.pop(\"file\")  # use the abs path instead of file\n    with open(path, **kwargs) as f:\n        data = f.read()\n    # return the data in a dataframe, this is just an example\n    return pd.DataFrame([data], columns=[\"text\"])\n\n\nGlobalVariables:\n    rootdir: 'data_sets'\n    input_plugin_path: 'data_sets'\n\nDataAdapter:\n    example_test:\n        type: test_text\n        file: 'test.txt'\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\ndf_in = data_adapter.input(\"example_test\")\n\n\n\nOptie 2:\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    my_csv_in:\n        type: csv\n        file: \"test_csv_in.csv\"\n...\n\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\ndata_adapter.set_dataframe_adapter(\"my_new_data_adapter\", input_df, if_not_exist=\"create\")\n\n\n\n\n\nAdapters aanmaken vanuit Python\nNaast het definiëren van data adapters via het configuratiebestand, kan dit ook vanuit Python zelf gedaan worden met de functie set_dataframe_adapter.\nDit kan op twee manieren:\n\nDe data adapter wordt vooraf in de configuratie opgegeven met het type Python. De functie geeft het desbetreffende dataframe door.\nEr is geen data-adapter gedefinieerd. Deze wordt aangemaakt bij het runnen van de code. Let op: het configuratiebestand verandert niet mee.\n\nOptie 1:\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    my_df_in:\n        type: python\n...\n\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\ndata_adapter.set_dataframe_adapter(\"my_df_in\", input_df, if_not_exist=\"raise\")\n...\n\n\n\nOptie 2:\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    my_csv_in:\n        type: csv\n        file: \"test_csv_in.csv\"\n...\n\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\ndata_adapter.set_dataframe_adapter(\"my_new_data_adapter\", input_df, if_not_exist=\"create\")\n\n\n\n\n\n\nWachtwoorden\nVoor bepaalde diensten, zoals het toegang krijgen tot een database, is een wachtwoord vereist. Deze kunnen in de “environmental variables” worden meegegeven, in de vorm van een .env bestand.\npostgresql_host=\"xxx.xx.xx.xx\"\npostgresql_database=\"xxxxxxx\"\npostgresql_port=\"xxxx\"\npostgresql_password=\"xxxx\"\npostgresql_user=\"xx\"",
    "crumbs": [
      "Modules",
      "Basis architectuur Toolbox Continu Inzicht"
    ]
  },
  {
    "objectID": "modules/bepalen_fragility_curves.html",
    "href": "modules/bepalen_fragility_curves.html",
    "title": "Bepalen fragility curves",
    "section": "",
    "text": "De Toolbox Continu Inzicht heeft de functionaliteit om fragility curves voor verschillende faalmechanismen uit te rekenen. Deze sectie beschrijft de beschikbare functies per type faalmechanisme. In Toolbox Continu Inzicht zijn 3 verschillende type fragility curves functies opgenomen: GEKB (Graserosie Kruin en Binnentalud), STPH (Piping en Heave) en voor alle overige faalmechanismen. Deze worden in het figuur hieronder weer gegeven.\n\n\n\nOverzicht van verschillende fragilityCurves in Toolbox Continu Inzicht\n\n\nDe fragility curves voor GEKB kunnen ‘on-the-fly’ worden berekend, afhankelijk van verschillende parameters (zoals windsnelheid en windrichting) kunnen deze worden aangepast. Voor STPH is een funtionaliteit beschikbaar om de fragility curves vooraf te berekenen. Vanwege de langere rekentijden en een benodigde kwaliteitscontrole is ervoor gekozen om de fragility curves voor STPH niet ‘on-the-fly’ te berekenen. Voor alle andere faalmechanismen geldt dat er geen functionaliteit binnen de Toolbox Continu Inzicht is om de fragility te berekenen. Voor deze overige faalmechanismen geldt dat de gebruiker buiten de Toolbox Continu Inzicht een fragility curve opgesteld (“pre-processed” fragility curves) en deze in de database definieert.\n\nGolfoverslag Erosie Kruin en Binnentalud (GEKB)\nVoor het bereken van fragility curves voor GEKB wordt gebruik gemaakt van de Python module pydra-core. Deze losstaande Python module is ontwikkeld door HKV en openbaar beschikbaar gemaakt op GitHub. De documentatie is op deze GitHub pagina te vinden.\nEen fragility curve kan berekend worden door de functie FragilityCurveOvertopping aan te roepen. Hier zijn drie DataFrames voor nodig: het eerste DataFrame met informatie over de hellingen, het tweede over het profiel en als laatste informatie over de bodem en strijklengte. In de berekening wordt modelonzekerheid meegenomen. Voor de modelonzekerheid zijn acht standaardwaardes gebruikt voor bretschneider, waarmee de golfhoogte en golfperiode worden bepaald. Deze kunnen aangepast worden als opties in de config.yaml, zoals te zien in het voorbeeld met gh_onz_mu. Naast onzekerheden kan ook de verhouding tussen de piekperiode van de golf ($T_p$) en de spectrale golfperiode ($Tm_{-1,0}$) worden aangepast met tp_tspec (standaard 1.1). Ook zijn er rekeninstellingen waarmee wordt gerekend, waarvan vier rekeninstellingen zijn aan te passen. De probabilistische berekening wordt gemaakt voor verschillende stapgroottes van de waterstand: grof en fijn. De standaardinstelling is een fijne stapgrootte van 0.05m (hstap) van 2m onder de kruin (upper_limit_coarse) tot 1.01m boven de kruin (upper_limit_fine). De standaardinstelling is een grove stapgrootte van 4m onder de kruin (lower_limit_coarse) tot 2m onder de kruin (upper_limit_coarse) met stappen van twee keer zo groot (2 * hstap = 0.1). Al deze variabele zijn los te configureren. Als de gebruiker deze niet opgeeft, dan wordt uitgegaan van de genoemde standaardwaardes.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    # default waardes, kunnen worden overschreven\n    FragilityCurveOvertopping:\n        gh_onz_mu: 0.96\n        gh_onz_sigma: 0.27\n        gp_onz_mu_tp: 1.03\n        gp_onz_sigma_tp: 0.13\n        gp_onz_mu_tspec: 1.03\n        gp_onz_sigma_tspec: 0.13\n        gh_onz_aantal: 7\n        gp_onz_aantal: 7\n        tp_tspec: 1.1\n        lower_limit_coarse: 4.0\n        upper_limit_coarse: 2.0\n        upper_limit_fine: 1.0\n        hstap: 0.05\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    slopes:\n        type: csv\n        file: \"slopes.csv\"\n    profiles:\n        type: csv\n        file: \"profiles.csv\"\n    bedlevel_fetch:\n        type: csv\n        file: \"bedlevelfetch.csv\"\n    fragility_curves:\n        type: csv\n        file: \"fragility_curves.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.fragility_curves import FragilityCurveOvertopping\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nfragility_curve_overtopping = FragilityCurveOvertopping(data_adapter=data_adapter)\nfragility_curve_overtopping.run(\n    input=[\"slopes\", \"profiles\", \"bedlevel_fetch\"],\n    output=\"fragility_curves\",\n)\n\n\n\n\n\nPiping en Heave (STPH)\nVoor het berekenen van de fragility curves voor piping (STPH) wordt gebruik gemaakt van de Python module probabilistic_piping. Deze losstaande Python module is ontwikkeld door HKV en is voor de Toolbox Continu Inzicht openbaar beschikbaar gemaakt op GitHub. De documentatie van deze module is daar ook te vinden.\n\nDisclaimer:\n\nDe uitvoer van 'probabilistic-piping' geeft meer informatie of een som in de berekening is gelukt. Binnen de Toolbox Continu Inzicht wordt geen validatie gedaan. Het is aan de gebruiker om te controleren of de berekende fragility curve daadwerkelijk logisch is.\n\n\n\nFragilityCurvePipingFixedWaterlevel\nDe functie FragilityCurvePipingFixedWaterlevel rekent met de drie deelmechanismen Uplift, Heave, Sellmeijer en geeft een gecombineerde fragility curve terug. Het combineren gebeurt hier door het minimum van de kansen van de drie deelmechanismen te nemen. De fragility curves van de drie deelmechanismen zijn beschikbaar via dedf_result_uplift, df_result_heave, en df_result_sellmeijer attributen.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\n    FragilityCurvePipingFixedWaterlevel:\n        debug: False\n        progress: True\n\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n\n    probabilistic_input:\n        type: excel\n        file: \"invoer_piping.xlsx\"\n        index_col: 0\n    waterlevels:\n        type: csv\n        file: \"waterlevels.csv\"\n    fragility_curve:\n        type: csv\n        file: \"fragility_curves_piping.csv\"\n\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.fragility_curves import FragilityCurvePipingFixedWaterlevel\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nfragility_curve_piping_fixed_waterlevel = FragilityCurvePipingFixedWaterlevel(data_adapter=data_adapter)\nfragility_curve_piping_fixed_waterlevel.run(\n    input=[\"probabilistic_input\", \"waterlevels\"],\n    output=\"fragility_curves\",\n)\n\n\n\n\n\n\nCombineren van fragility curves\nFragility curves kunnen op drie manieren worden gecombineerd: afhankelijk, onafhankelijk of met een gewogen gemiddelde. De tabel hieronder geeft hier een overzicht van.\n\n\n\n\n\n\n\n\nType\nFunctie\nFormule\n\n\n\n\nAfhankelijk\nCombineFragilityCurvesIndependent\n\\(P(fail,comb|h)=1-prod(1-P(fail,i|h))\\)\n\n\nOnafhankelijk\nCombineFragilityCurvesDependent\n\\(P(fail,comb|h)=max(P(fail,i|h))\\)\n\n\nGewogen gemiddelde\nCombineFragilityCurvesWeightedSum\n\\(P(fail,comb|h)=\\sum_{i=1}^{n}(w_i*P(fail,i|h))\\)\n\n\n\nVoor drie de functies is het nodig om een lijst op te geven, met daarin de namen van de data-adapters van de fragility curves die gecombineerd moeten worden. Bij de gewogen gemiddelde functie moet de laatste data-adapter de gewichten bevatten waarmee de fragility curves worden gecombineerd. Het gewichten DataFrame moet een kolom met ‘weights’ hebben. Er is bewust geen validatie of deze gewichten optellen tot 1, zodat de fragility curve ook geschaald kan worden. De tabel hieronder geeft weer hoe de tabel met gewichten er uit moet zien.\n\n\n\nweights\n\n\n\n\n0.6\n\n\n0.4\n\n\n\nBij het combineren van de fragility curves moeten eerst de waterstanden van de curves op elkaar afgestemd worden door middel van een gedeeld waterstandsgrid. Dit gedeelde waterstandsgrid wordt begrensd door de ondergrens en bovengrens van alle waterstanden van alle fragility curves. De stappen tussen deze grenzen worden vastgelegd met behulp van een vaste stapgrootte (refine_step_size, standaardwaarde is 0.05).\n\nConfiguratie (on)afhankelijkCode (on)afhankelijkConfiguratie gewogen gemiddeldeCode gewogen gemiddelde\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    fragility_curve_piping_csv:\n        type: csv\n        file: \"fragility_curve_piping.csv\"\n\n    fragility_curve_overtopping_csv:\n        type: csv\n        file: \"fragility_curve_overtopping.csv\"\n\n    fragility_curves:\n        type: csv\n        file: \"fragility_curve_combined.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\n\nfrom toolbox_continu_inzicht.fragility_curves import CombineFragilityCurvesIndependent\n\ncombine_fragility_curve = CombineFragilityCurvesIndependent(data_adapter=data_adapter)\ncombine_fragility_curve.run(\n    input=[\"fragility_curve_piping_csv\", \"fragility_curve_overtopping_csv\"],\n    output=\"fragility_curves\",\n)\n\nfrom toolbox_continu_inzicht.fragility_curves import CombineFragilityCurvesDependent\n\ncombine_fragility_curve_dep = CombineFragilityCurvesDependent(data_adapter=data_adapter)\ncombine_fragility_curve_dep.run(\n    input=[\"fragility_curve_piping_csv\", \"fragility_curve_overtopping_csv\"],\n    output=\"fragility_curves\",\n)\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    fragility_curve_piping_csv:\n        type: csv\n        file: \"fragility_curve_piping.csv\"\n\n    fragility_curve_overtopping_csv:\n        type: csv\n        file: \"fragility_curve_overtopping.csv\"\n\n    weighting_factor_csv:\n        type: csv\n        file: \"weighting_factor_combine.csv\"\n\n    fragility_curves:\n        type: csv\n        file: \"fragility_curve_combined.csv\"\n\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.fragility_curves import CombineFragilityCurvesWeightedSum\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\ncombine_fragility_curve = CombineFragilityCurvesWeightedSum(data_adapter=data_adapter)\ncombine_fragility_curve.run(\n    input=[\"fragility_curve_piping_csv\", \"fragility_curve_overtopping_csv\", \"weighting_factor_csv\"],\n    output=\"fragility_curves\",\n)",
    "crumbs": [
      "Modules",
      "Bepalen fragility curves"
    ]
  },
  {
    "objectID": "modules/impactanalyse.html",
    "href": "modules/impactanalyse.html",
    "title": "Impactanalyse: effect nieuwe statistiek en rekenregels op de faalkans",
    "section": "",
    "text": "De module impactanalyse is conceptueel anders dan de functionaliteit in de modules real-time en what-if. De gebruiker kan het effect van veranderingen in de statistiek van de belasting of rekenregels in kaart brengen. Hiervoor is in de Toolbox Continu Inzicht een functionaliteit toegevoegd om per dijkvak (sectie) de faalkans per jaar te berekenen. De faalkans per jaar wordt per dijvak berekend door het integreren van overschrijdingsfrequentielijn van een belasting (overschrijdingskans per jaar van belastingen) met een fragility curve (faalkans gegeven een belasting).\n\nJaarlijkse faalkans\nVoor het berekenen van de geïntegreerde faalkans zijn twee opties: (1) per dijkvak per faalmechanisme met de functie IntegrateFragilityCurve; of (2) voor meerdere dijkvakken en faalmechanismes met de functie IntegrateFragilityCurveMultiple. Qua configuratie is de functie IntegrateFragilityCurveMultiple identiek aan de functie IntegrateFragilityCurve, alleen loopt de functie IntegrateFragilityCurveMultiple nog extra de kolommen section_id en mechanism_id langs om voor alle fragility curves de geïntegreerde kans te berekenen.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n    moments: [-24,0,24,48]\n\n    IntegrateFragilityCurve:\n        refine_step_size: 0.05\n\nDataAdapter:\n    default_options:\n        csv:\n            sep: \",\"\n    fragility_curve_csv:\n        type: csv\n        file: \"single_fragility_curve.csv\"\n    exceedance_curve_csv:\n        type: csv\n        file: \"single_exceedance_curve.csv\"\n    result:\n        type: csv\n        file: \"result.csv\"\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.fragility_curves import IntegrateFragilityCurve\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nintegrate_statistics_per_section = IntegrateFragilityCurve(data_adapter=data_adapter)\nintegrate_statistics_per_section.run(\n    input=[\"exceedance_curve_csv\", \"fragility_curve_multi_csv\"], output=\"result\"\n)\n\n\n\n\n\nReliability Update (methode bewezen sterkte)\nNaast het berekenen van de faalkans per jaar per dijkvak, is het mogelijk om het effect van bewezen sterkte mee te nemen in de faalkansberekening. Met gebruik van FragilityCurve.reliability_update kan de fragility curve worden aangepast door een overleefde belastingsituatie in rekening te brengen. Ook hier geldt dat dit een waterstand, grondwaterstand of elke andere belastingparameter kan zijn. Hierdoor kan ook weer een geïntegreerde faalkans per jaar worden berekend met een nieuwe fragility curve, waarbij het effect van een overleefde belastingsituatie in is meegenomen. Dit stappenplan wordt weergegeven in het voorbeeld-notebook Aanpassen van geïntegreerde fragility curves.",
    "crumbs": [
      "Modules",
      "Impactanalyse: effect nieuwe statistiek en rekenregels op de faalkans"
    ]
  },
  {
    "objectID": "modules/kansen_en_status_per_sectie.html",
    "href": "modules/kansen_en_status_per_sectie.html",
    "title": "Conditionele kansen en status waterkering per sectie",
    "section": "",
    "text": "Voor het vertalen van een conditionele kans uit een fragility curve naar een status per sectie zijn er drie verschillende type functies. De technische zoals voor berekend, na een beheerdersoordeel en na een ingestelde maatregel. Als laatste kan de maatgevende faalkans van de drie opties worden bepaald en kan deze worden geclassificeerd met opgegeven grenzen.\n\nTechnische kans\nDit is de uitgangssituatie die altijd van belang is.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    fragilitycurves_table:\n        type: ci_postgresql_fragilitycurves_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n        measureid: 0\n\n    section_load_from_data_table:\n        type: ci_postgresql_section_load_from_data_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n    technical_failure_probability:\n        type: ci_postgresql_section_to_data\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n        parameter_id: 100\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.sections import SectionsTechnicalFailureprobability\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nsections_failureprobability = SectionsTechnicalFailureprobability(data_adapter=data_adapter)\nsections_failureprobability.run(\n        input=[\"fragilitycurves_table\", \"section_load_from_data_table\"],\n        output=\"technical_failure_probability\",\n    )\n\n\n\n\n\nKans na beheerdersoordeel\nIndien een beheerdersoordeel aanwezig is, kan deze ook worden gebruikt om een kans per sectie te bepalen.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    fragilitycurves_table:\n        type: ci_postgresql_measure_fragilitycurves_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n    section_load_from_data_table:\n        type: ci_postgresql_section_load_from_data_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n    measure_failure_probability:\n        type: ci_postgresql_section_to_data\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n        parameter_id: 101\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.sections import SectionsMeasureFailureprobability\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nsections_failureprobability = SectionsMeasureFailureprobability(data_adapter=data_adapter)\nsections_failureprobability.run(\n        input=[\"fragilitycurves_table\", \"section_load_from_data_table\"],\n        output=\"measure_failure_probability\",\n    )\n\n\n\n\n\nKans na maatregel\nIndien een maatregel aanwezig is, kan de kans gegeven de maatregel worden bepaald.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    in_expert_judgement_table:\n        type: ci_postgresql_section_expert_judgement_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n    expert_judgement_failure_probability:\n        type: ci_postgresql_section_to_data\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n        parameter_id: 102\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.sections import SectionsExpertJudgementFailureprobability\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nsections_failureprobability = SectionsExpertJudgementFailureprobability(data_adapter=data_adapter)\nsections_failureprobability.run(\n        input=\"in_expert_judgement_table\",\n        output=\"expert_judgement_failure_probability\",\n    )\n\n\n\n\n\nMaatgevende kans\nNadat voor de drie type kansen de faalkans per sectie is bepaald, kan ook de de maatgevende van de drie worden bepaald.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    in_section_data_failure_probability:\n        type: ci_postgresql_section_failure_probability_from_data_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n    out_section_failure_probability_data:\n        type: ci_postgresql_section_to_data\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n        parameter_id: 5\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.sections import SectionsCriticalFailureprobability\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nsections_failureprobability = SectionsCriticalFailureprobability(data_adapter=data_adapter)\nsections_failureprobability.run(\n        input=\"in_section_data_failure_probability\",\n        output=\"out_section_failure_probability_data\",\n    )\n\n\n\n\n\nClassificeren kans\nVoor het classificeren van kansen zijn twee inputs nodig: de klassen grenzen en faalkans per vak. Een klasse wordt vervolgens toegekend en terug gegeven.\n\nConfiguratieCode\n\n\nGlobalVariables:\n    rootdir: \"data_sets\"\n\nDataAdapter:\n    in_section_conditions:\n        type: ci_postgresql_section_thresholds_from_conditions_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n    in_section_data_failure_probability:\n        type: ci_postgresql_section_failure_probability_from_data_table\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n    out_section_states:\n        type: ci_postgresql_section_to_states\n        database: continuinzicht\n        schema: continuinzicht_demo_realtime\n\n\nfrom toolbox_continu_inzicht import Config, DataAdapter\nfrom toolbox_continu_inzicht.sections import SectionsClassify\n\nconfig = Config(config_path=\"config.yaml\")\nconfig.lees_config()\ndata_adapter = DataAdapter(config=config)\nsections_classify = SectionsClassify(data_adapter=data_adapter)\nsections_classify.run(\n        input=[\"in_section_conditions\", \"in_section_data_failure_probability\"],\n        output=\"out_section_states\",\n    )",
    "crumbs": [
      "Modules",
      "Conditionele kansen en status waterkering per sectie"
    ]
  },
  {
    "objectID": "overig/aquo_grootheid.html",
    "href": "overig/aquo_grootheid.html",
    "title": "Aquo grootheden",
    "section": "",
    "text": "Bij het inladen van belastingen wordt rekening gehouden met de Aquo standaard. Voor toolbox continu inzicht kan het soms lastig zijn omdat de termen binnen de Aquo standaard valt. Binnen de toolbox wordt de volgende meta data gebruikt:\n\n\n\nvoorkeurslabel\nomschrijving\nid\ngrootheid\ngroep\nlabel\ndefinitie\nlabel_en\nunits\n\n\n\n\nWaterdiepte\nWaterdiepte\n4723.0\nWATDTE\nGrootheid\nwaterdiepte\nverticale afstand tussen waterspiegel en waterbodem\nwater depth\nm\n\n\nWaterhoogte\nWaterhoogte\n4724.0\nWATHTE\nGrootheid\n\n\nwater height\nm+NAP\n\n\nWindrichting\nWindrichting\n4748.0\nWINDRTG\nGrootheid\nwindrichting\nde richting van waaruit de wind waait\nwind direction\n° tov Noord waar de wind vandaan komt\n\n\nWindsnelheid\nWindsnelheid\n4749.0\nWINDSHD\nGrootheid\nwindsnelheid\nde gemiddelde snelheid van luchtdeeltjes in de (buiten) lucht\nwindspeed\nm/s\n\n\nGolfhoogte\nGolfhoogte\n3640.0\nGOLFHTE\nGrootheid\ngolfhoogte\nverticale afstand tussen golftop en golfdal\nwave height\nm\n\n\nTemperatuur\nTemperatuur\n1522.0\nT\nGrootheid\ntemperatuur\nmaat voor hoe warm of koud iets is\ntemperature\n° Celcius\n\n\nTemperatuur lucht\nTemperatuur lucht\n-1.0\nTLCHT\n\n\n\ntemperature air\n° Celcius\n\n\nTemperatuur water\nTemperatuur water\n-2.0\nTWAT\n\n\n\ntemperature water\n° Celcius\n\n\nStroomrichting\nStroomrichting\n4513.0\nSTROOMRTG\nGrootheid\nstroomrichting\nrichting waarin het water stroomt. De richting die een stroom volgt, d.w.z. de richting van de snelheid van een stromend medium.\ncurrent direction\n° tov Noord waar de stroming heen gaat\n\n\nStroomsnelheid\nStroomsnelheid\n4519.0\nSTROOMSHD\nGrootheid\nstroomsnelheid\nde gemiddelde stroomsnelheid van het water, zijnde het quotiënt van de cumulatieve aanvoerhoeveelheid en de natte oppervlakte\ncurrent speed\nm/s\n\n\nDebiet\nDebiet\n3300.0\nQ\nGrootheid\ndebiet\nhet volume van een vloeistof of een gas dat per tijdseenheid door een doorsnede stroomt\nflow rate\nm3/s\n\n\nSaliniteit\nSaliniteit\n4103.0\nSALNTT\nGrootheid\nsaliniteit\nhet totale gewicht aan vaste stof per gewichtseenheid water, als alle carbonaatzouten zijn omgezet in oxiden, alle organische stof is geoxideerd en alle bromide- en jodide-ionen zijn vervangen door equivalente hoeveelheden chloride-ionen.\nsalinity\ng/kg\n\n\nActuele verdamping\nActuele verdamping\n4628.0\nVERDPG\nGrootheid\nactuele verdamping\nis de verdamping vanuit bodem en vegetatie\nprecipitation\nmm\n\n\nNeerslag\nNeerslag\n3991.0\nNEERSG\nGrootheid\nneerslag\nwater in vaste of vloeibare vorm dat uit de atmosfeer op het aardoppervlak valt\n\nmm\n\n\nNeerslagoverschot\nNeerslagoverschot\n5171.0\nNEERSOVST\nGrootheid\nneerslagoverschot\nhet verschil tussen de netto neerslag en de verdamping\nprecipitation excess\nmm\n\n\nNeerslagtekort\nNeerslagtekort\n5824.0\nNEERSTKRT\nGrootheid\nneerslagtekort\nhet verschil tussen de verdamping en de netto neerslag\nprecipitation deficit\nmm\n\n\nActuele verdamping\nActuele verdamping\n4627.0\nVERDPG\nGrootheid\nactuele verdamping\nis de verdamping vanuit bodem en vegetatie\nevaporation\nmm\n\n\nX-coordinaat\nX-coordinaat\n4768.0\nX_CODNT\nGrootheid\n\n\nx-coordinaat\n-\n\n\nY-coordinaat\nY-coordinaat\n4772.0\nY_CODNT\nGrootheid\n\n\ny-coordinaat\n-\n\n\nAstronomisch getij\nAstronomisch getij\n-3.0\nGETIJ\n\n\n\nastronomical tide\ncm tov MSL\n\n\nGrondwaterstand\nGrondwaterstand\n-4.0\nWATGRD\n\n\n\ngroundwater level\nm+NAP\n\n\n\nDit is een automatisch gegenereerde tabel, zie de bron code voor meer informatie",
    "crumbs": [
      "Overig",
      "Aquo grootheden"
    ]
  },
  {
    "objectID": "overig/contact.html",
    "href": "overig/contact.html",
    "title": "Contact",
    "section": "",
    "text": "Voor meer informatie, vragen of opmerkingen over de Toolbox Continu Inzicht kunt u terecht bij:\nSTOWA: Oscar van Dam (vandam@stowa.nl)\nHKV: Marit Zethof (m.zethof@hkv.nl), Bart Thonus (b.thonus@hkv.nl)",
    "crumbs": [
      "Overig",
      "Contact"
    ]
  },
  {
    "objectID": "overig/translations.html",
    "href": "overig/translations.html",
    "title": "Vertalingen",
    "section": "",
    "text": "De afspraak bij het ontwikkelen van toolbox continu inzicht is dat alles voor de gebruiker beschikbaar is in het Nederlands. De code zelf is echter in het Engels geschreven. Alle documentatie, errors en warnings zijn wel in het Engels. Om hier bij te helpen is een tabel opgesteld om bij te helpen.\n\n\n\nNederlands\nEngels\n\n\n\n\nWaterstand\nWaterlevel\n\n\nBelastingen\nHydraulicloads\n\n\nFaalkans\nFailure probability\n\n\nOverschrijdingskans\nExceedance probability\n\n\nOverschrijdingsfrequentie lijn\nExceedance frequency curve\n\n\nKruinhoogte\nCrest height\n\n\nOverslag\nOvertopping\n\n\nHelling\nSlope\n\n\nGolfhoogte\nWave height\n\n\nGolfperiode\nWave period\n\n\nGolfrichting\nWave direction",
    "crumbs": [
      "Overig",
      "Vertalingen"
    ]
  },
  {
    "objectID": "reference/ClassifyInspections.html",
    "href": "reference/ClassifyInspections.html",
    "title": "ClassifyInspections",
    "section": "",
    "text": "inspections.ClassifyInspections()\nClassificeert inspectieresultaten om weer te geven in de viewer.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_in\nOptional[pd.DataFrame | gpd.GeoDataFrame] | None\nInput DataFrame om te classificeren\n\n\ndf_styling\nOptional[pd.DataFrame] | None\nInput DataFrame met opmaak informatie\n\n\ndf_default_styling\nOptional[pd.DataFrame] | None\nDataFrame met standaard opmaak informatie, wordt gebruikt als er geen opmaak informatie is meegegeven Beschikbaar via get_default_styling() en te vervangen met set_default_styling(df)\n\n\ndf_out\nOptional[gpd.GeoDataFrame] | None\nOutput DataFrame containing the filtered DataFrame.\n\n\ndf_legend_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the legend information.\n\n\nstyling_schema\nClassVar[dict[str, str]]\nSchema DataFrame met de opmaak informatie\n\n\n\n\n\n\nHet classificeren van inspectieresultaten gebeurt op basis van de kolom ‘classify_column’ die is opgegeven in de global variables. De classificatie wordt gedaan op basis van de kolommen ‘upper_boundary’ en ‘lower_boundary’ in de opmaak DataFrame, deze wordt meegegeven als tweede input. Waardes die niet geclassificeerd kunnen worden, krijgen de opmaak van de rij zonder waardes in de upper_boundary en lower_boundary kolommen. Als er geen opmaak DataFrame wordt meegegeven, wordt de standaard opmaak gebruikt voor alle waardes. De standaard opmaak is op te halen met get_default_styling() en te vervangen met set_default_styling(df).\nEr zijn drie manier om geodata mee te geven. Deze wordt gebruik voor de opmaak. Alle projecties worden ondersteund, maar wordt omgezet naar EPSG:4326 voor de viewer.\nIn de Global Variables kan de projectie worden aangepast, standaard is EPSG:4326, alle andere projecties worden omgezet naar deze projectie.\n\nBij het mee geven van een GeoDataFrame, wordt de opmaak toegepast op de geometrie van het GeoDataFrame.\nAls er een ‘geometry’ kolom is in de DataFrame, wordt deze gebruikt om een GeoDataFrame te maken.\nIndien beide bovenstaande niet het geval is, wordt gezocht naar een kolom met x en met y co�rdinaten en deze wordt gebruikt om een GeoDataFrame te maken.\n\nHet type geometry wordt automatisch bepaald, maar kan ook meegegeven worden in de Global Variables. Slechts een type per tabel is toe gestaan.\nDe opties zijn:\n\nPolygon\nPolyline\nCircleMarker\nMarker\n\nDe output DataFrame bevat de opmaak informatie die is toegepast op de inspectieresultaten. Als er geen opmaak informatie is meegegeven, wordt de standaard opmaak gebruikt. De output kan een met alleen geclassificeerde resultaten of twee DataFrames met de inspectieresultaten en een met de legenda informatie. Ontbrekende kolommen in de opmaak DataFrame worden aangevuld met de standaard opmaak.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_default_styling\nHaal de standaard opmaak op.\n\n\nget_possible_styling\nHaal de mogelijke kolommen op voor de opmaak.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt het classificeren van inspectieresultaten om vervolgens weer te geven in de viewer.\n\n\nset_default_styling\nVervangt de default styling.\n\n\n\n\n\ninspections.ClassifyInspections.get_default_styling()\nHaal de standaard opmaak op.\nReturns: pd.DataFrame: Het DataFrame met de standaard opmaak.\n\n\n\ninspections.ClassifyInspections.get_possible_styling(\n    type=None\n    dict_output=False\n)\nHaal de mogelijke kolommen op voor de opmaak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntype\nstr | None\nType van de laag, indien None worden alle kolommen opgehaald. Mogelijke waardes zijn: Polyline, Polygon, Marker, CircleMarker\nNone\n\n\ndict_output\nbool\nAls True, wordt een dictionary met de kolommen en hun type terug gegeven. Anders wordt een lijst met de kolommen terug gegeven.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlist[str] | dict[str, dict]\nEen lijst met de mogelijke kolommen of een dictionary met de kolommen en hun type.\n\n\n\n\n\n\nDe standaard waardes & mogelijke opties zijn:\n\n\n\nPolyline\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van lijn\n\n\nweight\nnumber\n3\nbreedte lijn\n\n\nopacity\nnumber\n1\ntransparantie van lijn\n\n\ndashArray\nstring\nnull\narray voor dashed lijn\n\n\n\n\n\n\nPolygon\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\n\n\n\n\nMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nopacity\nnumber\n1\ntransparantie van marker\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nSVGname\nstring\nnull\nnaam van de marker\n\n\n\n\n\n\nCircleMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\nradius\nnumber\n10\ngroote van circle\n\n\n\nDefault waardes worden hier getoond, maar deze hebben geen invloed op de output. Om default aan te passen gebruik set_default_styling(df).\n\n\n\n\ninspections.ClassifyInspections.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\ninspections.ClassifyInspections.run(input, output)\nRunt het classificeren van inspectieresultaten om vervolgens weer te geven in de viewer.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr | list[str]\nNaam van de Data Adapters met inspectieresultaten en legenda met opmaak (indien gewenst), in die volgorde.\nrequired\n\n\noutput\nstr | list[str]\nNaam van Data adapter voor de output\nrequired\n\n\n\n\n\n\nDe input DataAdapters moet minimaal ‘Inspectieresultaten’ bevatten die worden geclassificeerd. De classificatie wordt gedaan op basis van de kolom ‘classify_column’ opgegeven in de global variables. Deze classificatiewaardes kunnen zowel numeriek zijn als text.\nIndien gewenst kan ook opmaak opties worden meegegeven. Als deze niet meegegeven wordt, wordt de standaard opmaak gebruikt. Deze is op te halen met get_default_styling() en te vervangen (geavanceerd) met set_default_styling(df).\nDeze moet de volgende kolommen bevatten:\n\n‘color’: kleur van de classificatie in hexadecimaal formaat\n‘lower_boundary’: ondergrens van de classificatie waarde. De inspectieresultaten moeten groter of gelijk zijn.\n\nDe classificatie in ‘lower_boundary’ en ‘classify_column’ moet van hetzelfde type zijn. Als de classificatie op basis van een waarde is, mag ook de volgende kolom aanwezig zijn:\n\n‘upper_boundary’: bovengrens van de classificatie\n\nBij text waardes wordt standaard tijdens de classificatie gekeken of de waarde identiek is aan de classificatie. Door de global variables kan dit ook worden aangepast naar een match_text_on check. De opties zijn:\n\n‘contains’: de classificatie waarde moet in de inspectieresultaten staan\n‘equals’: de classificatie waarde moet gelijk zijn aan de inspectieresultaten\n‘startswith’: de classificatie waarde moet aan het begin van de inspectieresultaten staan\n‘endswith’: de classificatie waarde moet aan het einde van de inspectieresultaten staan\n\nNaast de verplichte kolommen zijn ook een aantal die ook worden meegenomen in de output. Indien deze niet aanwezig zijn, worden ze ook niet meegenomen in de output.\nDit zijn:\n\n‘name’: Naam van de categorie\n‘description’: Omschrijving van de categorie\n‘symbol’: Symbool van de categorie\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAssertionError\nAls er maar ��n input DataAdapter wordt meegegeven als string in plaats van een lijst met minimaal twee items.\n\n\n\nKeyError\nAls de kolom die gebruikt moet worden voor classificatie niet aanwezig is in de input data.\n\n\n\nUserWarning\nAls de classificatie niet gelukt is, omdat de kolom die gebruikt moet worden voor classificatie geen tekst of getal is.\n\n\n\n\n\n\n\ninspections.ClassifyInspections.set_default_styling(df, permanent=False)\nVervangt de default styling. Parameters: df (pandas.DataFrame): Het DataFrame met de nieuwe default styling. permanent (bool, optional): Indien True, vervangt de default styling in het bestand. Standaard is False. Returns: None"
  },
  {
    "objectID": "reference/ClassifyInspections.html#attributes",
    "href": "reference/ClassifyInspections.html#attributes",
    "title": "ClassifyInspections",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_in\nOptional[pd.DataFrame | gpd.GeoDataFrame] | None\nInput DataFrame om te classificeren\n\n\ndf_styling\nOptional[pd.DataFrame] | None\nInput DataFrame met opmaak informatie\n\n\ndf_default_styling\nOptional[pd.DataFrame] | None\nDataFrame met standaard opmaak informatie, wordt gebruikt als er geen opmaak informatie is meegegeven Beschikbaar via get_default_styling() en te vervangen met set_default_styling(df)\n\n\ndf_out\nOptional[gpd.GeoDataFrame] | None\nOutput DataFrame containing the filtered DataFrame.\n\n\ndf_legend_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the legend information.\n\n\nstyling_schema\nClassVar[dict[str, str]]\nSchema DataFrame met de opmaak informatie"
  },
  {
    "objectID": "reference/ClassifyInspections.html#notes",
    "href": "reference/ClassifyInspections.html#notes",
    "title": "ClassifyInspections",
    "section": "",
    "text": "Het classificeren van inspectieresultaten gebeurt op basis van de kolom ‘classify_column’ die is opgegeven in de global variables. De classificatie wordt gedaan op basis van de kolommen ‘upper_boundary’ en ‘lower_boundary’ in de opmaak DataFrame, deze wordt meegegeven als tweede input. Waardes die niet geclassificeerd kunnen worden, krijgen de opmaak van de rij zonder waardes in de upper_boundary en lower_boundary kolommen. Als er geen opmaak DataFrame wordt meegegeven, wordt de standaard opmaak gebruikt voor alle waardes. De standaard opmaak is op te halen met get_default_styling() en te vervangen met set_default_styling(df).\nEr zijn drie manier om geodata mee te geven. Deze wordt gebruik voor de opmaak. Alle projecties worden ondersteund, maar wordt omgezet naar EPSG:4326 voor de viewer.\nIn de Global Variables kan de projectie worden aangepast, standaard is EPSG:4326, alle andere projecties worden omgezet naar deze projectie.\n\nBij het mee geven van een GeoDataFrame, wordt de opmaak toegepast op de geometrie van het GeoDataFrame.\nAls er een ‘geometry’ kolom is in de DataFrame, wordt deze gebruikt om een GeoDataFrame te maken.\nIndien beide bovenstaande niet het geval is, wordt gezocht naar een kolom met x en met y co�rdinaten en deze wordt gebruikt om een GeoDataFrame te maken.\n\nHet type geometry wordt automatisch bepaald, maar kan ook meegegeven worden in de Global Variables. Slechts een type per tabel is toe gestaan.\nDe opties zijn:\n\nPolygon\nPolyline\nCircleMarker\nMarker\n\nDe output DataFrame bevat de opmaak informatie die is toegepast op de inspectieresultaten. Als er geen opmaak informatie is meegegeven, wordt de standaard opmaak gebruikt. De output kan een met alleen geclassificeerde resultaten of twee DataFrames met de inspectieresultaten en een met de legenda informatie. Ontbrekende kolommen in de opmaak DataFrame worden aangevuld met de standaard opmaak."
  },
  {
    "objectID": "reference/ClassifyInspections.html#methods",
    "href": "reference/ClassifyInspections.html#methods",
    "title": "ClassifyInspections",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_default_styling\nHaal de standaard opmaak op.\n\n\nget_possible_styling\nHaal de mogelijke kolommen op voor de opmaak.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt het classificeren van inspectieresultaten om vervolgens weer te geven in de viewer.\n\n\nset_default_styling\nVervangt de default styling.\n\n\n\n\n\ninspections.ClassifyInspections.get_default_styling()\nHaal de standaard opmaak op.\nReturns: pd.DataFrame: Het DataFrame met de standaard opmaak.\n\n\n\ninspections.ClassifyInspections.get_possible_styling(\n    type=None\n    dict_output=False\n)\nHaal de mogelijke kolommen op voor de opmaak.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntype\nstr | None\nType van de laag, indien None worden alle kolommen opgehaald. Mogelijke waardes zijn: Polyline, Polygon, Marker, CircleMarker\nNone\n\n\ndict_output\nbool\nAls True, wordt een dictionary met de kolommen en hun type terug gegeven. Anders wordt een lijst met de kolommen terug gegeven.\nFalse\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlist[str] | dict[str, dict]\nEen lijst met de mogelijke kolommen of een dictionary met de kolommen en hun type.\n\n\n\n\n\n\nDe standaard waardes & mogelijke opties zijn:\n\n\n\nPolyline\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van lijn\n\n\nweight\nnumber\n3\nbreedte lijn\n\n\nopacity\nnumber\n1\ntransparantie van lijn\n\n\ndashArray\nstring\nnull\narray voor dashed lijn\n\n\n\n\n\n\nPolygon\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\n\n\n\n\nMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nopacity\nnumber\n1\ntransparantie van marker\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nSVGname\nstring\nnull\nnaam van de marker\n\n\n\n\n\n\nCircleMarker\n\n\n\n\n\n\n\nOption\nType\nDefault\nDescription\n\n\ncolor\nstring\n#9e9e9e\nhexcode van stroke\n\n\nweight\nnumber\n3\nbreedte stroke\n\n\nopacity\nnumber\n1\ntransparantie van stroke\n\n\ndashArray\nstring\nnull\narray voor dashed stroke\n\n\nfillColor\nstring\n#9e9e9e\nhexcode van fill\n\n\nfillOpacity\nnumber\n1\ntransparantie van fill\n\n\nradius\nnumber\n10\ngroote van circle\n\n\n\nDefault waardes worden hier getoond, maar deze hebben geen invloed op de output. Om default aan te passen gebruik set_default_styling(df).\n\n\n\n\ninspections.ClassifyInspections.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\ninspections.ClassifyInspections.run(input, output)\nRunt het classificeren van inspectieresultaten om vervolgens weer te geven in de viewer.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr | list[str]\nNaam van de Data Adapters met inspectieresultaten en legenda met opmaak (indien gewenst), in die volgorde.\nrequired\n\n\noutput\nstr | list[str]\nNaam van Data adapter voor de output\nrequired\n\n\n\n\n\n\nDe input DataAdapters moet minimaal ‘Inspectieresultaten’ bevatten die worden geclassificeerd. De classificatie wordt gedaan op basis van de kolom ‘classify_column’ opgegeven in de global variables. Deze classificatiewaardes kunnen zowel numeriek zijn als text.\nIndien gewenst kan ook opmaak opties worden meegegeven. Als deze niet meegegeven wordt, wordt de standaard opmaak gebruikt. Deze is op te halen met get_default_styling() en te vervangen (geavanceerd) met set_default_styling(df).\nDeze moet de volgende kolommen bevatten:\n\n‘color’: kleur van de classificatie in hexadecimaal formaat\n‘lower_boundary’: ondergrens van de classificatie waarde. De inspectieresultaten moeten groter of gelijk zijn.\n\nDe classificatie in ‘lower_boundary’ en ‘classify_column’ moet van hetzelfde type zijn. Als de classificatie op basis van een waarde is, mag ook de volgende kolom aanwezig zijn:\n\n‘upper_boundary’: bovengrens van de classificatie\n\nBij text waardes wordt standaard tijdens de classificatie gekeken of de waarde identiek is aan de classificatie. Door de global variables kan dit ook worden aangepast naar een match_text_on check. De opties zijn:\n\n‘contains’: de classificatie waarde moet in de inspectieresultaten staan\n‘equals’: de classificatie waarde moet gelijk zijn aan de inspectieresultaten\n‘startswith’: de classificatie waarde moet aan het begin van de inspectieresultaten staan\n‘endswith’: de classificatie waarde moet aan het einde van de inspectieresultaten staan\n\nNaast de verplichte kolommen zijn ook een aantal die ook worden meegenomen in de output. Indien deze niet aanwezig zijn, worden ze ook niet meegenomen in de output.\nDit zijn:\n\n‘name’: Naam van de categorie\n‘description’: Omschrijving van de categorie\n‘symbol’: Symbool van de categorie\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAssertionError\nAls er maar ��n input DataAdapter wordt meegegeven als string in plaats van een lijst met minimaal twee items.\n\n\n\nKeyError\nAls de kolom die gebruikt moet worden voor classificatie niet aanwezig is in de input data.\n\n\n\nUserWarning\nAls de classificatie niet gelukt is, omdat de kolom die gebruikt moet worden voor classificatie geen tekst of getal is.\n\n\n\n\n\n\n\ninspections.ClassifyInspections.set_default_styling(df, permanent=False)\nVervangt de default styling. Parameters: df (pandas.DataFrame): Het DataFrame met de nieuwe default styling. permanent (bool, optional): Indien True, vervangt de default styling in het bestand. Standaard is False. Returns: None"
  },
  {
    "objectID": "reference/CombineFragilityCurvesIndependent.html",
    "href": "reference/CombineFragilityCurvesIndependent.html",
    "title": "CombineFragilityCurvesIndependent",
    "section": "",
    "text": "fragility_curves.CombineFragilityCurvesIndependent()\nCombineer meerdere fragility curves onafhankelijk tot een enkele fragility curve.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\nlst_fragility_curves\nlist[pd.DataFrame]\nLijst van fragility curves die worden gecombineerd\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de gecombineerde fragility curve\n\n\ncombine_func\nCallable\nFunctie die wordt gebruikt om de fragility curves te combineren\n\n\nweights\nNone\nAlleen van toepassing bij de weighted sum methode, hier None\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen: hydraulicload: float, failure_probability: float\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt in FragilityCurve\n\n\n\n\n\n\nBij het combineren van de fragility curves moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen via de config worden ingesteld:\n\nextend_past_max. Hoever de nieuwe waterstanden verder gaan dan de maximale waterstanden van de inputcurves. Default is 0.01.\nrefine_step_size. De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncalculate_combined_curve\n\n\n\ncombine_func\nCombineer onafhankelijk: P(fail,comb|h) = 1 - PROD(1 - P(fail,i|h))\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nCombineert meerdere fragility curves\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.calculate_combined_curve(\n    extend_past_max\n    refine_step_size\n)\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.combine_func(\n    lst_fragility_curves\n    **kwargs\n)\nCombineer onafhankelijk: P(fail,comb|h) = 1 - PROD(1 - P(fail,i|h))\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.run(input, output)\nCombineert meerdere fragility curves\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van namen van de DataAdapters met fragility curves.\nrequired\n\n\noutput\nstr\nNaam van de output DataAdapter.\nrequired"
  },
  {
    "objectID": "reference/CombineFragilityCurvesIndependent.html#attributes",
    "href": "reference/CombineFragilityCurvesIndependent.html#attributes",
    "title": "CombineFragilityCurvesIndependent",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\nlst_fragility_curves\nlist[pd.DataFrame]\nLijst van fragility curves die worden gecombineerd\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de gecombineerde fragility curve\n\n\ncombine_func\nCallable\nFunctie die wordt gebruikt om de fragility curves te combineren\n\n\nweights\nNone\nAlleen van toepassing bij de weighted sum methode, hier None\n\n\nfragility_curve_schema\nClassVar[dict[str, str]]\nSchema waaraan de fragility curve moet voldoen: hydraulicload: float, failure_probability: float\n\n\ninterp_func\nCallable\nFunctie waarmee geinterpoleerd wordt in FragilityCurve"
  },
  {
    "objectID": "reference/CombineFragilityCurvesIndependent.html#notes",
    "href": "reference/CombineFragilityCurvesIndependent.html#notes",
    "title": "CombineFragilityCurvesIndependent",
    "section": "",
    "text": "Bij het combineren van de fragility curves moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen via de config worden ingesteld:\n\nextend_past_max. Hoever de nieuwe waterstanden verder gaan dan de maximale waterstanden van de inputcurves. Default is 0.01.\nrefine_step_size. De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05."
  },
  {
    "objectID": "reference/CombineFragilityCurvesIndependent.html#methods",
    "href": "reference/CombineFragilityCurvesIndependent.html#methods",
    "title": "CombineFragilityCurvesIndependent",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncalculate_combined_curve\n\n\n\ncombine_func\nCombineer onafhankelijk: P(fail,comb|h) = 1 - PROD(1 - P(fail,i|h))\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nCombineert meerdere fragility curves\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.calculate_combined_curve(\n    extend_past_max\n    refine_step_size\n)\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.combine_func(\n    lst_fragility_curves\n    **kwargs\n)\nCombineer onafhankelijk: P(fail,comb|h) = 1 - PROD(1 - P(fail,i|h))\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.CombineFragilityCurvesIndependent.run(input, output)\nCombineert meerdere fragility curves\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van namen van de DataAdapters met fragility curves.\nrequired\n\n\noutput\nstr\nNaam van de output DataAdapter.\nrequired"
  },
  {
    "objectID": "reference/Config.html",
    "href": "reference/Config.html",
    "title": "Config",
    "section": "",
    "text": "Config()\nBasisfunctie om de configuratie in te laden.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nconfig_path\nPath\nPad naar een .yaml-bestand waarin per functie staat beschreven wat de input- en outputbestanden zijn.\n\n\nglobal_variables\ndict\nGlobale variabelen die in de configuratie kunnen worden opgegeven\n\n\ndata_adapters\ndict\nData adapters die in de configuratie kunnen worden op\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ninit_data_adapters\n\n\n\nlees_config\nLaadt het gegeven pad in, zet de configuraties klaar in de Config class.\n\n\n\n\n\nConfig.init_data_adapters()\n\n\n\nConfig.lees_config()\nLaadt het gegeven pad in, zet de configuraties klaar in de Config class."
  },
  {
    "objectID": "reference/Config.html#attributes",
    "href": "reference/Config.html#attributes",
    "title": "Config",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nconfig_path\nPath\nPad naar een .yaml-bestand waarin per functie staat beschreven wat de input- en outputbestanden zijn.\n\n\nglobal_variables\ndict\nGlobale variabelen die in de configuratie kunnen worden opgegeven\n\n\ndata_adapters\ndict\nData adapters die in de configuratie kunnen worden op"
  },
  {
    "objectID": "reference/Config.html#methods",
    "href": "reference/Config.html#methods",
    "title": "Config",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninit_data_adapters\n\n\n\nlees_config\nLaadt het gegeven pad in, zet de configuraties klaar in de Config class.\n\n\n\n\n\nConfig.init_data_adapters()\n\n\n\nConfig.lees_config()\nLaadt het gegeven pad in, zet de configuraties klaar in de Config class."
  },
  {
    "objectID": "reference/Filter.html",
    "href": "reference/Filter.html",
    "title": "Filter",
    "section": "",
    "text": "inspections.Filter()\nFiltert een DataFrame aan de hand van de opgegeven configuratie.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_in\nOptional[pd.DataFrame] | None\nInput DataFrame om te filteren\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame die gefilterd is.\n\n\n\n\n\n\nVoor het filteren zijn drie opties te configureren:\n\nquery: SQL-achtige query om de DataFrame te filteren, zie ook pandas.DataFrame.query. Gebruik een '‘voor kolomnamen met spaties, bijvoorbeeld’Meetpunt code == 1’`.\ndrop_columns: Lijst van kolommen die verwijderd moeten worden\nkeep_columns: Lijst van kolommen die behouden moeten worden\n\nAls meerdere van deze opties zijn geconfigureerd, worden ze in bovenstaande volgorde toegepast.\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt filtering van een input DataAdapter.\n\n\n\n\n\ninspections.Filter.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\ninspections.Filter.run(input, output)\nRunt filtering van een input DataAdapter.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de DataAdapter om te filteren\nrequired\n\n\noutput\nstr\nNaam van DataAdapter voor de output\nrequired"
  },
  {
    "objectID": "reference/Filter.html#attributes",
    "href": "reference/Filter.html#attributes",
    "title": "Filter",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_in\nOptional[pd.DataFrame] | None\nInput DataFrame om te filteren\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame die gefilterd is."
  },
  {
    "objectID": "reference/Filter.html#notes",
    "href": "reference/Filter.html#notes",
    "title": "Filter",
    "section": "",
    "text": "Voor het filteren zijn drie opties te configureren:\n\nquery: SQL-achtige query om de DataFrame te filteren, zie ook pandas.DataFrame.query. Gebruik een '‘voor kolomnamen met spaties, bijvoorbeeld’Meetpunt code == 1’`.\ndrop_columns: Lijst van kolommen die verwijderd moeten worden\nkeep_columns: Lijst van kolommen die behouden moeten worden\n\nAls meerdere van deze opties zijn geconfigureerd, worden ze in bovenstaande volgorde toegepast."
  },
  {
    "objectID": "reference/Filter.html#methods",
    "href": "reference/Filter.html#methods",
    "title": "Filter",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt filtering van een input DataAdapter.\n\n\n\n\n\ninspections.Filter.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\ninspections.Filter.run(input, output)\nRunt filtering van een input DataAdapter.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de DataAdapter om te filteren\nrequired\n\n\noutput\nstr\nNaam van DataAdapter voor de output\nrequired"
  },
  {
    "objectID": "reference/FragilityCurveOvertopping.html",
    "href": "reference/FragilityCurveOvertopping.html",
    "title": "FragilityCurveOvertopping",
    "section": "",
    "text": "fragility_curves.FragilityCurveOvertopping()\nMaakt een enkele fragility curve voor golf overslag.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_slopes\nOptional[pd.DataFrame] | None\nDataFrame met helling data.\n\n\ndf_profile\nOptional[pd.DataFrame] | None\nDataFrame met profiel data.\n\n\ndf_bed_levels\nOptional[pd.DataFrame] | None\nDataFrame met bed level data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de resultaten van de berekening.\n\n\n\n\n\n\nVia de configuratie kunnen de volgende opties worden ingesteld, deze zijn float ten zij anders aangegeven. Onzekerheden:\n\ngh_onz_mu, GolfHoogte onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfhoogte (standaard 0.96)\ngh_onz_sigma, GolfHoogte onzekerheid sigma: standaardafwijking waarde (standaard 0.27)\ngp_onz_mu_tp, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tp, GolfPerioden onzekerheid sigma: standaardafwijking waarde (standaard 0.13)\ngp_onz_mu_tspec, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tspec, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngh_onz_aantal, Aantal onzekerheden in de golfhoogte (standaard 7)\ngp_onz_aantal, Aantal onzekerheden in de golfperiode (standaard 7)\n\ntp_tspec, de verhouding tussen de piek periode van de golf ($T_p$) en de spectrale golfperiode ($Tm_{-1,0}$) (standaard 1.1).\nDe waterniveaus waarmee probabilistisch gerekend wordt is verdeeld in twee delen: grof en fijn.\n\nlower_limit_coarse, De ondergrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 4.0m onder de kruin)\nupper_limit_coarse, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 2.0m onder de kruin). Er is geen lower_limit_fine omdat deze altijd gelijk is aan upper_limit_coarse.\nupper_limit_fine, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in fijne stappen (standaard 1.01m boven de kruin)\nhstap, De fijne stapgrootte van de waterstanden waarvoor de fragility curve wordt berekend (standaard 0.05), de grove stapgrootte is 2 * hstap.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurveOvertopping.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurveOvertopping.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurveOvertopping.find_jump_indices()\n\n\n\nfragility_curves.FragilityCurveOvertopping.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurveOvertopping.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurveOvertopping.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurveOvertopping.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurveOvertopping.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.run(input, output)\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profiel data moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurveOvertopping.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/FragilityCurveOvertopping.html#attributes",
    "href": "reference/FragilityCurveOvertopping.html#attributes",
    "title": "FragilityCurveOvertopping",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object\n\n\ndf_slopes\nOptional[pd.DataFrame] | None\nDataFrame met helling data.\n\n\ndf_profile\nOptional[pd.DataFrame] | None\nDataFrame met profiel data.\n\n\ndf_bed_levels\nOptional[pd.DataFrame] | None\nDataFrame met bed level data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame met de resultaten van de berekening."
  },
  {
    "objectID": "reference/FragilityCurveOvertopping.html#notes",
    "href": "reference/FragilityCurveOvertopping.html#notes",
    "title": "FragilityCurveOvertopping",
    "section": "",
    "text": "Via de configuratie kunnen de volgende opties worden ingesteld, deze zijn float ten zij anders aangegeven. Onzekerheden:\n\ngh_onz_mu, GolfHoogte onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfhoogte (standaard 0.96)\ngh_onz_sigma, GolfHoogte onzekerheid sigma: standaardafwijking waarde (standaard 0.27)\ngp_onz_mu_tp, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tp, GolfPerioden onzekerheid sigma: standaardafwijking waarde (standaard 0.13)\ngp_onz_mu_tspec, GolfPerioden onzekerheid mu: gemiddelde waarde van de onzekerheid van de golfperiode (standaard 1.03)\ngp_onz_sigma_tspec, GolfPerioden onzekerheid sigma: standaard afwijking waarde (standaard 0.13)\ngh_onz_aantal, Aantal onzekerheden in de golfhoogte (standaard 7)\ngp_onz_aantal, Aantal onzekerheden in de golfperiode (standaard 7)\n\ntp_tspec, de verhouding tussen de piek periode van de golf ($T_p$) en de spectrale golfperiode ($Tm_{-1,0}$) (standaard 1.1).\nDe waterniveaus waarmee probabilistisch gerekend wordt is verdeeld in twee delen: grof en fijn.\n\nlower_limit_coarse, De ondergrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 4.0m onder de kruin)\nupper_limit_coarse, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in grove stappen (standaard 2.0m onder de kruin). Er is geen lower_limit_fine omdat deze altijd gelijk is aan upper_limit_coarse.\nupper_limit_fine, De bovengrens van de waterstanden waarvoor de fragility curve wordt berekend in fijne stappen (standaard 1.01m boven de kruin)\nhstap, De fijne stapgrootte van de waterstanden waarvoor de fragility curve wordt berekend (standaard 0.05), de grove stapgrootte is 2 * hstap."
  },
  {
    "objectID": "reference/FragilityCurveOvertopping.html#methods",
    "href": "reference/FragilityCurveOvertopping.html#methods",
    "title": "FragilityCurveOvertopping",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurveOvertopping.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurveOvertopping.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurveOvertopping.find_jump_indices()\n\n\n\nfragility_curves.FragilityCurveOvertopping.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurveOvertopping.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurveOvertopping.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurveOvertopping.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurveOvertopping.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.run(input, output)\nRunt de berekening van de fragility curve voor golfoverslag\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profiel data moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.FragilityCurveOvertopping.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurveOvertopping.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/FragilityCurvePipingFixedWaterlevel.html",
    "href": "reference/FragilityCurvePipingFixedWaterlevel.html",
    "title": "FragilityCurvePipingFixedWaterlevel",
    "section": "",
    "text": "fragility_curves.FragilityCurvePipingFixedWaterlevel()\nMaakt een enkele fragility curve voor piping met een gegeven waterstand.\nDe fragility curve wordt berekend met behulp van de probabilistic_piping package, zie de eigen documentatie voor meer informatie.\nDeze functie berekent fragility curves voor uplift, heave, Sellmeijer, en de gecombineerde mechanismes.\nVoor het combineren van de mechanismes wordt het minimum van de kansen van de drie sub-mechanismes genomen, De gecombineerde fragility curve is de standaard output, de andere kunnen worden opgevraagd met de df_result_uplift, df_result_heave, en df_result_sellmeijer attributen.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_prob_input\nOptional[pd.DataFrame] | None\nDataFrame containing probabilistic input data.\n\n\ndf_hydraulicload\nOptional[pd.DataFrame] | None\nDataFrame containing hydraulic load data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the final fragility curve.\n\n\ndf_result_uplift\nOptional[pd.DataFrame] | None\nDataFrame containing the uplift mechanism results.\n\n\ndf_result_heave\nOptional[pd.DataFrame] | None\nDataFrame containing the heave mechanism results.\n\n\ndf_result_sellmeijer\nOptional[pd.DataFrame] | None\nDataFrame containing the Sellmeijer mechanism results.\n\n\ndf_result_combined\nOptional[pd.DataFrame] | None\nDataFrame containing the combined mechanism results.\n\n\n\n\n\n\nDe volgende bool opties kunnen worden ingesteld in de global_variables van de config:\n\nprogress, Standaard is False\ndebug, Standaard is False\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor piping\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand. Extra calculate functies is om overerving makkelijker te maken voor effecten.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.find_jump_indices()\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.run(input, output)\nRunt de berekening van de fragility curve voor piping\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nZie de documentatie van probabilistic_piping.probabilistic_fixedwl.ProbPipingFixedWaterlevelSimple voor meer informatie.\n\nprob_input is afhankelijk van de probabilistische berekening die je wilt uitvoeren, zie externe documentatie.\nDe hydraulicload data adapter geeft de waterlevel data door, deze moet de kolom hydraulicload bevatten met floats.\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/FragilityCurvePipingFixedWaterlevel.html#attributes",
    "href": "reference/FragilityCurvePipingFixedWaterlevel.html#attributes",
    "title": "FragilityCurvePipingFixedWaterlevel",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_prob_input\nOptional[pd.DataFrame] | None\nDataFrame containing probabilistic input data.\n\n\ndf_hydraulicload\nOptional[pd.DataFrame] | None\nDataFrame containing hydraulic load data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the final fragility curve.\n\n\ndf_result_uplift\nOptional[pd.DataFrame] | None\nDataFrame containing the uplift mechanism results.\n\n\ndf_result_heave\nOptional[pd.DataFrame] | None\nDataFrame containing the heave mechanism results.\n\n\ndf_result_sellmeijer\nOptional[pd.DataFrame] | None\nDataFrame containing the Sellmeijer mechanism results.\n\n\ndf_result_combined\nOptional[pd.DataFrame] | None\nDataFrame containing the combined mechanism results."
  },
  {
    "objectID": "reference/FragilityCurvePipingFixedWaterlevel.html#notes",
    "href": "reference/FragilityCurvePipingFixedWaterlevel.html#notes",
    "title": "FragilityCurvePipingFixedWaterlevel",
    "section": "",
    "text": "De volgende bool opties kunnen worden ingesteld in de global_variables van de config:\n\nprogress, Standaard is False\ndebug, Standaard is False"
  },
  {
    "objectID": "reference/FragilityCurvePipingFixedWaterlevel.html#methods",
    "href": "reference/FragilityCurvePipingFixedWaterlevel.html#methods",
    "title": "FragilityCurvePipingFixedWaterlevel",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor piping\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragiliteitscurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand. Extra calculate functies is om overerving makkelijker te maken voor effecten.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.find_jump_indices()\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.run(input, output)\nRunt de berekening van de fragility curve voor piping\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: prob_input, hydraulicload\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\nZie de documentatie van probabilistic_piping.probabilistic_fixedwl.ProbPipingFixedWaterlevelSimple voor meer informatie.\n\nprob_input is afhankelijk van de probabilistische berekening die je wilt uitvoeren, zie externe documentatie.\nDe hydraulicload data adapter geeft de waterlevel data door, deze moet de kolom hydraulicload bevatten met floats.\n\n\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.FragilityCurvePipingFixedWaterlevel.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/get_fews_locations.html",
    "href": "reference/get_fews_locations.html",
    "title": "get_fews_locations",
    "section": "",
    "text": "loads.get_fews_locations(host, port, region, filter_id)\nHaal voor FEWS de locaties op voor de opgegeven parameters.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nhost\nstr\nFEWS server host URL\nrequired\n\n\nport\nint\nPort waar de REST-service draait\nrequired\n\n\nregion\nstr\nIn FEWS gedefinieerde region\nrequired\n\n\nfilter_id\nstr\nFilter van de locaties\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nPandas dataframe met locaties"
  },
  {
    "objectID": "reference/get_fews_locations.html#parameters",
    "href": "reference/get_fews_locations.html#parameters",
    "title": "get_fews_locations",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nhost\nstr\nFEWS server host URL\nrequired\n\n\nport\nint\nPort waar de REST-service draait\nrequired\n\n\nregion\nstr\nIn FEWS gedefinieerde region\nrequired\n\n\nfilter_id\nstr\nFilter van de locaties\nrequired"
  },
  {
    "objectID": "reference/get_fews_locations.html#returns",
    "href": "reference/get_fews_locations.html#returns",
    "title": "get_fews_locations",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\npd.DataFrame\nPandas dataframe met locaties"
  },
  {
    "objectID": "reference/get_matroos_locations.html",
    "href": "reference/get_matroos_locations.html",
    "title": "get_matroos_locations",
    "section": "",
    "text": "loads.get_matroos_locations(source=None, parameter=None, endpoint='timeseries')\nHaal alle matroos locaties op, indien gewenst ook bron en parameter.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nsource\nstr | None\nBron in de matroos, None geeft alle terug\nNone\n\n\nparameter\nstr | None\nSpecifieke parameter waar voor je locaties zoekt, None geeft alle terug\nNone\n\n\nendpoint\nstr\nNaam van de endpoint, standaard ‘timeseries’\n'timeseries'\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ngeopandas.GeoDataFrame\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAlleen endpoint=‘timeseries’ is nu beschikbaar\n\n\n\nConnectionError\nHelaas is matroos niet altijd even stabiel, dit vangen we af met connection error\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ngeopandas.GeoDataFrame"
  },
  {
    "objectID": "reference/get_matroos_locations.html#parameters",
    "href": "reference/get_matroos_locations.html#parameters",
    "title": "get_matroos_locations",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nsource\nstr | None\nBron in de matroos, None geeft alle terug\nNone\n\n\nparameter\nstr | None\nSpecifieke parameter waar voor je locaties zoekt, None geeft alle terug\nNone\n\n\nendpoint\nstr\nNaam van de endpoint, standaard ‘timeseries’\n'timeseries'"
  },
  {
    "objectID": "reference/get_matroos_locations.html#returns",
    "href": "reference/get_matroos_locations.html#returns",
    "title": "get_matroos_locations",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ngeopandas.GeoDataFrame"
  },
  {
    "objectID": "reference/get_matroos_locations.html#raises",
    "href": "reference/get_matroos_locations.html#raises",
    "title": "get_matroos_locations",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nUserWarning\nAlleen endpoint=‘timeseries’ is nu beschikbaar\n\n\n\nConnectionError\nHelaas is matroos niet altijd even stabiel, dit vangen we af met connection error"
  },
  {
    "objectID": "reference/get_matroos_locations.html#returns-1",
    "href": "reference/get_matroos_locations.html#returns-1",
    "title": "get_matroos_locations",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ngeopandas.GeoDataFrame"
  },
  {
    "objectID": "reference/get_rws_webservices_locations.html",
    "href": "reference/get_rws_webservices_locations.html",
    "title": "get_rws_webservices_locations",
    "section": "",
    "text": "get_rws_webservices_locations\nloads.get_rws_webservices_locations()\nHaal locaties op die bekend zijn bij de RWS webservice."
  },
  {
    "objectID": "reference/get_waterinfo_thresholds.html",
    "href": "reference/get_waterinfo_thresholds.html",
    "title": "get_waterinfo_thresholds",
    "section": "",
    "text": "loads.get_waterinfo_thresholds(location_code, parameter_id='waterhoogte')\nHaal voor Waterinfo de thresholds op voor de opgegegeven parameter.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nlocation_code\nstr\nLocatiecode van de waterinfo locatie\nrequired\n\n\nparameter_id\nstr\nWaterinfo parameter bij geen waarde ‘waterhoogte’\n'waterhoogte'\n\n\n\n\n\n\nGebruikte API: https://waterinfo.rws.nl/api/chart/get\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nDataframe\nPandas dataframe met thresholds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nConnectionError\nAls de verbinding met de API niet lukt of geen thresholds zijn gevonden"
  },
  {
    "objectID": "reference/get_waterinfo_thresholds.html#parameters",
    "href": "reference/get_waterinfo_thresholds.html#parameters",
    "title": "get_waterinfo_thresholds",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\nlocation_code\nstr\nLocatiecode van de waterinfo locatie\nrequired\n\n\nparameter_id\nstr\nWaterinfo parameter bij geen waarde ‘waterhoogte’\n'waterhoogte'"
  },
  {
    "objectID": "reference/get_waterinfo_thresholds.html#notes",
    "href": "reference/get_waterinfo_thresholds.html#notes",
    "title": "get_waterinfo_thresholds",
    "section": "",
    "text": "Gebruikte API: https://waterinfo.rws.nl/api/chart/get"
  },
  {
    "objectID": "reference/get_waterinfo_thresholds.html#returns",
    "href": "reference/get_waterinfo_thresholds.html#returns",
    "title": "get_waterinfo_thresholds",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nDataframe\nPandas dataframe met thresholds"
  },
  {
    "objectID": "reference/get_waterinfo_thresholds.html#raises",
    "href": "reference/get_waterinfo_thresholds.html#raises",
    "title": "get_waterinfo_thresholds",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nConnectionError\nAls de verbinding met de API niet lukt of geen thresholds zijn gevonden"
  },
  {
    "objectID": "reference/input_fragilitycurve.html",
    "href": "reference/input_fragilitycurve.html",
    "title": "input_fragilitycurve",
    "section": "",
    "text": "base.adapters.input.continu_inzicht_postgresql.input_fragilitycurve\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\n\n\n\nName\nDescription\n\n\n\n\ninput_ci_postgresql_bedlevelfetch\nLeest bedlevelfetch data van PostgreSQL-database in de bedlevelfetch tabel en zet namen goed.\n\n\ninput_ci_postgresql_fragilitycurves\nLeest fragility curves data van PostgreSQL-database in.\n\n\ninput_ci_postgresql_fragilitycurves_methode2_table\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\n\n\ninput_ci_postgresql_fragilitycurves_overtopping\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op overtopping.\n\n\ninput_ci_postgresql_fragilitycurves_piping\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\ninput_ci_postgresql_fragilitycurves_stability\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\ninput_ci_postgresql_fragilitycurves_table\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\n\n\ninput_ci_postgresql_measure_fragilitycurves_table\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en maatregelen\n\n\ninput_ci_postgresql_probablistic_piping\nLeest probablistic data van PostgreSQL-database in de probablistic piping tabel en hernoemt de kolomen.\n\n\ninput_ci_postgresql_profiles\nLeest profieldata van PostgreSQL-database in de profieltabel en zet namen goed.\n\n\ninput_ci_postgresql_slopes\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed.\n\n\ninput_ci_postgresql_slopes_limburg\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed.\n\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_bedlevelfetch(\n    input_config\n)\nLeest bedlevelfetch data van PostgreSQL-database in de bedlevelfetch tabel en zet namen goed.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_methode2_table(\n    input_config\n)\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\nYAML voorbeeld:\ntype: ci_postgresql_fragilitycurves_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nmeasureid: 0\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht database\nschema (str): schema van de Continu Inzicht database\nmeasureid (int64, optioneel): maatregel id, bij geen waarde wordt geen maatregel (measureid=0) gebruikt\ntimedep (int64, optioneel): tijdsafhankelijk 0=nee, 1=ja\ndegradatieid (int64, optioneel): rekening houden met degradatie (nog net ge�mplementeerd)\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nmeasure_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nfailuremechanismid: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nhydraulicload: float64 : belasting van het tijdreeksitem\nfailureprobability: float64 : faalkans van het tijdreeksitem\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_overtopping(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op overtopping.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_piping(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_stability(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_table(\n    input_config\n)\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\nYAML voorbeeld:\ntype: ci_postgresql_fragilitycurves_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nmeasureid: 0\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht database\nschema (str): schema van de Continu Inzicht database\nmeasureid (int64, optioneel): maatregel id, bij geen waarde wordt geen maatregel (measureid=0) gebruikt\ntimedep (int64, optioneel): tijdsafhankelijk 0=nee, 1=ja\ndegradatieid (int64, optioneel): rekening houden met degradatie (nog net ge�mplementeerd)\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nmeasure_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nfailuremechanismid: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nhydraulicload: float64 : belasting van het tijdreeksitem\nfailureprobability: float64 : faalkans van het tijdreeksitem\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_measure_fragilitycurves_table(\n    input_config\n)\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en maatregelen\nYaml example:\ntype: ci_postgresql_measure_fragilitycurves_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht database\nschema (str): schema van de Continu Inzicht database\ntimedep (int64, optioneel): tijdsafhankelijk 0=nee, 1=ja\ndegradatieid (int64, optioneel): rekening houden met degradatie (nog net ge�mplementeerd)\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nmeasure_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nfailuremechanismid: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nhydraulicload: float64 : belasting van het tijdreeksitem\nfailureprobability: float64 : faalkans van het tijdreeksitem\nsuccessrate: float64 : kans op succes van de maatregel\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_probablistic_piping(\n    input_config\n)\nLeest probablistic data van PostgreSQL-database in de probablistic piping tabel en hernoemt de kolomen.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_profiles(\n    input_config\n)\nLeest profieldata van PostgreSQL-database in de profieltabel en zet namen goed.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_slopes(\n    input_config\n)\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_slopes_limburg(\n    input_config\n)\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed."
  },
  {
    "objectID": "reference/input_fragilitycurve.html#functions",
    "href": "reference/input_fragilitycurve.html#functions",
    "title": "input_fragilitycurve",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninput_ci_postgresql_bedlevelfetch\nLeest bedlevelfetch data van PostgreSQL-database in de bedlevelfetch tabel en zet namen goed.\n\n\ninput_ci_postgresql_fragilitycurves\nLeest fragility curves data van PostgreSQL-database in.\n\n\ninput_ci_postgresql_fragilitycurves_methode2_table\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\n\n\ninput_ci_postgresql_fragilitycurves_overtopping\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op overtopping.\n\n\ninput_ci_postgresql_fragilitycurves_piping\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\ninput_ci_postgresql_fragilitycurves_stability\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\ninput_ci_postgresql_fragilitycurves_table\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\n\n\ninput_ci_postgresql_measure_fragilitycurves_table\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en maatregelen\n\n\ninput_ci_postgresql_probablistic_piping\nLeest probablistic data van PostgreSQL-database in de probablistic piping tabel en hernoemt de kolomen.\n\n\ninput_ci_postgresql_profiles\nLeest profieldata van PostgreSQL-database in de profieltabel en zet namen goed.\n\n\ninput_ci_postgresql_slopes\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed.\n\n\ninput_ci_postgresql_slopes_limburg\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed.\n\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_bedlevelfetch(\n    input_config\n)\nLeest bedlevelfetch data van PostgreSQL-database in de bedlevelfetch tabel en zet namen goed.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_methode2_table(\n    input_config\n)\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\nYAML voorbeeld:\ntype: ci_postgresql_fragilitycurves_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nmeasureid: 0\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht database\nschema (str): schema van de Continu Inzicht database\nmeasureid (int64, optioneel): maatregel id, bij geen waarde wordt geen maatregel (measureid=0) gebruikt\ntimedep (int64, optioneel): tijdsafhankelijk 0=nee, 1=ja\ndegradatieid (int64, optioneel): rekening houden met degradatie (nog net ge�mplementeerd)\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nmeasure_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nfailuremechanismid: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nhydraulicload: float64 : belasting van het tijdreeksitem\nfailureprobability: float64 : faalkans van het tijdreeksitem\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_overtopping(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op overtopping.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_piping(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_stability(\n    input_config\n)\nLeest fragility curves data van PostgreSQL-database in, zet namen goed en filtert op piping.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_fragilitycurves_table(\n    input_config\n)\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en opgegeven maatregel\nYAML voorbeeld:\ntype: ci_postgresql_fragilitycurves_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nmeasureid: 0\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht database\nschema (str): schema van de Continu Inzicht database\nmeasureid (int64, optioneel): maatregel id, bij geen waarde wordt geen maatregel (measureid=0) gebruikt\ntimedep (int64, optioneel): tijdsafhankelijk 0=nee, 1=ja\ndegradatieid (int64, optioneel): rekening houden met degradatie (nog net ge�mplementeerd)\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nmeasure_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nfailuremechanismid: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nhydraulicload: float64 : belasting van het tijdreeksitem\nfailureprobability: float64 : faalkans van het tijdreeksitem\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_measure_fragilitycurves_table(\n    input_config\n)\nOphalen fragilitycurves voor alle dijkvakken, faalmechanismes en maatregelen\nYaml example:\ntype: ci_postgresql_measure_fragilitycurves_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht database\nschema (str): schema van de Continu Inzicht database\ntimedep (int64, optioneel): tijdsafhankelijk 0=nee, 1=ja\ndegradatieid (int64, optioneel): rekening houden met degradatie (nog net ge�mplementeerd)\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nmeasure_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nfailuremechanismid: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nhydraulicload: float64 : belasting van het tijdreeksitem\nfailureprobability: float64 : faalkans van het tijdreeksitem\nsuccessrate: float64 : kans op succes van de maatregel\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_probablistic_piping(\n    input_config\n)\nLeest probablistic data van PostgreSQL-database in de probablistic piping tabel en hernoemt de kolomen.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_profiles(\n    input_config\n)\nLeest profieldata van PostgreSQL-database in de profieltabel en zet namen goed.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_slopes(\n    input_config\n)\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed.\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_fragilitycurve.input_ci_postgresql_slopes_limburg(\n    input_config\n)\nleest hellingsdata van PostgreSQL-database in de hellingstabel en zet namen goed."
  },
  {
    "objectID": "reference/input_section.html",
    "href": "reference/input_section.html",
    "title": "input_section",
    "section": "",
    "text": "base.adapters.input.continu_inzicht_postgresql.input_section\nDataAdapters voor het lezen van data uit de Continu Inzicht database\n\n\n\n\n\nName\nDescription\n\n\n\n\ninput_ci_postgresql_from_sectionfractions\nHaalt sectiefracties uit een continu database.\n\n\ninput_ci_postgresql_from_sections\nHaalt sectie data op uit de Continu Inzicht database.\n\n\ninput_ci_postgresql_section_expert_judgement_table\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\n\n\ninput_ci_postgresql_section_failure_probability_from_data_table\nHaalt faalkansen per dijkvak per moment op\n\n\ninput_ci_postgresql_section_load_from_data_table\nHaalt tijdreeks van belasting per dijkvak op\n\n\ninput_ci_postgresql_section_thresholds_from_conditions_table\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\n\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_from_sectionfractions(\n    input_config\n)\nHaalt sectiefracties uit een continu database.\nYAML voorbeeld:\ntype: ci_postgresql_from_sectionfractions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nid: int64 : id van het dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedestrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_from_sections(\n    input_config\n)\nHaalt sectie data op uit de Continu Inzicht database.\nYAML voorbeeld:\ntype: ci_postgresql_from_sections\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nid: int64 : id van het dijkvak\nname: str : naam van het dijkvak\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_expert_judgement_table(\n    input_config\n)\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\nYAML voorbeeld:\ntype: ci_postgresql_section_thresholds_from_conditions_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nstate_id: int64 : id van de klassegrens\nlower_boundary: float64 : ondergrens van de klassegrens\nupper_boundary: float64 : bovengrens van de klassegrens\ncolor: str : kleur van de klassegrens\nlabel: str : legendanaam van de klassegrens\nunit: str : unit van de klassegrens\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_failure_probability_from_data_table(\n    input_config\n)\nHaalt faalkansen per dijkvak per moment op\nYAML voorbeeld:\ntype: ci_postgresql_section_failure_probability_from_data_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nfailureprobability_id: in64 : id van de dijkvak/faalmechanisme/maatregel-combinatie\nsection_id: int64 : id van het dijkvak\nvalue_parameter_id: int64 : id van de belastingparameter (1/2/3/4)\nfailuremechanism_id: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nmeasures_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nparameter_id: int64 : id van de faalkansparameter (5/100/101/102)\nunit: int64 : unit van de belasting\ndate_time: datetime64 : datum/ tijd van het tijdreeksitem\nvalue: float : waarde van het tijdreeksitem\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_load_from_data_table(\n    input_config\n)\nHaalt tijdreeks van belasting per dijkvak op\nYAML voorbeeld:\ntype: ci_postgresql_section_load_from_data_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nparameter_id: int64 : id van de parameter\nunit: str : unit van de parameter\ndate_time: datetime64 : datum/ tijd van het tijdreeksitem\nvalue: float64 : waarde van het tijdreeksitem\nvalue_type: str : type waarde van het tijdreeksitem (meting of verwacht)\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_thresholds_from_conditions_table(\n    input_config\n)\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\nYAML voorbeeld:\ntype: ci_postgresql_section_thresholds_from_conditions_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nstate_id: int64 : id van de klassegrens\nlower_boundary: float64 : ondergrens van de klassegrens\nupper_boundary: float64 : bovengrens van de klassegrens\ncolor: str : kleur van de klassegrens\nlabel: str : legendanaam van de klassegrens\nunit: str : unit van de klassegrens"
  },
  {
    "objectID": "reference/input_section.html#functions",
    "href": "reference/input_section.html#functions",
    "title": "input_section",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninput_ci_postgresql_from_sectionfractions\nHaalt sectiefracties uit een continu database.\n\n\ninput_ci_postgresql_from_sections\nHaalt sectie data op uit de Continu Inzicht database.\n\n\ninput_ci_postgresql_section_expert_judgement_table\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\n\n\ninput_ci_postgresql_section_failure_probability_from_data_table\nHaalt faalkansen per dijkvak per moment op\n\n\ninput_ci_postgresql_section_load_from_data_table\nHaalt tijdreeks van belasting per dijkvak op\n\n\ninput_ci_postgresql_section_thresholds_from_conditions_table\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\n\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_from_sectionfractions(\n    input_config\n)\nHaalt sectiefracties uit een continu database.\nYAML voorbeeld:\ntype: ci_postgresql_from_sectionfractions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nid: int64 : id van het dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedestrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_from_sections(\n    input_config\n)\nHaalt sectie data op uit de Continu Inzicht database.\nYAML voorbeeld:\ntype: ci_postgresql_from_sections\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nid: int64 : id van het dijkvak\nname: str : naam van het dijkvak\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_expert_judgement_table(\n    input_config\n)\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\nYAML voorbeeld:\ntype: ci_postgresql_section_thresholds_from_conditions_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nstate_id: int64 : id van de klassegrens\nlower_boundary: float64 : ondergrens van de klassegrens\nupper_boundary: float64 : bovengrens van de klassegrens\ncolor: str : kleur van de klassegrens\nlabel: str : legendanaam van de klassegrens\nunit: str : unit van de klassegrens\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_failure_probability_from_data_table(\n    input_config\n)\nHaalt faalkansen per dijkvak per moment op\nYAML voorbeeld:\ntype: ci_postgresql_section_failure_probability_from_data_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nfailureprobability_id: in64 : id van de dijkvak/faalmechanisme/maatregel-combinatie\nsection_id: int64 : id van het dijkvak\nvalue_parameter_id: int64 : id van de belastingparameter (1/2/3/4)\nfailuremechanism_id: int64 : id van het faalmechanisme\nfailuremechanism: str : naam van het faalmechanisme\nmeasures_id: int64 : id van de maatregel\nmeasure: str : naam van de maatregel\nparameter_id: int64 : id van de faalkansparameter (5/100/101/102)\nunit: int64 : unit van de belasting\ndate_time: datetime64 : datum/ tijd van het tijdreeksitem\nvalue: float : waarde van het tijdreeksitem\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_load_from_data_table(\n    input_config\n)\nHaalt tijdreeks van belasting per dijkvak op\nYAML voorbeeld:\ntype: ci_postgresql_section_load_from_data_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nsection_id: int64 : id van het dijkvak\nparameter_id: int64 : id van de parameter\nunit: str : unit van de parameter\ndate_time: datetime64 : datum/ tijd van het tijdreeksitem\nvalue: float64 : waarde van het tijdreeksitem\nvalue_type: str : type waarde van het tijdreeksitem (meting of verwacht)\n\n\n\n\nbase.adapters.input.continu_inzicht_postgresql.input_section.input_ci_postgresql_section_thresholds_from_conditions_table(\n    input_config\n)\nHaalt klassegrenzen (faalkans) van een dijkvak op uit de continu database.\nYAML voorbeeld:\ntype: ci_postgresql_section_thresholds_from_conditions_table\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\ninput_config (dict): configuratie-opties\nOpmerking:\nIn het .env-bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’-config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\nReturns:\ndf (DataFrame):\n\nstate_id: int64 : id van de klassegrens\nlower_boundary: float64 : ondergrens van de klassegrens\nupper_boundary: float64 : bovengrens van de klassegrens\ncolor: str : kleur van de klassegrens\nlabel: str : legendanaam van de klassegrens\nunit: str : unit van de klassegrens"
  },
  {
    "objectID": "reference/IntegrateFragilityCurve.html",
    "href": "reference/IntegrateFragilityCurve.html",
    "title": "IntegrateFragilityCurve",
    "section": "",
    "text": "fragility_curves.IntegrateFragilityCurve()\nIntegreert een waterniveau overschrijdingsfrequentielijn met een fragility curve\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_exceedance_frequency\nOptional[pd.DataFrame] | None\nDataFrame containing exceedance frequency data.\n\n\ndf_fragility_curve\nOptional[pd.DataFrame] | None\nDataFrame containing fragility curve data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the integrated fragility curve.\n\n\ninterp_func\nCallable\nFunctie waarmee ge�nterpoleerd wordt\n\n\n\n\n\n\nBij het combineren van de fragility curves met overschrijdingsfrequentielijn moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen worden ingesteld:\n\nrefine_step_size: De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05.\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncalculate_integration\n\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurve.calculate_integration(\n    exceedance_frequency_curve\n    fragility_curve\n    refine_step_size\n)\n\n\n\nfragility_curves.IntegrateFragilityCurve.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurve.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.IntegrateFragilityCurve.run(input, output)\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van data adapters met exceedance_frequency en fragility_curve\nrequired\n\n\noutput\nstr\nData adapter voor de output\nrequired\n\n\n\n\n\n\nexceedance_frequency bevat een hydraulische belasting met overschrijdingsfrequentie statistiek, beide floats:\n\nhydraulicload, hydralische belastingen\nprobability_exceedance, reek van overschrijdingsfrequenties\n\nfragility_curve bevat een hydraulische belasting met conditionele faalkansen, beide floats:\n\nhydraulicload, hydralische belastingen\nfailure_probabilities, conditionele faalkansen"
  },
  {
    "objectID": "reference/IntegrateFragilityCurve.html#attributes",
    "href": "reference/IntegrateFragilityCurve.html#attributes",
    "title": "IntegrateFragilityCurve",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nAdapter for handling data input and output operations.\n\n\ndf_exceedance_frequency\nOptional[pd.DataFrame] | None\nDataFrame containing exceedance frequency data.\n\n\ndf_fragility_curve\nOptional[pd.DataFrame] | None\nDataFrame containing fragility curve data.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nOutput DataFrame containing the integrated fragility curve.\n\n\ninterp_func\nCallable\nFunctie waarmee ge�nterpoleerd wordt"
  },
  {
    "objectID": "reference/IntegrateFragilityCurve.html#notes",
    "href": "reference/IntegrateFragilityCurve.html#notes",
    "title": "IntegrateFragilityCurve",
    "section": "",
    "text": "Bij het combineren van de fragility curves met overschrijdingsfrequentielijn moeten de waterstanden van de curves op elkaar afgestemd worden. Dit gebeurt door de waterstanden van de curves te interpoleren naar een nieuwe set waterstanden. De volgende opties kunnen worden ingesteld:\n\nrefine_step_size: De stapgrootte van de waterstanden die gebruikt wordt bij het herschalen van de kansen voor het combineren. Default is 0.05."
  },
  {
    "objectID": "reference/IntegrateFragilityCurve.html#methods",
    "href": "reference/IntegrateFragilityCurve.html#methods",
    "title": "IntegrateFragilityCurve",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncalculate_integration\n\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurve.calculate_integration(\n    exceedance_frequency_curve\n    fragility_curve\n    refine_step_size\n)\n\n\n\nfragility_curves.IntegrateFragilityCurve.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.IntegrateFragilityCurve.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.IntegrateFragilityCurve.run(input, output)\nRunt de integratie van een waterniveau overschrijdingsfrequentielijn met een fragility curve\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst van data adapters met exceedance_frequency en fragility_curve\nrequired\n\n\noutput\nstr\nData adapter voor de output\nrequired\n\n\n\n\n\n\nexceedance_frequency bevat een hydraulische belasting met overschrijdingsfrequentie statistiek, beide floats:\n\nhydraulicload, hydralische belastingen\nprobability_exceedance, reek van overschrijdingsfrequenties\n\nfragility_curve bevat een hydraulische belasting met conditionele faalkansen, beide floats:\n\nhydraulicload, hydralische belastingen\nfailure_probabilities, conditionele faalkansen"
  },
  {
    "objectID": "reference/LoadsCIWhatIf.html",
    "href": "reference/LoadsCIWhatIf.html",
    "title": "LoadsCIWhatIf",
    "section": "",
    "text": "loads.LoadsCIWhatIf()\nMet deze functie worden belasting opgehaald en weggeschreven.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_in\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Loads Classify.\n\n\n\n\n\nloads.LoadsCIWhatIf.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsCIWhatIf.run(input, output)\nDe runner van de Loads Classify.\nArgs: input (str):\noutput (str):\nReturns: Dataframe: Pandas dataframe met …"
  },
  {
    "objectID": "reference/LoadsCIWhatIf.html#attributes",
    "href": "reference/LoadsCIWhatIf.html#attributes",
    "title": "LoadsCIWhatIf",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_in\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton."
  },
  {
    "objectID": "reference/LoadsCIWhatIf.html#methods",
    "href": "reference/LoadsCIWhatIf.html#methods",
    "title": "LoadsCIWhatIf",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Loads Classify.\n\n\n\n\n\nloads.LoadsCIWhatIf.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsCIWhatIf.run(input, output)\nDe runner van de Loads Classify.\nArgs: input (str):\noutput (str):\nReturns: Dataframe: Pandas dataframe met …"
  },
  {
    "objectID": "reference/LoadsFews.html",
    "href": "reference/LoadsFews.html",
    "title": "LoadsFews",
    "section": "",
    "text": "loads.LoadsFews()\nMet deze functie worden gegevens uit de opgegeven FEWS omgeving opgehaald via REST.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_in\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton.\n\n\ninput_schema\ndict() -&gt; new empty dictionary\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_dataframe\nMaak een pandas dataframe\n\n\ncreate_params\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\ncreate_url\nMaak een REST-URL voor FEWS\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Loads FEWS.\n\n\n\n\n\nloads.LoadsFews.create_dataframe(\n    options\n    calc_time\n    json_data\n    locations\n    global_variables\n)\nMaak een pandas dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOpties uit de invoer yaml\nrequired\n\n\ncalc_time\ndatetime\nT0 in UTC\nrequired\n\n\njson_data\nstr\nJSON data van FEWS\nrequired\n\n\nlocations\npd.DataFrame\nDataframe met meetlocaties\nrequired\n\n\nglobal_variables\ndict\nGlobale variabelen uit de invoer yaml\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nDataFrame\npandas.core.Dataframe\nMet daar in: - Meetlocatie id (measurement_location_id) - Meetlocatie code (measurement_location_code) - Meetlocatie omschrijving/naam (measurement_location_description) - Parameter id overeenkomstig Aquo-standaard: ‘4724’ (parameter_id) - Parameter code overeenkomstig Aquo-standaard: ‘WATHTE’ (parameter_code) - Parameter omschrijving overeenkomstig Aquo-standaard: ‘Waterhoogte’ (parameter_description) - Eenheid (unit) - Datum en tijd (date_time) - Waarde (value) - Type waarde: meting of verwachting (value_type)\n\n\n\n\n\n\n\nloads.LoadsFews.create_params(calc_time, options, moments, locations)\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncalc_time\ndatetime\nT0 in UTC\nrequired\n\n\noptions\ndict\noptions uit de invoer yaml\nrequired\n\n\nmoments\nlist\nLijst van momenten in uren\nrequired\n\n\nlocations\npd.DataFrame\nDataframe met meetlocaties\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlijst met parameters: dict\nDe parameters die meegegeven moeten worden aan de FEWS API\n\n\n\n\n\n\n\nloads.LoadsFews.create_url(options)\nMaak een REST-URL voor FEWS\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOptions uit de invoer yaml\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nURL\nstr\nDe URL voor de FEWS REST API\n\n\n\n\n\n\n\nloads.LoadsFews.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsFews.run(input, output)\nDe runner van de Loads FEWS.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nDe naam van de input data met meetlocaties bekend in FEWS\nrequired\n\n\noutput\nstr\nDe naam van de output data met resultaten uit FEWS\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de LoadsFews niet in de globale variabelen staat"
  },
  {
    "objectID": "reference/LoadsFews.html#attributes",
    "href": "reference/LoadsFews.html#attributes",
    "title": "LoadsFews",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_in\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton.\n\n\ninput_schema\ndict() -&gt; new empty dictionary"
  },
  {
    "objectID": "reference/LoadsFews.html#methods",
    "href": "reference/LoadsFews.html#methods",
    "title": "LoadsFews",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_dataframe\nMaak een pandas dataframe\n\n\ncreate_params\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\ncreate_url\nMaak een REST-URL voor FEWS\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Loads FEWS.\n\n\n\n\n\nloads.LoadsFews.create_dataframe(\n    options\n    calc_time\n    json_data\n    locations\n    global_variables\n)\nMaak een pandas dataframe\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOpties uit de invoer yaml\nrequired\n\n\ncalc_time\ndatetime\nT0 in UTC\nrequired\n\n\njson_data\nstr\nJSON data van FEWS\nrequired\n\n\nlocations\npd.DataFrame\nDataframe met meetlocaties\nrequired\n\n\nglobal_variables\ndict\nGlobale variabelen uit de invoer yaml\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nDataFrame\npandas.core.Dataframe\nMet daar in: - Meetlocatie id (measurement_location_id) - Meetlocatie code (measurement_location_code) - Meetlocatie omschrijving/naam (measurement_location_description) - Parameter id overeenkomstig Aquo-standaard: ‘4724’ (parameter_id) - Parameter code overeenkomstig Aquo-standaard: ‘WATHTE’ (parameter_code) - Parameter omschrijving overeenkomstig Aquo-standaard: ‘Waterhoogte’ (parameter_description) - Eenheid (unit) - Datum en tijd (date_time) - Waarde (value) - Type waarde: meting of verwachting (value_type)\n\n\n\n\n\n\n\nloads.LoadsFews.create_params(calc_time, options, moments, locations)\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncalc_time\ndatetime\nT0 in UTC\nrequired\n\n\noptions\ndict\noptions uit de invoer yaml\nrequired\n\n\nmoments\nlist\nLijst van momenten in uren\nrequired\n\n\nlocations\npd.DataFrame\nDataframe met meetlocaties\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlijst met parameters: dict\nDe parameters die meegegeven moeten worden aan de FEWS API\n\n\n\n\n\n\n\nloads.LoadsFews.create_url(options)\nMaak een REST-URL voor FEWS\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nOptions uit de invoer yaml\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nURL\nstr\nDe URL voor de FEWS REST API\n\n\n\n\n\n\n\nloads.LoadsFews.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsFews.run(input, output)\nDe runner van de Loads FEWS.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nDe naam van de input data met meetlocaties bekend in FEWS\nrequired\n\n\noutput\nstr\nDe naam van de output data met resultaten uit FEWS\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de LoadsFews niet in de globale variabelen staat"
  },
  {
    "objectID": "reference/LoadsToMoments.html",
    "href": "reference/LoadsToMoments.html",
    "title": "LoadsToMoments",
    "section": "",
    "text": "loads.LoadsToMoments()\nMet deze klasse kunnen waterstandsgegevens worden omgezet naar bepaalde momenten. Deze klasse bevat een methode genaamd ‘run’ die de waterstandsgegevens verwerkt en de resulterende momenten opslaat in een dataframe.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nEen object van de klasse DataAdapter.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nHet invoerdataframe met waterstandsgegevens. Standaard is dit None.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nHet uitvoerdataframe met de resulterende momenten. Standaard is dit None.\n\n\ninput_schema_loads\nClassVar[dict[str, str | list[str]]]\nHet schema van het invoerdataframe met waterstandsgegevens.\n\n\n\n\n\n\nHet schema van het invoerdataframe is:\n\nmeasurement_location_id: int64\nparameter_id: int64\nunit: object\ndate_time: datetime64[ns, UTC] of object\nvalue: float64\nvalue_type: object\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nget_moment_from_dataframe\nHaalt het moment op uit een dataframe van momenten.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nVerwerkt de invoergegevens om momenten te berekenen en genereert het uitvoerdataframe.\n\n\n\n\n\nloads.LoadsToMoments.get_moment_from_dataframe(moment, df_moments)\nHaalt het moment op uit een dataframe van momenten.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmoment\ndict\nHet moment dat moet worden opgehaald.\nrequired\n\n\ndf_moments\npd.DataFrame\nHet dataframe van momenten.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nHet dataframe met het opgehaalde moment: pd.DataFrame\n\n\n\n\n\n\n\n\nloads.LoadsToMoments.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsToMoments.run(input, output)\nVerwerkt de invoergegevens om momenten te berekenen en genereert het uitvoerdataframe.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de dataadapter met invoergegevens.\nrequired\n\n\noutput\nstr\nNaam van de dataadapter om uitvoergegevens op te slaan.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAssertionError\nAls de invoergegevens niet voldoen aan de vereiste schema’s."
  },
  {
    "objectID": "reference/LoadsToMoments.html#attributes",
    "href": "reference/LoadsToMoments.html#attributes",
    "title": "LoadsToMoments",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nEen object van de klasse DataAdapter.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nHet invoerdataframe met waterstandsgegevens. Standaard is dit None.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nHet uitvoerdataframe met de resulterende momenten. Standaard is dit None.\n\n\ninput_schema_loads\nClassVar[dict[str, str | list[str]]]\nHet schema van het invoerdataframe met waterstandsgegevens."
  },
  {
    "objectID": "reference/LoadsToMoments.html#notes",
    "href": "reference/LoadsToMoments.html#notes",
    "title": "LoadsToMoments",
    "section": "",
    "text": "Het schema van het invoerdataframe is:\n\nmeasurement_location_id: int64\nparameter_id: int64\nunit: object\ndate_time: datetime64[ns, UTC] of object\nvalue: float64\nvalue_type: object"
  },
  {
    "objectID": "reference/LoadsToMoments.html#methods",
    "href": "reference/LoadsToMoments.html#methods",
    "title": "LoadsToMoments",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nget_moment_from_dataframe\nHaalt het moment op uit een dataframe van momenten.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nVerwerkt de invoergegevens om momenten te berekenen en genereert het uitvoerdataframe.\n\n\n\n\n\nloads.LoadsToMoments.get_moment_from_dataframe(moment, df_moments)\nHaalt het moment op uit een dataframe van momenten.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmoment\ndict\nHet moment dat moet worden opgehaald.\nrequired\n\n\ndf_moments\npd.DataFrame\nHet dataframe van momenten.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nHet dataframe met het opgehaalde moment: pd.DataFrame\n\n\n\n\n\n\n\n\nloads.LoadsToMoments.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsToMoments.run(input, output)\nVerwerkt de invoergegevens om momenten te berekenen en genereert het uitvoerdataframe.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nNaam van de dataadapter met invoergegevens.\nrequired\n\n\noutput\nstr\nNaam van de dataadapter om uitvoergegevens op te slaan.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nAssertionError\nAls de invoergegevens niet voldoen aan de vereiste schema’s."
  },
  {
    "objectID": "reference/LoadsWaterwebservicesRWS.html",
    "href": "reference/LoadsWaterwebservicesRWS.html",
    "title": "LoadsWaterwebservicesRWS",
    "section": "",
    "text": "loads.LoadsWaterwebservicesRWS()\nBelastinggegevens ophalen van rijkswaterstaat waterwebservices\n\n\nLink: https://waterwebservices.rijkswaterstaat.nl/\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter voor het ophalen en opslaan van gegevens.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nHet invoerdataframe.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nHet uitvoerdataframe.\n\n\nurl_retrieve_observations\nstr\nDe url voor het ophalen van waarnemingen.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ncreate_dataframe\nMaakt een dataframe met waardes van de rws water webservices\n\n\ncreate_json_list\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Belasting WaterwebservicesRWS.\n\n\n\n\n\nloads.LoadsWaterwebservicesRWS.create_dataframe(\n    options\n    calc_time\n    lst_data\n    df_in\n    global_variables\n)\nMaakt een dataframe met waardes van de rws water webservices\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nEen dictionary met opties uit de config\nrequired\n\n\ncalc_time\ndatetime\nDe huidige tijd\nrequired\n\n\nlst_data\nlist\nEen lijst met JSON data uit de post request\nrequired\n\n\ndf_in\npd.DataFrame\nHet invoerdataframe\nrequired\n\n\nglobal_variables\ndict\nDe globale variabelen uit de config\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndataframe\npd.Dataframe\nPandas dataframe geschikt voor uitvoer\n\n\n\n\n\n\n\nloads.LoadsWaterwebservicesRWS.create_json_list(\n    measurement\n    calc_time\n    global_variables\n    locations\n)\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmeasurement\nstr\nDe naam van de parameter die je wilt ophalen.\nrequired\n\n\ncalc_time\ndatetime\nDe huidige tijd in UTC.\nrequired\n\n\nglobal_variables\ndict\nDe globale variabelen uit de invoer yaml.\nrequired\n\n\nlocations\npd.DataFrame\nDataframe met de gewenste locaties.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlist\nLijst met parameters.\n\n\n\n\n\n\n\nloads.LoadsWaterwebservicesRWS.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsWaterwebservicesRWS.run(input, output)\nDe runner van de Belasting WaterwebservicesRWS.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nDe naam van de invoerdataadapter.\nrequired\n\n\noutput\nstr\nDe naam van de uitvoerdataadapter.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nWanneer de inputdata niet de kolom ‘measurement_location_id’ bevat. Wanneer de inputdata geen ‘measurement_location_code’ bevat. Wanneer de ‘measurement_location_code’ geen getal is. Wanneer de ‘LoadsWaterwebservicesRWS’ sectie niet aanwezig is in global_variables (config)."
  },
  {
    "objectID": "reference/LoadsWaterwebservicesRWS.html#notes",
    "href": "reference/LoadsWaterwebservicesRWS.html#notes",
    "title": "LoadsWaterwebservicesRWS",
    "section": "",
    "text": "Link: https://waterwebservices.rijkswaterstaat.nl/"
  },
  {
    "objectID": "reference/LoadsWaterwebservicesRWS.html#attributes",
    "href": "reference/LoadsWaterwebservicesRWS.html#attributes",
    "title": "LoadsWaterwebservicesRWS",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter voor het ophalen en opslaan van gegevens.\n\n\ndf_in\nOptional[pd.DataFrame] | None\nHet invoerdataframe.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nHet uitvoerdataframe.\n\n\nurl_retrieve_observations\nstr\nDe url voor het ophalen van waarnemingen."
  },
  {
    "objectID": "reference/LoadsWaterwebservicesRWS.html#methods",
    "href": "reference/LoadsWaterwebservicesRWS.html#methods",
    "title": "LoadsWaterwebservicesRWS",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ncreate_dataframe\nMaakt een dataframe met waardes van de rws water webservices\n\n\ncreate_json_list\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nDe runner van de Belasting WaterwebservicesRWS.\n\n\n\n\n\nloads.LoadsWaterwebservicesRWS.create_dataframe(\n    options\n    calc_time\n    lst_data\n    df_in\n    global_variables\n)\nMaakt een dataframe met waardes van de rws water webservices\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\noptions\ndict\nEen dictionary met opties uit de config\nrequired\n\n\ncalc_time\ndatetime\nDe huidige tijd\nrequired\n\n\nlst_data\nlist\nEen lijst met JSON data uit de post request\nrequired\n\n\ndf_in\npd.DataFrame\nHet invoerdataframe\nrequired\n\n\nglobal_variables\ndict\nDe globale variabelen uit de config\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndataframe\npd.Dataframe\nPandas dataframe geschikt voor uitvoer\n\n\n\n\n\n\n\nloads.LoadsWaterwebservicesRWS.create_json_list(\n    measurement\n    calc_time\n    global_variables\n    locations\n)\nMaak een lijst van FEWS parameters om mee te sturen bij het ophalen van data.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nmeasurement\nstr\nDe naam van de parameter die je wilt ophalen.\nrequired\n\n\ncalc_time\ndatetime\nDe huidige tijd in UTC.\nrequired\n\n\nglobal_variables\ndict\nDe globale variabelen uit de invoer yaml.\nrequired\n\n\nlocations\npd.DataFrame\nDataframe met de gewenste locaties.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlist\nLijst met parameters.\n\n\n\n\n\n\n\nloads.LoadsWaterwebservicesRWS.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nloads.LoadsWaterwebservicesRWS.run(input, output)\nDe runner van de Belasting WaterwebservicesRWS.\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nstr\nDe naam van de invoerdataadapter.\nrequired\n\n\noutput\nstr\nDe naam van de uitvoerdataadapter.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nWanneer de inputdata niet de kolom ‘measurement_location_id’ bevat. Wanneer de inputdata geen ‘measurement_location_code’ bevat. Wanneer de ‘measurement_location_code’ geen getal is. Wanneer de ‘LoadsWaterwebservicesRWS’ sectie niet aanwezig is in global_variables (config)."
  },
  {
    "objectID": "reference/output_measuringstation.html",
    "href": "reference/output_measuringstation.html",
    "title": "output_measuringstation",
    "section": "",
    "text": "base.adapters.output.continu_inzicht_postgresql.output_measuringstation\nData adapters voor het schrijven naar de Continu Inzicht database\n\n\n\n\n\nName\nDescription\n\n\n\n\noutput_ci_postgresql_conditions\nSchrijft voor condities van belastingen voor meetstations naar de Continu Inzicht database (tabel: conditions).\n\n\noutput_ci_postgresql_measuringstation\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\n\n\noutput_ci_postgresql_measuringstation_to_data\nSchrijft voor meetstations de belasting data naar de Continu Inzicht database (tabel: data).\n\n\noutput_ci_postgresql_to_moments\nSchrijft moments naar Continu Inzicht database (tabel: moments)\n\n\noutput_ci_postgresql_to_states\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\n\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_conditions(\n    output_config\n    df\n)\nSchrijft voor condities van belastingen voor meetstations naar de Continu Inzicht database (tabel: conditions).\nYaml example:\ntype: ci_postgresql_conditions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties df (DataFrame):\n\nid: int64 : id van de conditie\nstateid: int64 : id van de status van een conditie\nobjectid: int64 : id van het object waartoe de conditie behoort (altijd in combinatie met objecttype)\nobjecttype: str : het type object waartoe de conditie behoort (bijv. een ‘section’ of ‘measuringstation’)\nupperboundary: float64 : de bovengrenswaarde van de status van een conditie (overgang van de betreffende status naar de volgende status)\nname: str : naam van de status van de conditie\ndescription: str : omschrijving van de status van de conditie\ncolor: str : HEX kleurcode van de kleur van de status van de conditie\nstatevalue: float64 : middenwaarde van statusovergangen (specifiek voor objecttype ‘sections’)\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_measuringstation(\n    output_config\n    df\n)\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\nYaml example:\ntype: ci_postgresql_measuringstation\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- id: int64                 : id van het meetstation\n- name: str                 : naam van het meetstation\n- code: str                 : code van het meetstation\n- source: str               : bron van de data van het meetstation\n- geometry: geom            : geometrie (ligging) van het meetstation (let op projectie!)\n- tide: bool                : meetstation bevat belasting waar een getijperiode een tol speelt (default false)\n- area_geometry: geom       : OPTIONEEL geometrie van het gebied waarbinnen de belasting wordt bepaald (bijv. een gemiddelde waarde)\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_measuringstation_to_data(\n    output_config\n    df\n)\nSchrijft voor meetstations de belasting data naar de Continu Inzicht database (tabel: data).\nYaml example:\ntype: ci_postgresql_measuringstation_to_data\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nunit_conversion_factor: 0.01\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- measurement_location_id: int64\n- date_time: datetime64[ns, UTC]\n- value: float64\n- value_type: str\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\nunit_conversion_factor (optioneel, float): conversiefactor om waarde om te zetten naar meters\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_to_moments(\n    output_config\n    df\n)\nSchrijft moments naar Continu Inzicht database (tabel: moments)\nYaml example:\ntype: ci_postgresql_to_moments\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties\ndf (DataFrame):\n\ndate_time: int64 : datum/tijd van het huidige moment\ncalc_time: int64 : datum/tijd van eerst volgende rekenstap\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_to_states(\n    output_config\n    df\n)\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\nYaml example:\ntype: ci_postgresql_to_states\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- measurement_location_id: int64\n- date_time: datetime64[ns, UTC]\n- hours: int64\n- upper_boundary: int64\n- value: float64\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht"
  },
  {
    "objectID": "reference/output_measuringstation.html#functions",
    "href": "reference/output_measuringstation.html#functions",
    "title": "output_measuringstation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\noutput_ci_postgresql_conditions\nSchrijft voor condities van belastingen voor meetstations naar de Continu Inzicht database (tabel: conditions).\n\n\noutput_ci_postgresql_measuringstation\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\n\n\noutput_ci_postgresql_measuringstation_to_data\nSchrijft voor meetstations de belasting data naar de Continu Inzicht database (tabel: data).\n\n\noutput_ci_postgresql_to_moments\nSchrijft moments naar Continu Inzicht database (tabel: moments)\n\n\noutput_ci_postgresql_to_states\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\n\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_conditions(\n    output_config\n    df\n)\nSchrijft voor condities van belastingen voor meetstations naar de Continu Inzicht database (tabel: conditions).\nYaml example:\ntype: ci_postgresql_conditions\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties df (DataFrame):\n\nid: int64 : id van de conditie\nstateid: int64 : id van de status van een conditie\nobjectid: int64 : id van het object waartoe de conditie behoort (altijd in combinatie met objecttype)\nobjecttype: str : het type object waartoe de conditie behoort (bijv. een ‘section’ of ‘measuringstation’)\nupperboundary: float64 : de bovengrenswaarde van de status van een conditie (overgang van de betreffende status naar de volgende status)\nname: str : naam van de status van de conditie\ndescription: str : omschrijving van de status van de conditie\ncolor: str : HEX kleurcode van de kleur van de status van de conditie\nstatevalue: float64 : middenwaarde van statusovergangen (specifiek voor objecttype ‘sections’)\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_measuringstation(\n    output_config\n    df\n)\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\nYaml example:\ntype: ci_postgresql_measuringstation\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- id: int64                 : id van het meetstation\n- name: str                 : naam van het meetstation\n- code: str                 : code van het meetstation\n- source: str               : bron van de data van het meetstation\n- geometry: geom            : geometrie (ligging) van het meetstation (let op projectie!)\n- tide: bool                : meetstation bevat belasting waar een getijperiode een tol speelt (default false)\n- area_geometry: geom       : OPTIONEEL geometrie van het gebied waarbinnen de belasting wordt bepaald (bijv. een gemiddelde waarde)\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_measuringstation_to_data(\n    output_config\n    df\n)\nSchrijft voor meetstations de belasting data naar de Continu Inzicht database (tabel: data).\nYaml example:\ntype: ci_postgresql_measuringstation_to_data\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nunit_conversion_factor: 0.01\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- measurement_location_id: int64\n- date_time: datetime64[ns, UTC]\n- value: float64\n- value_type: str\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\nunit_conversion_factor (optioneel, float): conversiefactor om waarde om te zetten naar meters\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_to_moments(\n    output_config\n    df\n)\nSchrijft moments naar Continu Inzicht database (tabel: moments)\nYaml example:\ntype: ci_postgresql_to_moments\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_whatif\"\nArgs:\noutput_config (dict): configuratie opties\ndf (DataFrame):\n\ndate_time: int64 : datum/tijd van het huidige moment\ncalc_time: int64 : datum/tijd van eerst volgende rekenstap\n\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht\n\n\n\n\nbase.adapters.output.continu_inzicht_postgresql.output_measuringstation.output_ci_postgresql_to_states(\n    output_config\n    df\n)\nSchrijft voor meetstations de classificatie data naar de Continu Inzicht database (tabel: states).\nYaml example:\ntype: ci_postgresql_to_states\ndatabase: \"continuinzicht\"\nschema: \"continuinzicht_demo_realtime\"\nArgs:\n* output_config (dict): configuratie opties\n* df (DataFrame):\n\n- measurement_location_id: int64\n- date_time: datetime64[ns, UTC]\n- hours: int64\n- upper_boundary: int64\n- value: float64\nOpmerking:\nIn de .env environment bestand moeten de volgende parameters staan:\n\npostgresql_user (str): inlog gebruikersnaam van de Continu Inzicht database\npostgresql_password (str): inlog wachtwoord van de Continu Inzicht database\npostgresql_host (str): servernaam/ ip adres van de Continu Inzicht databaseserver\npostgresql_port (str): poort van de Continu Inzicht databaseserver\n\nIn de ‘yaml’ config moeten de volgende parameters staan:\n\ndatabase (str): database van de Continu Inzicht\nschema (str): schema van de Continu Inzicht"
  },
  {
    "objectID": "reference/proof_of_concept.example_module.html",
    "href": "reference/proof_of_concept.example_module.html",
    "title": "proof_of_concept.example_module",
    "section": "",
    "text": "proof_of_concept.example_module\n\n\n\n\n\nName\nDescription\n\n\n\n\nValuesDivideTwo\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes delen door twee te doen\n\n\nValuesTimesTwo\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes keer twee te doen\n\n\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo()\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes delen door twee te doen\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die de input en output regelt\n\n\ndf_in\nOptional[pd.DataFrame] | None\nDe input data\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDe output data\n\n\ninput_schema\nClassVar[dict[str, str]]\nDe input schema\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndivide_two\nVermenigvuldigd de meetstation waardes met 2 als voorbeeld\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de functies en stuur de df terug\n\n\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo.divide_two(dataframe)\nVermenigvuldigd de meetstation waardes met 2 als voorbeeld\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo.run(input, output)\nRunt de functies en stuur de df terug\n\n\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo()\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes keer twee te doen\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die de input en output regelt\n\n\ndf_in\nOptional[pd.DataFrame] | None\nDe input data\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDe output data\n\n\ninput_schema\nClassVar[dict[str, str]]\nDe input schema\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de funcies en stuur de df terug\n\n\ntimes_two\nDeelt de meetstation waardes door 2 als voorbeeld\n\n\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo.run(input, output)\nRunt de funcies en stuur de df terug\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo.times_two(dataframe)\nDeelt de meetstation waardes door 2 als voorbeeld"
  },
  {
    "objectID": "reference/proof_of_concept.example_module.html#classes",
    "href": "reference/proof_of_concept.example_module.html#classes",
    "title": "proof_of_concept.example_module",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nValuesDivideTwo\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes delen door twee te doen\n\n\nValuesTimesTwo\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes keer twee te doen\n\n\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo()\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes delen door twee te doen\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die de input en output regelt\n\n\ndf_in\nOptional[pd.DataFrame] | None\nDe input data\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDe output data\n\n\ninput_schema\nClassVar[dict[str, str]]\nDe input schema\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndivide_two\nVermenigvuldigd de meetstation waardes met 2 als voorbeeld\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de functies en stuur de df terug\n\n\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo.divide_two(dataframe)\nVermenigvuldigd de meetstation waardes met 2 als voorbeeld\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nproof_of_concept.example_module.ValuesDivideTwo.run(input, output)\nRunt de functies en stuur de df terug\n\n\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo()\nVoorbeeld class die laat zien hoe de architectuur werkt door waardes keer twee te doen\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter die de input en output regelt\n\n\ndf_in\nOptional[pd.DataFrame] | None\nDe input data\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDe output data\n\n\ninput_schema\nClassVar[dict[str, str]]\nDe input schema\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nRunt de funcies en stuur de df terug\n\n\ntimes_two\nDeelt de meetstation waardes door 2 als voorbeeld\n\n\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo.run(input, output)\nRunt de funcies en stuur de df terug\n\n\n\nproof_of_concept.example_module.ValuesTimesTwo.times_two(dataframe)\nDeelt de meetstation waardes door 2 als voorbeeld"
  },
  {
    "objectID": "reference/SectionsCriticalFailureprobability.html",
    "href": "reference/SectionsCriticalFailureprobability.html",
    "title": "SectionsCriticalFailureprobability",
    "section": "",
    "text": "sections.SectionsCriticalFailureprobability()\nBepaal de maatgevende faalkans van een dijkvak gegeven de technische faalkans, maatregel en beheerdersoordeel.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object voor het verwerken van gegevens.\n\n\ndf_in_failureprobability\nOptional[pd.DataFrame] | None\nInvoer DataFrame met faalkans per dijkvak. Standaardwaarde is None.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nUitvoer DataFrame met faalkans per dijkvak. Standaardwaarde is None.\n\n\ninput_schema_failureprobability\nClassVar[dict[str, str]]\nSchema voor de invoer van de faalkans per dijkvak.\n\n\n\n\n\n\nInput schema’s\ninput_schema_failureprobability: schema voor de lijst met dijkvakken\n\nsection_id: int64 : id van de dijkvak\nfailuremechanism_id: int64 : id van het faalmechanisme\nvalue_parameter_id: int64 : id van de belastingparameter (1,2,3,4)\nparameter_id: int64 : id van de faalkans parameter (5,100,101,102)\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : belasting van de tijdreeksitem\n\nOutput schema\ndf_out: uitvoer\n\nsection_id: int64 : id van het dijkvak\nfailuremechanism_id: int64 : id van het faalmechanisme\nvalue_parameter_id: int64 : id van de belastingparameter (1,2,3,4)\nparameter_id: int64 : id van de faalkans parameter (5,100,101,102)\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nfailureprobability: float64 : faalkans van de tijdreeksitem\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nUitvoeren van het bepalen van de faalkans van een dijkvak.\n\n\n\n\n\nsections.SectionsCriticalFailureprobability.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nsections.SectionsCriticalFailureprobability.run(input, output)\nUitvoeren van het bepalen van de faalkans van een dijkvak.\n\n\ninput: str Naam van de data adapter van Faalkans per dijkvak output: str\nuitvoer data adapter: koppeling van de maatgevende meetlocaties per dijkvak\nDataframe: Pandas dataframe geschikt voor uitvoer:\n\n- Meetlocatie id (measurement_location_id)\n- Meetlocatie code (measurement_location_code)\n- Meetlocatie omschrijving/naam (measurement_location_description)\n- Parameter id overeenkomstig Aquo-standaard: '4724' (parameter_id)\n- Parameter code overeenkomstig Aquo-standaard: 'WATHTE' (parameter_code)\n- Parameter omschrijving overeenkomstig Aquo-standaard: 'Waterhoogte' (parameter_description)\n- Eenheid (unit)\n- Datum en tijd (date_time)\n- Waarde (value)\n- Type waarde: meting of verwachting (value_type)"
  },
  {
    "objectID": "reference/SectionsCriticalFailureprobability.html#attributes",
    "href": "reference/SectionsCriticalFailureprobability.html#attributes",
    "title": "SectionsCriticalFailureprobability",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDataAdapter object voor het verwerken van gegevens.\n\n\ndf_in_failureprobability\nOptional[pd.DataFrame] | None\nInvoer DataFrame met faalkans per dijkvak. Standaardwaarde is None.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nUitvoer DataFrame met faalkans per dijkvak. Standaardwaarde is None.\n\n\ninput_schema_failureprobability\nClassVar[dict[str, str]]\nSchema voor de invoer van de faalkans per dijkvak."
  },
  {
    "objectID": "reference/SectionsCriticalFailureprobability.html#notes",
    "href": "reference/SectionsCriticalFailureprobability.html#notes",
    "title": "SectionsCriticalFailureprobability",
    "section": "",
    "text": "Input schema’s\ninput_schema_failureprobability: schema voor de lijst met dijkvakken\n\nsection_id: int64 : id van de dijkvak\nfailuremechanism_id: int64 : id van het faalmechanisme\nvalue_parameter_id: int64 : id van de belastingparameter (1,2,3,4)\nparameter_id: int64 : id van de faalkans parameter (5,100,101,102)\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : belasting van de tijdreeksitem\n\nOutput schema\ndf_out: uitvoer\n\nsection_id: int64 : id van het dijkvak\nfailuremechanism_id: int64 : id van het faalmechanisme\nvalue_parameter_id: int64 : id van de belastingparameter (1,2,3,4)\nparameter_id: int64 : id van de faalkans parameter (5,100,101,102)\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nfailureprobability: float64 : faalkans van de tijdreeksitem"
  },
  {
    "objectID": "reference/SectionsCriticalFailureprobability.html#methods",
    "href": "reference/SectionsCriticalFailureprobability.html#methods",
    "title": "SectionsCriticalFailureprobability",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrun\nUitvoeren van het bepalen van de faalkans van een dijkvak.\n\n\n\n\n\nsections.SectionsCriticalFailureprobability.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nsections.SectionsCriticalFailureprobability.run(input, output)\nUitvoeren van het bepalen van de faalkans van een dijkvak.\n\n\ninput: str Naam van de data adapter van Faalkans per dijkvak output: str\nuitvoer data adapter: koppeling van de maatgevende meetlocaties per dijkvak\nDataframe: Pandas dataframe geschikt voor uitvoer:\n\n- Meetlocatie id (measurement_location_id)\n- Meetlocatie code (measurement_location_code)\n- Meetlocatie omschrijving/naam (measurement_location_description)\n- Parameter id overeenkomstig Aquo-standaard: '4724' (parameter_id)\n- Parameter code overeenkomstig Aquo-standaard: 'WATHTE' (parameter_code)\n- Parameter omschrijving overeenkomstig Aquo-standaard: 'Waterhoogte' (parameter_description)\n- Eenheid (unit)\n- Datum en tijd (date_time)\n- Waarde (value)\n- Type waarde: meting of verwachting (value_type)"
  },
  {
    "objectID": "reference/SectionsMeasureFailureprobability.html",
    "href": "reference/SectionsMeasureFailureprobability.html",
    "title": "SectionsMeasureFailureprobability",
    "section": "",
    "text": "sections.SectionsMeasureFailureprobability()\nBepaal de faalkans door een maatregel van een dijkvak\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter voor het in- en uitvoeren van gegevens.\n\n\ndf_in_section_loads\nOptional[pd.DataFrame] | None\nDataFrame: Tijdreeks met belasting op het dijkvak.\n\n\ndf_in_fragility_curves\nOptional[pd.DataFrame] | None\nDataFrame: Fragility curves voor het dijkvak.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame: Uitvoer.\n\n\ninput_schema_fragility_curves\nClassVar[dict[str, str]]\nHet invoerschema voor de fragility curves per dijkvak.\n\n\ninput_schema_loads\nClassVar[dict[str, str | list[str]]]\nHet invoerschema voor de belasting per moment per dijkvak\n\n\n\n\n\n\nInput schema’s\ninput_schema_sections: schema voor de lijst met dijkvakken\n\nid: int64 : id van het dijkvak\nname: str : naam van de dijkvak\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\ninput_schema_section_fractions: schema voor koppeling van de maatgevende meetlocaties per dijkvak\n\nid: int64 : id van de dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedenstrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\nOutput schema\ndf_out (DataFrame): uitvoer\n\nid: int64 : id van het dijkvak\nname; str : naam van de dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nunit: str : eenheid van de belastingparameter\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\niterate_combinations\n\n\n\nrun\nBepalen faalkans van een dijkvak met maatregel.\n\n\n\n\n\nsections.SectionsMeasureFailureprobability.iterate_combinations(\n    unique_combinations\n    df_in_belasting\n    df_in_fragility_curves\n    df_out\n)\n\n\n\nsections.SectionsMeasureFailureprobability.run(input, output)\nBepalen faalkans van een dijkvak met maatregel.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst met namen van data adapters voor tijd reeks met belasting op het dijkvak en fragility curves voor het dijkvak.\nrequired\n\n\noutput\nstr\nUitvoer data adapter voor de faalkans van een dijkvak met maatregel.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de lengte van de input niet gelijk is aan 2."
  },
  {
    "objectID": "reference/SectionsMeasureFailureprobability.html#attributes",
    "href": "reference/SectionsMeasureFailureprobability.html#attributes",
    "title": "SectionsMeasureFailureprobability",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ndata_adapter\nDataAdapter\nDe data adapter voor het in- en uitvoeren van gegevens.\n\n\ndf_in_section_loads\nOptional[pd.DataFrame] | None\nDataFrame: Tijdreeks met belasting op het dijkvak.\n\n\ndf_in_fragility_curves\nOptional[pd.DataFrame] | None\nDataFrame: Fragility curves voor het dijkvak.\n\n\ndf_out\nOptional[pd.DataFrame] | None\nDataFrame: Uitvoer.\n\n\ninput_schema_fragility_curves\nClassVar[dict[str, str]]\nHet invoerschema voor de fragility curves per dijkvak.\n\n\ninput_schema_loads\nClassVar[dict[str, str | list[str]]]\nHet invoerschema voor de belasting per moment per dijkvak"
  },
  {
    "objectID": "reference/SectionsMeasureFailureprobability.html#notes",
    "href": "reference/SectionsMeasureFailureprobability.html#notes",
    "title": "SectionsMeasureFailureprobability",
    "section": "",
    "text": "Input schema’s\ninput_schema_sections: schema voor de lijst met dijkvakken\n\nid: int64 : id van het dijkvak\nname: str : naam van de dijkvak\n\ninput_schema_loads: schema voor belasting per moment per meetlocaties\n\nmeasurement_location_id: int64 : id van het meetstation\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nunit: str : eenheid van de belastingparameter\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)\n\ninput_schema_section_fractions: schema voor koppeling van de maatgevende meetlocaties per dijkvak\n\nid: int64 : id van de dijkvak\nidup: int64 : id van bovenstrooms meetstation\niddown: int64 : id van benedenstrooms meetstation\nfractionup: float64 : fractie van bovenstrooms meetstation\nfractiondown: float64 : fractie van benedestrooms meetstation\n\nOutput schema\ndf_out (DataFrame): uitvoer\n\nid: int64 : id van het dijkvak\nname; str : naam van de dijkvak\ndate_time: datetime64[ns, UTC] : datum/ tijd van de tijdreeksitem\nvalue: float64 : waarde van de tijdreeksitem\nunit: str : eenheid van de belastingparameter\nparameter_id: int64 : id van de belastingparameter (1,2,3,4)\nvalue_type: str : type waarde van de tijdreeksitem (meting of verwacht)"
  },
  {
    "objectID": "reference/SectionsMeasureFailureprobability.html#methods",
    "href": "reference/SectionsMeasureFailureprobability.html#methods",
    "title": "SectionsMeasureFailureprobability",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\niterate_combinations\n\n\n\nrun\nBepalen faalkans van een dijkvak met maatregel.\n\n\n\n\n\nsections.SectionsMeasureFailureprobability.iterate_combinations(\n    unique_combinations\n    df_in_belasting\n    df_in_fragility_curves\n    df_out\n)\n\n\n\nsections.SectionsMeasureFailureprobability.run(input, output)\nBepalen faalkans van een dijkvak met maatregel.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst met namen van data adapters voor tijd reeks met belasting op het dijkvak en fragility curves voor het dijkvak.\nrequired\n\n\noutput\nstr\nUitvoer data adapter voor de faalkans van een dijkvak met maatregel.\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nAls de lengte van de input niet gelijk is aan 2."
  },
  {
    "objectID": "reference/ShiftFragilityCurveOvertopping.html",
    "href": "reference/ShiftFragilityCurveOvertopping.html",
    "title": "ShiftFragilityCurveOvertopping",
    "section": "",
    "text": "fragility_curves.ShiftFragilityCurveOvertopping()\nVerschuift de fragility curve met een gegeven effect\n\n\n\n\n\nName\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_bed_levels\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton.\n\n\ndf_profile\nThe type of the None singleton.\n\n\ndf_slopes\nThe type of the None singleton.\n\n\nenforce_monotonic\nReturns True when the argument is true, False otherwise.\n\n\nfailure_probability\nThe type of the None singleton.\n\n\nfragility_curve_schema\ndict() -&gt; new empty dictionary\n\n\nhydraulicload\nThe type of the None singleton.\n\n\nlower_limit\nConvert a string or number to a floating-point number, if possible.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag & shift de curve met een gegeven effect\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.find_jump_indices()\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.run(input, output, effect)\nRunt de berekening van de fragility curve voor golfoverslag & shift de curve met een gegeven effect\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input data adapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\neffect\nfloat\nVerschuiving van de fragility curve\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profieldata moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  },
  {
    "objectID": "reference/ShiftFragilityCurveOvertopping.html#attributes",
    "href": "reference/ShiftFragilityCurveOvertopping.html#attributes",
    "title": "ShiftFragilityCurveOvertopping",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndata_adapter\n\n\n\ndf_bed_levels\nThe type of the None singleton.\n\n\ndf_out\nThe type of the None singleton.\n\n\ndf_profile\nThe type of the None singleton.\n\n\ndf_slopes\nThe type of the None singleton.\n\n\nenforce_monotonic\nReturns True when the argument is true, False otherwise.\n\n\nfailure_probability\nThe type of the None singleton.\n\n\nfragility_curve_schema\ndict() -&gt; new empty dictionary\n\n\nhydraulicload\nThe type of the None singleton.\n\n\nlower_limit\nConvert a string or number to a floating-point number, if possible."
  },
  {
    "objectID": "reference/ShiftFragilityCurveOvertopping.html#methods",
    "href": "reference/ShiftFragilityCurveOvertopping.html#methods",
    "title": "ShiftFragilityCurveOvertopping",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nas_array\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\nas_dataframe\nGeef curve terug als pandas dataframe\n\n\ncalculate_fragility_curve\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\ncheck_monotonic_curve\nForceert monotoon stijgende faalkansen\n\n\nfind_jump_indices\n\n\n\nfrom_dataframe\nZet een dataframe om naar een fragility curve\n\n\ninterp_func\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\nload\nLaadt een fragility curve in\n\n\nlog_exceptions\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\nrefine\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\nreliability_update\nVoer een versimpelde reliability updating uit\n\n\nrun\nRunt de berekening van de fragility curve voor golfoverslag & shift de curve met een gegeven effect\n\n\nshift\nSchuift de hydraulische belasting van de fragility curve op om\n\n\nsort_curve\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.as_array()\nGeef curve terug als NumPy array. Deze kunnen vervolgens worden gestacked en in een database geplaatst\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.as_dataframe()\nGeef curve terug als pandas dataframe\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.calculate_fragility_curve(\n    input\n    output\n)\nBereken de fragility scurve op basis van de opgegeven input en sla het resultaat op in het opgegeven outputbestand.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input dataadapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nUserWarning\nSlopes should have a slopetypeid of 1 or 2\n\n\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.check_monotonic_curve()\nForceert monotoon stijgende faalkansen\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.find_jump_indices()\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.from_dataframe(df)\nZet een dataframe om naar een fragility curve\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.interp_func(\n    x\n    xp\n    fp\n    ll=1e-200\n    clip01=False\n)\ninterpolate_1d met y-waardes omgezet naar log-waardes\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nx\nnp.ndarray\nX-waardes waarop geinterpoleerd moet worden\nrequired\n\n\nxp\nnp.ndarray\nReferentievector van x-waardes\nrequired\n\n\nfp\nnp.ndarray\nReferentievector van y-waardes\nrequired\n\n\nll\nfloat\nOndergrens voor de interpolatie, deze waarde of kleiner wordt als 0 gezien\n1e-200\n\n\nclip01\nbool\nBegrens resultaat tussen [0, 1]\nFalse\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nnp.array\ngeinterpoleerde vector\n\n\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.load(input)\nLaadt een fragility curve in\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.log_exceptions(method)\nStuurt exceptions eerst naar de logger van de DataAdapter\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.refine(\n    new_hydraulicload\n    add_steps=True\n)\nInterpoleert de fragility curve op de gegeven waterstanden\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.reliability_update(\n    update_level\n    trust_factor=1\n)\nVoer een versimpelde reliability updating uit\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nupdate_level\nint | float\nhydraulic load level to which the fragility curve is updated\nrequired\n\n\ntrust_factor\nint | float\nby default 1\n1\n\n\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.run(input, output, effect)\nRunt de berekening van de fragility curve voor golfoverslag & shift de curve met een gegeven effect\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ninput\nlist[str]\nLijst namen van de input data adapters: slopes, profile en bed_levels\nrequired\n\n\noutput\nstr\nNaam van de dataadapter Fragility curve output\nrequired\n\n\neffect\nfloat\nVerschuiving van de fragility curve\nrequired\n\n\n\n\n\n\nDeze input volgorde is wat specifiek, vandaar de extra details. Waar geen type is opgegeven moet het type float zijn. De eerste (slopes) data adapter moet de volgende kolommen bevatten:\n\nx, x-co�rdinaat\ny, y-co�rdinaat\nr, roughness\nslopetypeid, id de helling type (int, 1: dike or 2: slope)\n\nDe tweede (profile) data adapter met profieldata moet de volgende kolommen bevatten:\n\nwindspeed, windsnelheid\nsectormin, de minimale sectorhoek.\nsectorsize, de grootte van de sectorhoek.\norientation, orientatie van het profiel in graden\ncrestlevel, kruinhoogte in meters\ndam, wel of geen dam (int, 0: geen dam or 1: dam)\ndamheight, dam hoogte in meters\nqcr, mag een van 3 zijn: een waarde in m^3/s (float), open of niet (str: close | open) of de waarden van mu en sigma (tuple).\n\nDe derde (Bedlevelfetch) data adapter met bodem data moet de volgende kolommen bevatten:\n\ndirection, windrichtingen\nbedlevel, bodem profielen\nfetch, lengte van fetch in meters\n\n\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.shift(effect)\nSchuift de hydraulische belasting van de fragility curve op om bijvoorbeeld het effect van een noodmaatregel te implementeren. Een positieve verschuiving levert bij dezelfde faalkans dan een hogere hydraulische belasting op. Of bij dezelfde hydraulische belasting een lagere faalkans.\n\n\n\nfragility_curves.ShiftFragilityCurveOvertopping.sort_curve()\nSorteert de fragility curve eerst op waterstand en vervolgens op faalkans"
  }
]