{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title : \"Overstromingsrisico scenarios\"\n",
    "execute:\n",
    "    output: asis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarios worden gebruikt om de mogelijke gevolgen van overstromingen in kaart te brengen. <br>\n",
    "Hiermee kan de kans uit een fragilitycruve gecombineerd worden met de gevolgen die bepaald zijn bij een scenario om zo een beter inzicht te krijgen in het totale risico. <br>\n",
    "Dit kan helpen om prioriteiten te stellen op basis van een totaal beeld en niet alleen op basis van kans of gevolg afzonderlijk. <br>\n",
    "Om de scenarios te kunnen combineren moeten er een aantal stappen worden doorlopen:\n",
    "- Omrekenen van dijkvakkansen naar trajectdeelkansen ([CalculateFloodScenarioProbability](#sec-CalculateFloodScenarioProbability))\n",
    "- Belasting per deeltraject bepalen ([LoadFromFloodScenarioProbabilit](#sec-LoadFromFloodScenarioProbabilit))\n",
    "- Met de belasting een bijpassende overstromingscenario selecteren ([SelectFloodScenarioFromLoad ](#sec-SelectFloodScenarioFromLoad))\n",
    "- Van het scenario en de curve een geagregeerd risico bepalen ([CalculateFloodRisk](#sec-CalculateFloodRisk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from toolbox_continu_inzicht.base.config import Config\n",
    "from toolbox_continu_inzicht.base.data_adapter import DataAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"data_sets\" / \"7.flood_scenarios\"\n",
    "config = Config(config_path=path / \"test_calculate_flood_scenario_probability.yaml\")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_continu_inzicht.flood_scenarios import CalculateFloodScenarioProbability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalculateFloodScenarioProbability{sec-CalculateFloodScenarioProbability}\n",
    "\n",
    "Dit voorbeeld laat zien hoe met behulp van de `CalculateFloodScenarioProbability`  dijkvakkansen naar trajectdeelkansen kunnen worden omgezet. <br>\n",
    "Hiervoor is de gecombineerde faalkans per dijkvak nodig en een mapping van dijkvakken naar dijktraject delen van daar naar de overstromingsscenario gebieden.\n",
    "```yaml|\n",
    "GlobalVariables:\n",
    "    rootdir: \"data_sets/7.flood_scenarios\"\n",
    "    moments: [-24,0,24,48]\n",
    "\n",
    "DataAdapter:\n",
    "    default_options:\n",
    "        csv:\n",
    "            sep: \",\"\n",
    "    combined_failure_probability_data:\n",
    "        type: csv\n",
    "        file: \"combined_failure_probability_data.csv\"\n",
    "    section_id_to_segment_id:\n",
    "        type: csv\n",
    "        file: \"section_id_to_segment_id.csv\"\n",
    "    segment_failure_probability:\n",
    "        type: csv\n",
    "        file: \"segment_failure_probability.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_scenario_probability = CalculateFloodScenarioProbability(\n",
    "    data_adapter=data_adapter\n",
    ")\n",
    "calculate_flood_scenario_probability.run(\n",
    "    input=[\"combined_failure_probability_data\", \"section_id_to_segment_id\"],\n",
    "    output=\"segment_failure_probability\",\n",
    ")\n",
    "# TODO: segment to dikesystem, only needed later on for risk = probability * damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_scenario_probability.df_in_sections_to_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_scenario_probability.df_in_grouped_sections_failure_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_scenario_probability.df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_continu_inzicht.flood_scenarios import LoadFromFloodScenarioProbability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoadFromFloodScenarioProbability{sec-LoadFromFloodScenarioProbabilit}\n",
    "\n",
    "Nu we de faalkansen per trajectdeel hebben kunnen we met de `LoadFromFloodScenarioProbability` de belasting per trajectdeel bepalen. <br>\n",
    "Dit doen we om een bijpassende overstromingsscenario te kunnen selecteren. <br>\n",
    "Met de input van de vorige stap `segment_failure_probability`, maken we een koppeling naar de bijhorende bres en fragilitycurve die representatief is voor een deeltraject met de tabel `breach_id_to_segment_id`. <br>\n",
    "Deze `representative_section_id_fragilitycurve` kan vervolgens uit de data van de curves in `section_failure_probability_data` worden gehaald. <br>\n",
    "Met de curve wordt de hydraulische belasting bepaald voor het deeltraject.\n",
    "\n",
    "```yaml\n",
    "GlobalVariables:\n",
    "    rootdir: \"data_sets/7.flood_scenarios\"\n",
    "    moments: [ -24, 0, 24, 48 ]\n",
    "\n",
    "DataAdapter:\n",
    "    default_options:\n",
    "        csv:\n",
    "            sep: \",\"\n",
    "    segment_failure_probability:\n",
    "        type: csv\n",
    "        file: \"segment_failure_probability.csv\"\n",
    "    breach_id_to_segment_id:\n",
    "        type: csv\n",
    "        file: \"breach_id_to_segment_id.csv\"\n",
    "    section_failure_probability_data:\n",
    "        type: csv\n",
    "        file: \"fragility_curve_multi_section.csv\"\n",
    "    flood_scenario_load_resultaten:\n",
    "        type: csv\n",
    "        path: \"hidden_flood_scenario_load_resultaten.csv\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(config_path=path / \"test_load_from_flood_scenario_probability.yaml\")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"segment_failure_probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"breach_id_to_segment_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"section_failure_probability_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_flood_scenario_probability = LoadFromFloodScenarioProbability(\n",
    "    data_adapter=data_adapter\n",
    ")\n",
    "load_from_flood_scenario_probability.run(\n",
    "    input=[\n",
    "        \"segment_failure_probability\",\n",
    "        \"breach_id_to_segment_id\",\n",
    "        \"section_failure_probability_data\",\n",
    "    ],\n",
    "    output=\"flood_scenario_load_resultaten\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"flood_scenario_load_resultaten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_adapter.input(\"section_failure_probability_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from toolbox_continu_inzicht.utils.interpolate import (\n",
    "    log_y_interpolate_1d,\n",
    "    log_x_interpolate_1d,\n",
    ")\n",
    "\n",
    "\n",
    "df_fc = df[df[\"section_id\"] == 1][[\"hydraulicload\", \"failure_probability\"]]\n",
    "x, fp = df_fc[\"hydraulicload\"].to_numpy(), df_fc[\"failure_probability\"].to_numpy()\n",
    "y = np.array(sorted(list(fp) + [0.183]))\n",
    "new_x = log_y_interpolate_1d(y, x, fp, ll=1e-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x, fp, label=\"data points\")\n",
    "plt.plot(new_x, y, label=\"interpolated\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"section_id\"] == 1][[\"hydraulicload\", \"failure_probability\"]].set_index(\n",
    "    \"hydraulicload\"\n",
    ").plot(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: add to fragility curve tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_continu_inzicht.utils.interpolate import (\n",
    "    log_y_interpolate_1d,\n",
    "    beta_y_interpolate_1d,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_new = np.array([2, 3, 4])\n",
    "y = np.array([1 / 1000, 1 / 10])\n",
    "x = np.array([2, 4])\n",
    "y_new = np.array([1 / 1000, 1 / 100, 1 / 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_x_interpolate_1d(x_new, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_y_interpolate_1d(y_new, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_y_interpolate_1d(y_new, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
