{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title : \"Overstromingsrisico scenarios\"\n",
    "execute:\n",
    "    output: asis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarios worden gebruikt om de mogelijke gevolgen van overstromingen in kaart te brengen. <br>\n",
    "Hiermee kan de kans uit een fragilitycruve gecombineerd worden met de gevolgen die bepaald zijn bij een scenario om zo een beter inzicht te krijgen in het totale risico. <br>\n",
    "Dit kan helpen om prioriteiten te stellen op basis van een totaal beeld en niet alleen op basis van kans of gevolg afzonderlijk. <br>\n",
    "Om de scenarios te kunnen combineren moeten er een aantal stappen worden doorlopen:\n",
    "- Omrekenen van dijkvakkansen naar trajectdeelkansen ([CalculateFloodScenarioProbability](#sec-CalculateFloodScenarioProbability))\n",
    "- Belasting per deeltraject bepalen ([LoadFromFloodScenarioProbabilit](#sec-LoadFromFloodScenarioProbabilit))\n",
    "- Met de belasting een bijpassende overstromingscenario selecteren ([SelectFloodScenarioFromLoad ](#sec-SelectFloodScenarioFromLoad))\n",
    "- Van het scenario en de curve een geagregeerd risico bepalen ([CalculateFloodRisk](#sec-CalculateFloodRisk))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from toolbox_continu_inzicht.base.config import Config\n",
    "from toolbox_continu_inzicht.base.data_adapter import DataAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / \"data_sets\" / \"7.flood_scenarios\"\n",
    "config = Config(config_path=path / \"test_calculate_flood_scenario_probability.yaml\")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_continu_inzicht.flood_scenarios import CalculateFloodScenarioProbability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalculateFloodScenarioProbability{sec-CalculateFloodScenarioProbability}\n",
    "\n",
    "Dit voorbeeld laat zien hoe met behulp van de `CalculateFloodScenarioProbability`  dijkvakkansen naar trajectdeelkansen kunnen worden omgezet. <br>\n",
    "Hiervoor is de **gecombineerde** faalkans per dijkvak nodig en een mapping van dijkvakken naar dijktraject delen van daar naar de overstromingsscenario gebieden.\n",
    "\n",
    "\n",
    ">|⚠️ **Nog checken**|\n",
    ">|---|\n",
    ">- of we eerst alle mechanismes combineren, en dan naar dijktraject delen combineren (doen we nu). \n",
    ">- of eerst naar dijktraject delen combineren en dan de mechanismes combineren.\n",
    "\n",
    "```yaml|\n",
    "GlobalVariables:\n",
    "    rootdir: \"data_sets/7.flood_scenarios\"\n",
    "    moments: [-24,0,24,48]\n",
    "\n",
    "DataAdapter:\n",
    "    default_options:\n",
    "        csv:\n",
    "            sep: \",\"\n",
    "    combined_failure_probability_data:\n",
    "        type: csv\n",
    "        file: \"combined_failure_probability_data.csv\"\n",
    "    section_id_to_segment_id:\n",
    "        type: csv\n",
    "        file: \"section_id_to_segment_id.csv\"\n",
    "    segment_failure_probability:\n",
    "        type: csv\n",
    "        file: \"segment_failure_probability.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_scenario_probability = CalculateFloodScenarioProbability(\n",
    "    data_adapter=data_adapter\n",
    ")\n",
    "calculate_flood_scenario_probability.run(\n",
    "    input=[\n",
    "        \"combined_failure_probability_data\",\n",
    "        \"section_id_to_segment_id\",\n",
    "        \"failure_mechanisms\",\n",
    "    ],\n",
    "    output=[\"segment_failure_probability\", \"gecombineerde_faalkans_dijkvakken\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_scenario_probability.df_in_sections_to_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_flood_scenario_probability.df_in_grouped_sections_failure_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"section_id\"][df[\"section_id\"] < 1.5].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_scenario_probability.df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# across all dike sections, needed for CalculateFloodRisk\n",
    "calculate_flood_scenario_probability.df_out_combined_failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoadFromFloodScenarioProbability{sec-LoadFromFloodScenarioProbabilit}\n",
    "\n",
    "Nu we de faalkansen per trajectdeel hebben kunnen we met de `LoadFromFloodScenarioProbability` de belasting per trajectdeel bepalen. <br>\n",
    "Dit doen we om een bijpassende overstromingsscenario te kunnen selecteren. <br>\n",
    "Met de input van de vorige stap `segment_failure_probability`, maken we een koppeling naar de bijhorende bres en fragilitycurve die representatief is voor een deeltraject met de tabel `breach_id_to_segment_id`. <br>\n",
    "Deze `representative_section_id_fragilitycurve` kan vervolgens uit de data van de curves in `section_failure_probability_data` worden gehaald. <br>\n",
    "Met de curve wordt de hydraulische belasting bepaald voor het deeltraject.\n",
    "\n",
    "```yaml\n",
    "GlobalVariables:\n",
    "    rootdir: \"data_sets/7.flood_scenarios\"\n",
    "    moments: [ -24, 0, 24, 48 ]\n",
    "\n",
    "DataAdapter:\n",
    "    default_options:\n",
    "        csv:\n",
    "            sep: \",\"\n",
    "    segment_failure_probability:\n",
    "        type: csv\n",
    "        file: \"segment_failure_probability.csv\"\n",
    "    breach_id_to_segment_id:\n",
    "        type: csv\n",
    "        file: \"breach_id_to_segment_id.csv\"\n",
    "    section_failure_probability_data:\n",
    "        type: csv\n",
    "        file: \"fragility_curve_multi_section.csv\"\n",
    "    flood_scenario_load_resultaten:\n",
    "        type: csv\n",
    "        path: \"hidden_flood_scenario_load_resultaten.csv\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(config_path=path / \"test_load_from_flood_scenario_probability.yaml\")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"segment_failure_probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"breach_id_to_segment_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_adapter.input(\"section_failure_probability_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_continu_inzicht.flood_scenarios import LoadFromFloodScenarioProbability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_flood_scenario_probability = LoadFromFloodScenarioProbability(\n",
    "    data_adapter=data_adapter\n",
    ")\n",
    "load_from_flood_scenario_probability.run(\n",
    "    input=[\n",
    "        \"segment_failure_probability\",\n",
    "        \"breach_id_to_segment_id\",\n",
    "        \"section_failure_probability_data\",\n",
    "    ],\n",
    "    output=\"flood_scenario_load_resultaten\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"flood_scenario_load_resultaten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"section_failure_probability_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectFloodScenarioFromLoad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "GlobalVariables:\n",
    "    rootdir: \"data_sets/7.flood_scenarios\"\n",
    "    moments: [ -24, 0, 24, 48 ]\n",
    "    SelectFloodScenarioFromLoad:\n",
    "        return_two_scenarios: False # default\n",
    "\n",
    "DataAdapter:\n",
    "    default_options:\n",
    "        csv:\n",
    "            sep: \",\"\n",
    "    flood_scenario_loads:\n",
    "        type: csv\n",
    "        path: \"flood_scenario_load_resultaten.csv\"\n",
    "    breach_location_metadata:\n",
    "        type: csv\n",
    "        path: \"breach_location_metadata.csv\"\n",
    "    flood_scenario_grids:\n",
    "        type: csv\n",
    "        path: \"hidden_flood_scenario_grids.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(config_path=path / \"test_select_flood_scenario_from_load.yaml\")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_continu_inzicht.flood_scenarios import SelectFloodScenarioFromLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"flood_scenario_loads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_adapter.input(\"breach_location_metadata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_flood_scenario_from_load = SelectFloodScenarioFromLoad(data_adapter=data_adapter)\n",
    "select_flood_scenario_from_load.run(\n",
    "    input=[\n",
    "        \"flood_scenario_loads\",\n",
    "        \"breach_location_metadata\",\n",
    "    ],\n",
    "    output=\"flood_scenario_grids\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_flood_scenario_from_load.df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keuze uit twee scenarios\n",
    "\n",
    "Standaard wordt er per deeltraject één overstromingsscenario geselecteerd op basis van de hydraulische belasting. <br>\n",
    "Met de parameter `return_two_scenarios` kan ervoor gekozen worden om twee overstromingsscenarios te selecteren. <br>\n",
    "De gebruiker kan hiermee zelf bepalen welk scenario hij wil gebruiken voor de risico berekening. <br>\n",
    "Of de gemiddelde schade van de twee scenario's gebruiken, of beide tonen. \n",
    "\n",
    "```yaml\n",
    "GlobalVariables:\n",
    "    rootdir: \"data_sets/7.flood_scenarios\"\n",
    "    moments: [ -24, 0, 24, 48 ]\n",
    "    SelectFloodScenarioFromLoad:\n",
    "        return_two_scenarios: True\n",
    "\n",
    "DataAdapter:\n",
    "    default_options:\n",
    "        csv:\n",
    "            sep: \",\"\n",
    "    flood_scenario_loads:\n",
    "        type: csv\n",
    "        path: \"flood_scenario_load_resultaten.csv\"\n",
    "    breach_location_metadata:\n",
    "        type: csv\n",
    "        path: \"breach_location_metadata.csv\"\n",
    "    flood_scenario_grids:\n",
    "        type: csv\n",
    "        path: \"hidden_flood_scenario_grids_two.csv\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    config_path=path / \"test_select_flood_scenario_from_load_two_scenarios.yaml\"\n",
    ")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_flood_scenario_from_load = SelectFloodScenarioFromLoad(data_adapter=data_adapter)\n",
    "select_flood_scenario_from_load.run(\n",
    "    input=[\n",
    "        \"flood_scenario_loads\",\n",
    "        \"breach_location_metadata\",\n",
    "    ],\n",
    "    output=\"flood_scenario_grids\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_flood_scenario_from_load.df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CalculateFloodRisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox_continu_inzicht.flood_scenarios.calculate_flood_risk import (\n",
    "    CalculateFloodRisk,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "GlobalVariables:\n",
    "    rootdir: \"data_sets/7.flood_scenarios\"\n",
    "    moments: [ -24, 0, 24, 48 ]\n",
    "    CalculateFloodRisk:\n",
    "        averging_method: # these are default values, can be overridden in config\n",
    "            casualties: sum\n",
    "            damage: sum\n",
    "            flooding: median\n",
    "            affectedpeople: sum\n",
    "            waterdepth: sum\n",
    "        per_hectare: False\n",
    "        \n",
    "DataAdapter:\n",
    "    default_options:\n",
    "        csv:\n",
    "            sep: \",\"\n",
    "    segment_failure_probability:\n",
    "        type: csv\n",
    "        path: \"segment_failure_probability.csv\"\n",
    "    flood_scenario_grids:\n",
    "        type: csv\n",
    "        path: \"flood_scenario_grids.csv\"\n",
    "    areas_to_average:\n",
    "        type: shape\n",
    "        path: \"areas_to_average.geojson\"\n",
    "    flood_risk_local_file:\n",
    "        type: flood_risk_local_file\n",
    "        path: '' # gebruik de data_dir\n",
    "        scenario_path: \"flood_scenarios\" # en een map dieper kijk in de floodscenarios dir\n",
    "    flood_risk_results:\n",
    "        type: csv\n",
    "        path: \"hidden_flood_risk_results.csv\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(config_path=path / \"test_calculate_flood_risk.yaml\")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_risk = CalculateFloodRisk(data_adapter=data_adapter)\n",
    "calculate_flood_risk.run(\n",
    "    input=[\n",
    "        \"segment_failure_probability\",\n",
    "        \"flood_scenario_grids\",\n",
    "        \"areas_to_average\",\n",
    "        \"flood_risk_local_file\",\n",
    "    ],\n",
    "    output=\"flood_risk_results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_flood_risk.df_out.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gdf_results = calculate_flood_risk.df_out\n",
    "\n",
    "columns = [\"casualties\", \"damage\", \"flooding\", \"affected_people\"]\n",
    "rename = {\n",
    "    \"casualties\": \"Slachtoffers\",\n",
    "    \"damage\": \"Schade\",\n",
    "    \"flooding\": \"Plaatgebonden overstromingskans\",\n",
    "    \"affected_people\": \"Getroffen mensen\",\n",
    "}\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7, 5))\n",
    "ax = axs.flatten()\n",
    "for index, column in enumerate(columns):\n",
    "    gdf_results.plot(column=column, ax=ax[index])\n",
    "    plt.colorbar(ax[index].collections[0], ax=ax[index], orientation=\"horizontal\")\n",
    "    ax[index].set_title(rename[column])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Herhaal per ha\n",
    "```yaml\n",
    "GlobalVariables:\n",
    "    ...\n",
    "    CalculateFloodRisk:\n",
    "        ...\n",
    "        per_hectare: True\n",
    "        columns_per_hectare:\n",
    "            - casualties\n",
    "            - damage\n",
    "            - affectedpeople\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(config_path=path / \"test_calculate_flood_risk_per_ha.yaml\")\n",
    "config.lees_config()\n",
    "data_adapter = DataAdapter(config=config)\n",
    "calculate_flood_risk = CalculateFloodRisk(data_adapter=data_adapter)\n",
    "calculate_flood_risk.run(\n",
    "    input=[\n",
    "        \"segment_failure_probability\",\n",
    "        \"flood_scenario_grids\",\n",
    "        \"areas_to_average\",\n",
    "        \"flood_risk_local_file\",\n",
    "    ],\n",
    "    output=\"flood_risk_results\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gdf_results = calculate_flood_risk.df_out\n",
    "\n",
    "columns = [\"casualties_per_ha\", \"damage_per_ha\", \"flooding\", \"affected_people_per_ha\"]\n",
    "rename = {\n",
    "    \"casualties_per_ha\": \"Slachtoffers per hectare\",\n",
    "    \"damage_per_ha\": \"Schade per hectare\",\n",
    "    \"flooding\": \"Plaatgebonden overstromingskans\",\n",
    "    \"affected_people_per_ha\": \"Getroffen mensen per hectare\",\n",
    "}\n",
    "fig, axs = plt.subplots(2, 2, figsize=(7, 5))\n",
    "ax = axs.flatten()\n",
    "for index, column in enumerate(columns):\n",
    "    gdf_results.plot(column=column, ax=ax[index])\n",
    "    plt.colorbar(ax[index].collections[0], ax=ax[index], orientation=\"horizontal\")\n",
    "    ax[index].set_title(rename[column])\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
